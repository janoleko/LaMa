[{"path":[]},{"path":"https://janoleko.github.io/articles/Continuous_time_HMMs.html","id":"setting-parameters-for-simulation","dir":"Articles","previous_headings":"Example 1: two states","what":"Setting parameters for simulation","title":"Continuous-time HMMs","text":"start setting parameters simulate data. example, state 1 smaller rate state dwell time state one follows Exp(0.5)Exp(0.5) distribution, .e. exhibits longer dwell times state 2 rate 1.","code":"# loading the package library(LaMa) #> Loading required package: RTMB # generator matrix Q: Q = matrix(c(-0.5, 0.5, 1, -1),             nrow = 2, byrow = TRUE)  # parameters for the state-dependent (normal) distributions mu = c(5, 20) sigma = c(2, 5)"},{"path":"https://janoleko.github.io/articles/Continuous_time_HMMs.html","id":"simulating-data","dir":"Articles","previous_headings":"Example 1: two states","what":"Simulating data","title":"Continuous-time HMMs","text":"simulate continuous-time Markov chain drawing exponentially distributed state dwell-times. Within stay, can assume whatever structure like observation times, explicitly modeled. choose generate Poisson process rate λ=1\\lambda=1, choice arbitrary. details Poisson point processes, see MM(M)PP vignette. Let’s visualise simulated continuous-time HMM:","code":"set.seed(123)  k = 200 # number of state switches trans_times = s = rep(NA, k) # time points where the chain transitions s[1] = sample(1:2, 1) # initial distribuion c(0.5, 0.5) # exponentially distributed waiting times trans_times[1] = rexp(1, -Q[s[1],s[1]]) n_arrivals = rpois(1, trans_times[1]) obs_times = sort(runif(n_arrivals, 0, trans_times[1])) x = rnorm(n_arrivals, mu[s[1]], sigma[s[1]]) for(t in 2:k){   s[t] = c(1,2)[-s[t-1]] # for 2-states, always a state swith when transitioning   # exponentially distributed waiting times   trans_times[t] = trans_times[t-1] + rexp(1, -Q[s[t], s[t]])   n_arrivals = rpois(1, trans_times[t]-trans_times[t-1])   obs_times = c(obs_times,                  sort(runif(n_arrivals, trans_times[t-1], trans_times[t])))   x = c(x, rnorm(n_arrivals, mu[s[t]], sigma[s[t]])) } color = c(\"orange\", \"deepskyblue\")  n = length(obs_times) plot(obs_times[1:50], x[1:50], pch = 16, bty = \"n\", xlab = \"observation times\",       ylab = \"x\", ylim = c(-5,25)) segments(x0 = c(0,trans_times[1:48]), x1 = trans_times[1:49],           y0 = rep(-5,50), y1 = rep(-5,50), col = color[s[1:49]], lwd = 4) legend(\"topright\", lwd = 2, col = color,         legend = c(\"state 1\", \"state 2\"), box.lwd = 0)"},{"path":"https://janoleko.github.io/articles/Continuous_time_HMMs.html","id":"writing-the-negative-log-likelihood-function","dir":"Articles","previous_headings":"Example 1: two states","what":"Writing the negative log-likelihood function","title":"Continuous-time HMMs","text":"likelhood continuous-time HMM observations xt1,…,xtTx_{t_1}, \\dots, x_{t_T} irregular time points t1,…,tTt_1, \\dots, t_T exact structure regular HMM likelihood: L(θ)=δ(1)Γ(t1,t2)P(xt2)Γ(t2,t3)P(xt3)…Γ(tT−1,tT)P(xtT)1t, L(\\theta) = \\delta^{(1)} \\Gamma(t_1, t_2) P(x_{t_2}) \\Gamma(t_2, t_3) P(x_{t_3}) \\dots \\Gamma(t_{T-1}, t_T) P(x_{t_T}) 1^t,  δ(1)\\delta^{(1)}, PP 1t1^t usual Γ(tk,tk+1)\\Gamma(t_k, t_{k+1}) computed explained . Thus can fit models using standard implementation general forward algorithm forward_g() time-varying transition probability matrices. can use generator() function compute infinitesimal generator matrix unconstrained parameter vector tpm_cont() compute matrix exponentials.","code":"nll = function(par, timediff, x, N){   mu = par[1:N]   sigma = exp(par[N+1:N])   Q = generator(par[2*N+1:(N*(N-1))]) # generator matrix   delta = stationary_cont(Q) # stationary dist of CT Markov chain   Qube = tpm_cont(Q, timediff) # this computes exp(Q*timediff)   allprobs = matrix(1, nrow = length(x), ncol = N)   ind = which(!is.na(x))   for(j in 1:N){     allprobs[ind,j] = dnorm(x[ind], mu[j], sigma[j])   }   -forward_g(delta, Qube, allprobs) }"},{"path":"https://janoleko.github.io/articles/Continuous_time_HMMs.html","id":"fitting-a-continuous-time-hmm-to-the-data","dir":"Articles","previous_headings":"Example 1: two states","what":"Fitting a continuous-time HMM to the data","title":"Continuous-time HMMs","text":"","code":"par = c(mu = c(5, 15), # state-dependent means         logsigma = c(log(3), log(5)), # state-dependent sds         qs = c(log(1), log(0.5))) # off-diagonals of Q  timediff = diff(obs_times)  system.time(   mod <- nlm(nll, par, timediff = timediff, x = x, N = 2) ) #>    user  system elapsed  #>   0.272   0.211   0.248"},{"path":"https://janoleko.github.io/articles/Continuous_time_HMMs.html","id":"results","dir":"Articles","previous_headings":"Example 1: two states","what":"Results","title":"Continuous-time HMMs","text":"","code":"N = 2 # mu round(mod$estimate[1:N],2) #> [1]  5.06 20.24 # sigma round(exp(mod$estimate[N+1:N])) #> [1] 2 5 Q = generator(mod$estimate[2*N+1:(N*(N-1))]) round(Q,3) #>        [,1]   [,2] #> [1,] -0.479  0.479 #> [2,]  0.905 -0.905"},{"path":[]},{"path":"https://janoleko.github.io/articles/Continuous_time_HMMs.html","id":"setting-parameters-for-simulation-1","dir":"Articles","previous_headings":"Example 2: three states","what":"Setting parameters for simulation","title":"Continuous-time HMMs","text":"","code":"# generator matrix Q: Q = matrix(c(-0.5,0.2,0.3,              1,-2, 1,              0.4, 0.6, -1), nrow = 3, byrow = TRUE)  # parameters for the state-dependent (normal) distributions mu = c(5, 15, 30) sigma = c(2, 3, 5)"},{"path":"https://janoleko.github.io/articles/Continuous_time_HMMs.html","id":"simulating-data-1","dir":"Articles","previous_headings":"Example 2: three states","what":"Simulating data","title":"Continuous-time HMMs","text":"simulation similar now also draw state transition , explained beginning.","code":"set.seed(123)  k = 200 # number of state switches trans_times = s = rep(NA, k) # time points where the chain transitions s[1] = sample(1:3, 1) # uniform initial distribuion # exponentially distributed waiting times trans_times[1] = rexp(1, -Q[s[1],s[1]]) n_arrivals = rpois(1, trans_times[1]) obs_times = sort(runif(n_arrivals, 0, trans_times[1])) x = rnorm(n_arrivals, mu[s[1]], sigma[s[1]]) for(t in 2:k){   # off-diagonal elements of the s[t-1] row of Q divided by the diagonal element   # give the probabilites of the next state   s[t] = sample(c(1:3)[-s[t-1]], 1, prob = Q[s[t-1],-s[t-1]]/-Q[s[t-1],s[t-1]])   # exponentially distributed waiting times   trans_times[t] = trans_times[t-1] + rexp(1, -Q[s[t], s[t]])   n_arrivals = rpois(1, trans_times[t]-trans_times[t-1])   obs_times = c(obs_times,                  sort(runif(n_arrivals, trans_times[t-1], trans_times[t])))   x = c(x, rnorm(n_arrivals, mu[s[t]], sigma[s[t]])) }"},{"path":"https://janoleko.github.io/articles/Continuous_time_HMMs.html","id":"fitting-a-3-state-continuous-time-hmm-to-the-data","dir":"Articles","previous_headings":"Example 2: three states","what":"Fitting a 3-state continuous-time HMM to the data","title":"Continuous-time HMMs","text":"","code":"par = c(mu = c(5, 10, 25), # state-dependent means         logsigma = c(log(2), log(2), log(6)), # state-dependent sds         qs = rep(0, 6)) # off-diagonals of Q  timediff = diff(obs_times)  system.time(   mod2 <- nlm(nll, par, timediff = timediff, x = x, N = 3, stepmax = 10) ) #>    user  system elapsed  #>   1.920   2.665   1.530 # without restricting stepmax, we run into numerical problems"},{"path":"https://janoleko.github.io/articles/Continuous_time_HMMs.html","id":"results-1","dir":"Articles","previous_headings":"Example 2: three states","what":"Results","title":"Continuous-time HMMs","text":"","code":"N = 3 # mu round(mod2$estimate[1:N],2) #> [1]  4.90 15.45 29.10 # sigma round(exp(mod2$estimate[N+1:N]),2) #> [1] 1.80 2.58 5.06 Q = generator(mod2$estimate[2*N+1:(N*(N-1))]) round(Q, 3) #>        [,1]   [,2]   [,3] #> [1,] -0.888  0.565  0.323 #> [2,]  2.821 -3.469  0.647 #> [3,]  0.000  0.770 -0.770"},{"path":[]},{"path":"https://janoleko.github.io/articles/HSMMs.html","id":"homogeneous-hsmms","dir":"Articles","previous_headings":"","what":"Homogeneous HSMMs","title":"Hidden semi-Markov models","text":"begin considering homogeneous HSMMs. models, state associated state dwell-time distribution. transition probability matrix regular HMM replaced distributions conditional transition probabilities given state left.","code":""},{"path":"https://janoleko.github.io/articles/HSMMs.html","id":"setting-parameters","dir":"Articles","previous_headings":"Homogeneous HSMMs","what":"Setting parameters","title":"Hidden semi-Markov models","text":"choose simplest case dwell times shifted Poisson distributed. specify Poisson mean state, conditional transition probability matrix called Ω\\Omega parameters state-dependent process.","code":"# loading the package library(\"LaMa\") #> Loading required package: RTMB lambda = c(7, 4, 4) omega = matrix(c(0, 0.7, 0.3,                  0.5, 0, 0.5,                  0.7, 0.3, 0), nrow = 3, byrow = TRUE) mu = c(10, 40, 100) sigma = c(5, 20, 50)  color = c(\"orange\", \"deepskyblue\", \"seagreen2\") curve(dnorm(x, mu[1], sigma[1]), lwd = 2, col = color[1], bty = \"n\",       xlab = \"x\", ylab = \"density\", xlim = c(0, 150), n = 300) curve(dnorm(x, mu[2], sigma[2]), lwd = 2, col = color[2], add = T) curve(dnorm(x, mu[3], sigma[3]), lwd = 2, col = color[3], add = T)"},{"path":"https://janoleko.github.io/articles/HSMMs.html","id":"simulating-data","dir":"Articles","previous_headings":"Homogeneous HSMMs","what":"Simulating data","title":"Hidden semi-Markov models","text":"simulate data drawing dwell times dwell-time distribution current state draw next state using conditional transition probabilities. state-dependent process drawn conditional current state.","code":"set.seed(123)  k = 50 # number of stays s = rep(NA, k) s[1] = sample(1:3, 1) # uniform initial distribution staylength = rpois(1, lambda[s[1]]) + 1 # drawing dwell time from shifted Poisson C = rep(s[1], staylength) x = rnorm(staylength, mu[s[1]], sigma[s[1]])  for(t in 2:k){   # conditionally drawing state   s[t] = sample(c(1:3)[-s[t-1]], 1, prob = omega[s[t-1], -s[t-1]])   staylength = rpois(1, lambda[s[t]]) + 1 # drawing dwell time from shifted Poisson      C = c(C, rep(s[t], staylength))   x = c(x, rnorm(staylength, mu[s[t]], sigma[s[t]])) }  plot(x, pch = 20, col = color[C], bty = \"n\") legend(\"topright\", col = color, pch = 20,         legend = paste(\"state\", 1:3), box.lwd = 0)"},{"path":"https://janoleko.github.io/articles/HSMMs.html","id":"writing-the-negative-log-likelihood-function","dir":"Articles","previous_headings":"Homogeneous HSMMs","what":"Writing the negative log-likelihood function","title":"Hidden semi-Markov models","text":"now write negative log-likelihood function approximating HMM. semi-Markov chain specified terms state-specific dwell-time distributions conditional transition probabilities given current state left, compute (called dm omege). transition probability matrix approxmiating HMM can computed function tpm_hsmm() exact procedure detailed Langrock Zucchini (2011). need extra argument agsizes specify aggregate sizes used approximate dwell-time distributions. chosen support state-specific dwell-time distributions covered.","code":"mllk = function(theta.star, x, N, agsizes){   mu = theta.star[1:N]   sigma = exp(theta.star[N+1:N])   lambda = exp(theta.star[2*N+1:N])   if(N>2){      # this is a bit complicated as we need the diagonal elements to be zero     omega = matrix(0,N,N)     omega[!diag(N)] = as.vector(t(matrix(c(rep(1,N),                           exp(theta.star[3*N+1:(N*(N-2))])),N,N-1)))     omega = t(omega)/apply(omega,2,sum)   } else{ omega = matrix(c(0,1,1,0),2,2) }   dm = list() # list of dwell-time distributions   for(j in 1:N){ dm[[j]] = dpois(1:agsizes[j]-1, lambda[j]) } # shifted Poisson   Gamma = LaMa::tpm_hsmm2(omega, dm)   delta = LaMa::stationary(Gamma)   allprobs = matrix(1, length(x), N)   ind = which(!is.na(x))   for(j in 1:N){     allprobs[ind,j] = dnorm(x[ind], mu[j], sigma[j])   }   -LaMa::forward_s(delta, Gamma, allprobs, agsizes) }"},{"path":"https://janoleko.github.io/articles/HSMMs.html","id":"fitting-an-hsmm-as-an-approxiating-hmm-to-the-data","dir":"Articles","previous_headings":"Homogeneous HSMMs","what":"Fitting an HSMM (as an approxiating HMM) to the data","title":"Hidden semi-Markov models","text":"HSMMs rather slow (even using C++) translate additional model complexity higher computational overhead (31 states ).","code":"# intial values theta.star = c(10, 40, 100, log(c(5, 20, 50)), # state-dependent                log(c(7,4,4)), # dwell time means                rep(0, 3)) # omega  agsizes = qpois(0.95, lambda)+1  t1 = Sys.time() mod = nlm(mllk, theta.star, x = x, N = 3, agsizes = agsizes, stepmax = 2) Sys.time()-t1 #> Time difference of 2.256955 secs"},{"path":"https://janoleko.github.io/articles/HSMMs.html","id":"results","dir":"Articles","previous_headings":"Homogeneous HSMMs","what":"Results","title":"Hidden semi-Markov models","text":"","code":"N = 3 (mu = mod$estimate[1:N]) #> [1]  10.16569  39.06161 107.66034 (sigma = exp(mod$estimate[N+1:N])) #> [1]  4.78882 19.35639 48.56115 (lambda = exp(mod$estimate[2*N+1:N])) #> [1] 6.942983 4.595469 3.354765 omega = matrix(0,N,N) omega[!diag(N)] = as.vector(t(matrix(c(rep(1,N),                           exp(mod$estimate[3*N+1:(N*(N-2))])),N,N-1))) omega = t(omega)/apply(omega,2,sum) omega #>           [,1]      [,2]      [,3] #> [1,] 0.0000000 0.5541030 0.4458970 #> [2,] 0.5040937 0.0000000 0.4959063 #> [3,] 0.6654704 0.3345296 0.0000000"},{"path":"https://janoleko.github.io/articles/HSMMs.html","id":"real-data-application","dir":"Articles","previous_headings":"","what":"Real-data application","title":"Hidden semi-Markov models","text":"now want briefly show analysis real data set using hidden semi-Markov models. purpose use movement track Arctic muskox contained R package PHSMM. Originally data collected Beumer et al. (2020) already analyzed Pohle, Adam, Beumer (2022). data already preprossed, can immediately write negative log-likelihood function. modeling dwell-time distribution real processes, typically advisable use flexible distribution shifted Poisson distribution, latter account overdispersion. , employ shifted negative binomial distribution yields Poisson distribution special case dispersion parameter equal zero. state-dependent step lengths modeled gamma distributions, reparametrize gamma distribution terms mean standard deviation opposed shape scale better interpretability.","code":"# install.packages(\"PHSMM\") data = PHSMM::muskox[1:1000,] # only using first 1000 observations for speed head(data) #>                      date tday        x       y       step #> 88273 2013-10-11 22:00:00   15 513299.2 8264867  17.998874 #> 88274 2013-10-11 22:00:00   16 513283.4 8264875   8.214733 #> 88275 2013-10-11 22:00:00   17 513284.3 8264883   7.205098 #> 88276 2013-10-11 22:00:00   18 513280.4 8264877  53.378332 #> 88277 2013-10-11 22:00:00   19 513252.0 8264922 719.242687 #> 88278 2013-10-11 22:00:00   20 513386.7 8265629  10.797127 mllk_muskox = function(theta.star, step, N, agsizes){   # parameter transformation from working to natural   mu = exp(theta.star[1:N]) # step mean   sigma = exp(theta.star[N+1:N]) # step standard deviation   mu_dwell = exp(theta.star[2*N+1:N]) # dwell time mean   phi = exp(theta.star[3*N+1:N]) # dwell time dispersion   if(N>2){      # conditional transition probability matrix     omega = matrix(0,N,N)     omega[!diag(N)] = as.vector(t(matrix(c(rep(1,N),                           exp(theta.star[4*N+1:(N*(N-2))])),N,N-1)))     omega = t(omega)/apply(omega,2,sum)   } else{ omega = matrix(c(0,1,1,0),2,2) }   dm = list() # list of dwell-time distributions   for(j in 1:N){      # R allows to parametrize by mean and size where size = 1/dispersion     dm[[j]] = dnbinom(1:agsizes[j]-1, mu=mu_dwell[j], size=1/phi[j])    }   Gamma = LaMa::tpm_hsmm2(omega, dm)   delta = LaMa::stationary(Gamma)   allprobs = matrix(1, length(step), N)   ind = which(!is.na(step))   for(j in 1:N){     # we reparametrise the gamma distribution in terms of mean and sd     allprobs[ind,j] = dgamma(step[ind], shape = mu[j]^2 / sigma[j]^2,                               scale = sigma[j]^2 / mu[j])   }   -LaMa::forward_s(delta, Gamma, allprobs, agsizes) }"},{"path":"https://janoleko.github.io/articles/HSMMs.html","id":"fitting-an-hsmm-as-an-approxiating-hmm-to-the-muskox-data","dir":"Articles","previous_headings":"Real-data application","what":"Fitting an HSMM (as an approxiating HMM) to the muskox data","title":"Hidden semi-Markov models","text":"","code":"# intial values theta.star = c(log(c(4, 50, 300, 4, 50, 300)), # state-dependent mean and sd                log(c(3,3,5)), # dwell time means                log(c(0.01, 0.01, 0.01)), # dwell time dispersion                rep(0, 3)) # omega  agsizes = c(11,11,14)  t1 = Sys.time() mod_muskox = nlm(mllk_muskox, theta.star, step=data$step, N=3,                  agsizes=agsizes,iterlim = 500) Sys.time()-t1 #> Time difference of 6.272659 secs"},{"path":"https://janoleko.github.io/articles/HSMMs.html","id":"results-1","dir":"Articles","previous_headings":"Real-data application","what":"Results","title":"Hidden semi-Markov models","text":"retransform parameters interpretation case Poisson distribution suffficiently flexible, dispersion parameters estimated close zero. can easily visualize estimated state-specific dwell-time distributions:","code":"theta.star = mod_muskox$estimate; N = 3 (mu = exp(theta.star[1:N])) # step mean #> [1]   4.408113  55.515937 306.505015 (sigma = exp(theta.star[N+1:N])) # step standard deviation #> [1]   3.148133  50.337337 331.539159 (mu_dwell = exp(theta.star[2*N+1:N])) # dwell time mean #> [1] 2.544980 2.660321 5.541736 (phi = exp(theta.star[3*N+1:N])) # dwell time dispersion #> [1] 5.312503e-05 3.749293e-02 4.822955e-09 omega = matrix(0,N,N) omega[!diag(N)] = as.vector(t(matrix(c(rep(1,N),                         exp(theta.star[4*N+1:(N*(N-2))])),N,N-1))) omega = t(omega)/apply(omega,2,sum) omega #>           [,1]      [,2]         [,3] #> [1,] 0.0000000 0.6865898 3.134102e-01 #> [2,] 0.9999999 0.0000000 5.438672e-08 #> [3,] 0.8210731 0.1789269 0.000000e+00 oldpar = par(mfrow = c(1,3)) for(j in 1:N){   plot(1:agsizes[j], dnbinom(1:agsizes[j]-1, mu=mu_dwell[j], size = 1/phi[j]),        type = \"h\", lwd = 2, col = color[j], xlab = \"dwell time (hours)\",        ylab = \"probabilities\", main = paste(\"state\",j), bty = \"n\", ylim = c(0,0.25)) } par(oldpar)"},{"path":[]},{"path":"https://janoleko.github.io/articles/Inhomogeneous_HMMs.html","id":"covariate-effects-in-the-state-process","dir":"Articles","previous_headings":"","what":"Covariate effects in the state process","title":"Inhomogeneous HMMs","text":"covariates affect transition probabilities, implies model transition probability matrix function said covariates. Let ztz_t vector covariates length p+1p+1 t=1,…,Tt = 1, \\dots, T, first entry always equal 11 include intercept. Moreover, let βij\\beta_{ij} vector regression parameters, also length p+1p+1 -diagonal element (≠ji \\neq j) transition probability matrix. First, consider linear predictors ηij(t)=βij′zt, \\eta_{ij}^{(t)} = \\beta_{ij}^{'} z_t,  t=1,…,Tt = 1, \\dots, T. transition probabilities need lie interval (0,1)(0,1) row transition matrix needs sum one, obtain transition probabilities via inverse multinomial logistic link γij(t)=Pr(St=j∣St−1=)=exp(ηij(t))∑k=1Nexp(ηik(t)), \\gamma_{ij}^{(t)} = \\Pr(S_t = j \\mid S_{t-1} = ) = \\frac{\\exp(\\eta_{ij}^{(t)})}{\\sum_{k=1}^N \\exp(\\eta_{ik}^{(t)})},  ηii\\eta_{ii} set zero =1,…,Ni = 1, \\dots, N identifiability NN number hidden states. function tpm_g() conducts calculation elements t.p.m. time points efficiently C++. point want point definition transition probabilities necessarily unique. Indeed data points times 1,…,T1, \\dots, T need T−1T-1 transition probability matrices. definition means transition probability t−1t-1 tt depends covariate values time point tt, also defined γij(t)=Pr(St+1=j∣St=). \\gamma_{ij}^{(t)} = \\Pr(S_{t+1} = j \\mid S_t = ).  want point two specifications equivalent. HMMs established convention, choice needs made users can important exact timing covariate effect relevant. LaMa comes either passing design matrix excluding first last row tpm_g(), use first option vignette. forget exclude first last row design matrix calculating transition matrices, pass array dimension c(N,N,T) forward_g() likelihood evaluation, function revert first option just ignoring first slice array.","code":""},{"path":"https://janoleko.github.io/articles/Inhomogeneous_HMMs.html","id":"simulation-example","dir":"Articles","previous_headings":"Covariate effects in the state process","what":"Simulation example","title":"Inhomogeneous HMMs","text":"begin simulating data specified model, assuming 2 states Gaussian state-dependent distributions. covariate effects state process fully specified parameter matrix beta dimension c(N*(N-1), p+1). default function tpm_g() fill -diagonal elements transition matrix column, can changed setting byrow = TRUE. latter useful, popular HMM packages like moveHMM momentuHMM return parameter matrix t.p.m. needs filled row.  Let’s now simulate synthetic data specified model.","code":"# loading the package library(LaMa) #> Loading required package: RTMB # parameters mu = c(5, 20)   # state-dependent means sigma = c(4, 5) # state-dependent standard deviations  # state process regression parameters beta = matrix(c(-2, -2,       # intercepts                 -1, 0.5,      # linear effects                 0.25, -0.25), # quadratic effects               nrow = 2)  n = 1000 # number of observations set.seed(123) z = rnorm(n) # in practice there will be n covariate values. # However, we only have n-1 transitions, thererfore we only need n-1 values: Z = cbind(z, z^2) # quadratic effect of z Gamma = tpm_g(Z = Z[-1,], beta) # of dimension c(2, 2, n-1) delta = c(0.5, 0.5) # non-stationary initial distribution  color = c(\"orange\", \"deepskyblue\")  oldpar = par(mfrow = c(1,2)) zseq = seq(-2,2,by = 0.01) Gamma_seq = tpm_g(Z = cbind(zseq, zseq^2), beta) plot(zseq, Gamma_seq[1,2,], type = \"l\", lwd = 3, bty = \"n\", ylim = c(0,1),       xlab = \"z\", ylab = \"gamma_12\", col = color[1]) plot(zseq, Gamma_seq[2,1,], type = \"l\", lwd = 3, bty = \"n\", ylim = c(0,1),      xlab = \"z\", ylab = \"gamma_21\", col = color[2]) par(oldpar) s = rep(NA, n) s[1] = sample(1:2, 1, prob = delta) # sampling first state from initial distr. for(t in 2:n){   # sampling next state conditional on previous one with tpm at that time point   s[t] = sample(1:2, 1, prob = Gamma[s[t-1],,t-1]) } # sampling observations conditional on the states x = rnorm(n, mu[s], sigma[s])  plot(x[1:200], bty = \"n\", pch = 20, ylab = \"x\",       col = c(color[1], color[2])[s[1:200]])"},{"path":"https://janoleko.github.io/articles/Inhomogeneous_HMMs.html","id":"parametric-modeling-of-the-transition-probabilities","dir":"Articles","previous_headings":"Covariate effects in the state process","what":"Parametric modeling of the transition probabilities","title":"Inhomogeneous HMMs","text":"begin modeling transition probabilities parametrically, paramter intercept, linear effect quadratic effect -diagonal element t.p.m.","code":""},{"path":"https://janoleko.github.io/articles/Inhomogeneous_HMMs.html","id":"writing-the-negative-log-likelihood-function","dir":"Articles","previous_headings":"Covariate effects in the state process","what":"Writing the negative log-likelihood function","title":"Inhomogeneous HMMs","text":"specify likelihood function pretend know polynomial degree effect zz transition probabilities.","code":"nll = function(par, x, Z){   beta = matrix(par[1:6], nrow = 2) # matrix of coefficients   Gamma = tpm_g(Z[-1,], beta) # excluding the first covariate value -> n-1 tpms   delta = c(1, exp(par[7]))   delta = delta / sum(delta)   mu = par[8:9]   sigma = exp(par[10:11])   # calculate all state-dependent probabilities   allprobs = matrix(1, length(x), 2)   for(j in 1:2) allprobs[,j] = dnorm(x, mu[j], sigma[j])   # forward algorithm   -forward_g(delta, Gamma, allprobs) }"},{"path":"https://janoleko.github.io/articles/Inhomogeneous_HMMs.html","id":"fitting-an-hmm-to-the-data","dir":"Articles","previous_headings":"Covariate effects in the state process","what":"Fitting an HMM to the data","title":"Inhomogeneous HMMs","text":"Really fast!","code":"par = c(beta = c(-2, -2, rep(0,4)), # initialising with homogeneous tpm         logitdelta = 0, # starting value for initial distribution         mu = c(4, 14), # initial state-dependent means         sigma = c(log(3),log(5))) # initial state-dependents sds system.time(   mod <- nlm(nll, par, x = x, Z = Z)  ) #>    user  system elapsed  #>   3.273   0.012   0.835"},{"path":"https://janoleko.github.io/articles/Inhomogeneous_HMMs.html","id":"visualising-results","dir":"Articles","previous_headings":"Covariate effects in the state process","what":"Visualising results","title":"Inhomogeneous HMMs","text":", use tpm_g() stationary() tranform parameters.","code":"# transform parameters to working beta_hat = matrix(mod$estimate[1:6], nrow = 2) Gamma_hat = tpm_g(Z = Z[-1,], beta_hat) delta_hat = c(1, exp(mod$estimate[7])) delta_hat = delta_hat / sum(delta_hat) mu_hat = mod$estimate[8:9] sigma_hat = exp(mod$estimate[10:11])  # we calculate the average state distribution overall all covariate values zseq = seq(-2, 2, by = 0.01) Gamma_seq = tpm_g(Z = cbind(zseq, zseq^2), beta_hat) Prob = matrix(nrow = length(zseq), ncol = 2) for(i in 1:length(zseq)){ Prob[i,] = stationary(Gamma_seq[,,i]) } prob = apply(Prob, 2, mean)  hist(x, prob = TRUE, bor = \"white\", breaks = 20, main = \"\") curve(prob[1]*dnorm(x, mu_hat[1], sigma_hat[1]), add = TRUE, lwd = 3,        col = color[1], n=500) curve(prob[2]*dnorm(x, mu_hat[2], sigma_hat[2]), add = TRUE, lwd = 3,        col = color[2], n=500) curve(prob[1]*dnorm(x, mu_hat[1], sigma_hat[1])+         prob[2]*dnorm(x, mu[2], sigma_hat[2]),       add = TRUE, lwd = 3, lty = \"dashed\", n = 500) legend(\"topright\", col = c(color[1], color[2], \"black\"), lwd = 3, bty = \"n\",        lty = c(1,1,2), legend = c(\"state 1\", \"state 2\", \"marginal\")) oldpar = par(mfrow = c(1,2)) plot(zseq, Gamma_seq[1,2,], type = \"l\", lwd = 3, bty = \"n\", ylim = c(0,1),       xlab = \"z\", ylab = \"gamma_12_hat\", col = color[1]) plot(zseq, Gamma_seq[2,1,], type = \"l\", lwd = 3, bty = \"n\", ylim = c(0,1),      xlab = \"z\", ylab = \"gamma_21_hat\", col = color[2]) par(mfrow = c(1,1)) plot(zseq, Prob[,1], type = \"l\", lwd = 3, bty = \"n\", ylim = c(0,1), xlab = \"z\",       ylab = \"Pr(state 1)\", col = color[1]) par(oldpar)"},{"path":"https://janoleko.github.io/articles/Inhomogeneous_HMMs.html","id":"covariate-effects-in-the-state-dependent-process","dir":"Articles","previous_headings":"","what":"Covariate effects in the state-dependent process","title":"Inhomogeneous HMMs","text":"now look setting covariates influence mean state-dependent distribution, state switching controlled homogeneous Markov chain. often called Markov-switching regression. Assuming observation process conditionally normally distributed, means Xt∣St=j∼N(βj′zt,σj2),j=1,…,N. X_t \\mid S_t = j \\sim N(\\beta_j^{'} z_t, \\: \\sigma_j^2), \\quad j = 1, \\dots, N.","code":""},{"path":"https://janoleko.github.io/articles/Inhomogeneous_HMMs.html","id":"simulation-example-1","dir":"Articles","previous_headings":"Covariate effects in the state-dependent process","what":"Simulation example","title":"Inhomogeneous HMMs","text":"","code":"sigma = c(1, 1) # state-dependent standard deviations (homoscedasticity)  # parameter matrix # each row contains parameter vector for the corresponding state beta = matrix(c(8, 10,             # intercepts                 -2, 1, 0.5, -0.5), # slopes               nrow = 2) n = 1000 # number of observations set.seed(123) z = rnorm(n) Z = cbind(z, z^2) # quadratic effect of z  Gamma = matrix(c(0.9, 0.1, 0.05, 0.95),                 nrow = 2, byrow = TRUE) # homogeneous t.p.m. delta = stationary(Gamma) # stationary Markov chain"},{"path":"https://janoleko.github.io/articles/Inhomogeneous_HMMs.html","id":"simulation","dir":"Articles","previous_headings":"Covariate effects in the state-dependent process","what":"Simulation","title":"Inhomogeneous HMMs","text":"","code":"s = x = rep(NA, n) s[1] = sample(1:2, 1, prob = delta) x[1] = rnorm(1, beta[s[1],]%*%c(1, Z[1,]), # state-dependent regression                     sigma[s[1]]) for(t in 2:n){   s[t] = sample(1:2, 1, prob = Gamma[s[t-1],])   x[t] = rnorm(1, beta[s[t],]%*%c(1, Z[t,]), # state-dependent regression                       sigma[s[t]]) }  oldpar = par(mfrow = c(1,2)) plot(x[1:400], bty = \"n\", pch = 20, ylab = \"x\",       col = c(color[1], color[2])[s[1:400]])  plot(z[which(s==1)], x[which(s==1)], pch = 16, col = color[1], bty = \"n\",       ylim = c(0,15), xlab = \"z\", ylab = \"x\") points(z[which(s==2)], x[which(s==2)], pch = 16, col = color[2]) par(oldpar)"},{"path":"https://janoleko.github.io/articles/Inhomogeneous_HMMs.html","id":"writing-the-negative-log-likelihood-function-1","dir":"Articles","previous_headings":"Covariate effects in the state-dependent process","what":"Writing the negative log-likelihood function","title":"Inhomogeneous HMMs","text":"","code":"nllMSR = function(par, x, Z){   Gamma = tpm(par[1:2]) # homogeneous tpm   delta = stationary(Gamma) # stationary Markov chain   beta = matrix(par[2 + 1:(2 + 2*2)], nrow = 2) # parameter matrix   sigma = exp(par[2 + 2 + 2*2 + 1:2])   # calculate all state-dependent probabilities   allprobs = matrix(1, length(x), 2)   # state-dependent regression   for(j in 1:2) allprobs[,j] = dnorm(x, cbind(1,Z) %*% beta[j,], sigma[j])   # forward algorithm   -forward(delta, Gamma, allprobs) }"},{"path":"https://janoleko.github.io/articles/Inhomogeneous_HMMs.html","id":"fitting-a-markov-switching-regression-model","dir":"Articles","previous_headings":"Covariate effects in the state-dependent process","what":"Fitting a Markov-switching regression model","title":"Inhomogeneous HMMs","text":"","code":"par = c(logitgamma = c(-2, -3),      # starting values state process         beta = c(8, 10, rep(0,4)),   # starting values for regression         logsigma = c(log(1),log(1))) # starting values for sigma system.time(   mod_reg <- nlm(nllMSR, par, x = x, Z = Z) ) #>    user  system elapsed  #>   0.228   0.008   0.235"},{"path":"https://janoleko.github.io/articles/Inhomogeneous_HMMs.html","id":"visualizing-results","dir":"Articles","previous_headings":"Covariate effects in the state-dependent process","what":"Visualizing results","title":"Inhomogeneous HMMs","text":"","code":"Gamma_hat_reg = tpm(mod_reg$estimate[1:2]) # calculating all tpms delta_hat_reg = stationary(Gamma_hat_reg) beta_hat_reg = matrix(mod_reg$estimate[2+1:(2*2+2)], nrow = 2) sigma_hat_reg = exp(mod_reg$estimate[2+2*2+2 +1:2])  # we have some label switching plot(z, x, pch = 16, bty = \"n\", xlab = \"z\", ylab = \"x\", col = color[s]) points(z, x, pch = 20) curve(beta_hat_reg[1,1] + beta_hat_reg[1,2]*x + beta_hat_reg[1,3]*x^2,        add = TRUE, lwd = 4, col = color[2]) curve(beta_hat_reg[2,1] + beta_hat_reg[2,2]*x + beta_hat_reg[2,3]*x^2,        add = TRUE, lwd = 4, col = color[1])"},{"path":"https://janoleko.github.io/articles/Intro_to_LaMa.html","id":"introductory-example-homogeneous-hmm","dir":"Articles","previous_headings":"","what":"Introductory example: Homogeneous HMM","title":"Introduction to LaMa","text":"vignette, start simple HMM can think . basic NN-state HMM doubly stochastic process discrete time. Observations generated one NN possible distributions fj(xt)f_j(x_t), j=1,…Nj = 1, \\dots N unobserved NN-state Markov chain selecting distribution active given time point. Hence, HMMs can interpreted temporally dependent mixture models popular accross wide range disciplines like ecology, sports finance time-series data underlying sequential dependencies analysed. statements already hint two main assumptions model, namely f(st∣st−1,st−2,…,s1)=f(st∣st−1)f(s_t \\mid s_{t-1}, s_{t-2}, \\dots, s_1) = f(s_t \\mid s_{t-1}) (Markov assumption) f(xt∣x1,…,xt−1,xt−1,xT,s1,…,sT)=f(xt∣st)f(x_t \\mid x_1, \\dots, x_{t-1}, x_{t-1}, x_T, s_1, \\dots, s_T) = f(x_t \\mid s_t) (conditional independence assumption). hidden state process described Markov chain, stochastic process can easily characterised initial distribution δ(1)=(Pr(S1=1),…,Pr(S1=N))\\delta^{(1)} = (\\Pr(S_1 = 1), \\dots, \\Pr(S_1 = N)) one-step transition probabilities γij=Pr(St=j∣St−1=),,j=1,…,N\\gamma_{ij} = \\Pr(S_t = j \\mid S_{t-1} = ), \\quad ,j = 1, \\dotsc, N typically summarised -called transition probability matrix (t.p.m.) Γ=(γij),j=1,…,N\\Gamma = (\\gamma_{ij})_{,j = 1, \\dots, N} row ii conditional one-step ahead distribution state process given current state ii. matrix -conveniently parametrised unconstrained parameter vector N(N−1)N (N-1) -diagonal elements. row can computed via inverse multinomial logistic link (also known softmax). can done using function tpm(): HMMs homogeneous transition probabilities, often assume stationarity underlying Markov chain, well-behaved Markov chains converge unique stationary distribution. e.g. observe animial model behavioral states Markov chain, reasonable assume chain running long time prior observation thus already converged stationary distribution. distribution (call δ\\delta) can computed solving system equations δΓ=δ,s.t.∑j=1Nδj=1, \\delta \\Gamma = \\delta, \\quad \\text{s.t.} \\; \\sum_{j=1}^N \\delta_j = 1,  implemented function stationary(). stationary HMMs, replace initial distribution δ(1)\\delta^{(1)} stationary distribution. can easily compute stationary distribution associated t.p.m. using stationary distribution can interpreted log-run-time proportion time spent state. conditional distributions observations fj(xt)f_j(x_t), typical choice kind parametric family like normal gamma distributions state-specific means standard deviations. exhaustive description models see Zucchini, MacDonald, Langrock (2016).","code":"(Gamma = tpm(c(-2, -3))) # 2 states -> 2*(1-2) = 2 off-diagonal entries #>           [,1]       [,2] #> [1,] 0.9525741 0.04742587 #> [2,] 0.1192029 0.88079708 (delta = stationary(Gamma)) #>   state 1   state 2  #> 0.7153801 0.2846199"},{"path":"https://janoleko.github.io/articles/Intro_to_LaMa.html","id":"generating-data-from-a-2-state-hmm","dir":"Articles","previous_headings":"Introductory example: Homogeneous HMM","what":"Generating data from a 2-state HMM","title":"Introduction to LaMa","text":"start simulating data simple 2-state HMM Gaussian state-dependent distributions, get intuition. can use stationary() compute stationary distribution.","code":"# parameters mu = c(0, 6)    # state-dependent means sigma = c(2, 4) # state-dependent standard deviations Gamma = matrix(c(0.95, 0.05, 0.15, 0.85), # transition probability matrix                nrow = 2, byrow = TRUE) delta = stationary(Gamma) # stationary distribution  # simulation n = 1000 set.seed(123) s = rep(NA, n) s[1] = sample(1:2, 1, prob = delta) # sampling first state from delta for(t in 2:n){   # drawing the next state conditional on the last one   s[t] = sample(1:2, 1, prob = Gamma[s[t-1],])  } # drawing the observation conditional on the states x = rnorm(n, mu[s], sigma[s])  color = c(\"orange\", \"deepskyblue\") plot(x[1:200], bty = \"n\", pch = 20, ylab = \"x\",       col = color[s[1:200]])"},{"path":"https://janoleko.github.io/articles/Intro_to_LaMa.html","id":"inference-by-direct-numerical-maximum-likelihood-estimation","dir":"Articles","previous_headings":"Introductory example: Homogeneous HMM","what":"Inference by direct numerical maximum likelihood estimation","title":"Introduction to LaMa","text":"Inference HMMs difficult compared e.g. regression modelling observations independent. want estimate model parameters via maximum likelihood estimation, due nice properties possessed maximum likelihood estimator. However, computing HMM likelihood observed data points x1,…,xTx_1, \\dots, x_T non-trivial task observe underlying states. thus need sum possible state sequences infeasible general state processes. can, however, exploit Markov property thus calculate likelihood recursively matrix product using -called forward algorithm. closed form, HMM likelihood becomes L(θ)=δ(1)P(x1)ΓP(x2)Γ…ΓP(xT)1t, L(\\theta) = \\delta^{(1)} P(x_1) \\Gamma P(x_2) \\Gamma \\dots \\Gamma P(x_T) 1^t,  δ(1)\\delta^{(1)} Γ\\Gamma defined , P(xt)P(x_t) diagonal matrix state-dependent densities probability mass functions fj(xt)=f(xt∣St=j)f_j(x_t) = f(x_t \\mid S_t = j) diagonal 11 row vector ones length NN. model parameters summarised vector θ\\theta. able evaluate likelihood function, can numerically maximised popular optimisers like nlm() optim(). algorithm explained suffers numerical underflow TT moderately large likelihood rounded zero. Thus, one can use scaling strategy, detailed Zucchini, MacDonald, Langrock (2016), avoid calculate log-likelihood recursively. version forward algorithm implemented LaMa written C++. Additionally, HMMs often need constrain domains several model parameters θ\\theta (.e. positive standard deviations transition probability matrix elements 0 1 rows sum one). One now resort contrained numerical optimisation practice better option maximise likelihood w.r.t. transformed version (real number line) model parameters using suitable invertible differenentiable link functions (denoted par code). example use log-link parameters need strictly positive multinomial logistic link transition probability matrix. former can easily coded hand, latter implemented functions tpm family convenience computational speed. efficiency, also advisable evaluate state-dependent densities (probability mass functions) vectorised outside recursive forward algorithm. results matrix containing state-dependent likelihoods data point (rows), conditional state (columns), , throughout package, call allprobs matrix. example, within negative log-likelihood function build homogeneous transition probability matrix using tpm() function compute stationary distribution Markov chain using stationary(). build allprobs matrix calculate log-likelihood using forward() last line. returned negative function can numerically minimised e.g. nlm().","code":"nll = function(par, x){   # parameter transformations for unconstrained optimisation   Gamma = tpm(par[1:2]) # multinomial logistic link   delta = stationary(Gamma) # stationary initial distribution   mu = par[3:4] # no transformation needed   sigma = exp(par[5:6]) # strictly positive   # calculating all state-dependent probabilities outside the forward algorithm   allprobs = matrix(1, length(x), 2)   for(j in 1:2) allprobs[,j] = dnorm(x, mu[j], sigma[j])   # return negative for minimisation   -forward(delta, Gamma, allprobs) }"},{"path":"https://janoleko.github.io/articles/Intro_to_LaMa.html","id":"fitting-an-hmm-to-the-data","dir":"Articles","previous_headings":"Introductory example: Homogeneous HMM","what":"Fitting an HMM to the data","title":"Introduction to LaMa","text":"see implementation forward algorithm C++ leads really fast estimation speeds.","code":"par = c(logitGamma = qlogis(c(0.05, 0.05)),         mu = c(1,4),         logsigma = c(log(1),log(3))) # initial transformed parameters: not chosen too well system.time(   mod <- nlm(nll, par, x = x)  ) #>    user  system elapsed  #>   0.093   0.000   0.093"},{"path":"https://janoleko.github.io/articles/Intro_to_LaMa.html","id":"visualising-results","dir":"Articles","previous_headings":"Introductory example: Homogeneous HMM","what":"Visualising results","title":"Introduction to LaMa","text":"model estimation, need retransform unconstrained parameters according code inside likelihood:  can also decode probable state sequence viterbi() function, first computing allprobs matrix:","code":"# transform parameters to working Gamma = tpm(mod$estimate[1:2]) delta = stationary(Gamma) # stationary HMM mu = mod$estimate[3:4] sigma = exp(mod$estimate[5:6])  hist(x, prob = TRUE, bor = \"white\", breaks = 40, main = \"\") curve(delta[1]*dnorm(x, mu[1], sigma[1]), add = TRUE, lwd = 2, col = \"orange\", n=500) curve(delta[2]*dnorm(x, mu[2], sigma[2]), add = TRUE, lwd = 2, col = \"deepskyblue\", n=500) curve(delta[1]*dnorm(x, mu[1], sigma[1])+delta[2]*dnorm(x, mu[2], sigma[2]),       add = TRUE, lwd = 2, lty = \"dashed\", n=500) legend(\"topright\", col = c(color, \"black\"), lwd = 2, bty = \"n\",        lty = c(1,1,2), legend = c(\"state 1\", \"state 2\", \"marginal\")) allprobs = matrix(1, length(x), 2) for(j in 1:2) allprobs[,j] = dnorm(x, mu[j], sigma[j])  states = viterbi(delta, Gamma, allprobs)  plot(x, pch = 20, bty = \"n\", col = color[states]) legend(\"topright\", pch = 20, legend = c(\"state 1\", \"state 2\"),         col = color, box.lwd = 0)"},{"path":[]},{"path":"https://janoleko.github.io/articles/LaMa_and_RTMB.html","id":"basic-workflow","dir":"Articles","previous_headings":"","what":"Basic workflow","title":"LaMa and RTMB","text":"workflow RTMB basically always . need define negative log-likelihood function, create automatically differentiable objective function fit model numerical minimization latter. RTMB also provides many functions make process convenient.","code":""},{"path":"https://janoleko.github.io/articles/LaMa_and_RTMB.html","id":"simple-hmm","dir":"Articles","previous_headings":"","what":"Simple HMM","title":"LaMa and RTMB","text":"start fitting super simple stationary HMM state-dependent gamma distributions step lengths von Mises distributions turning angles. first step, define initial parameter list par dat list contains data potential hyperparamters – NN, number hidden states. names par dat course arbitrary. par named list initial parameter values, accessing parameters later much convenient indexing. can also use parameter vector RTMB, using named list makes life much easier. can now define negative log-likelihood function similar fashion basic numerical ML points made : prominently, negative log-likelihood function parameters estimated data parameters passed argument stage. something get used (know), just way RTMB works. getAll() function useful use first line unpack par dat list, making elements available without $ operator. stage, nll just takes dat object global environment. Parameter transformations course still necessary, .e. parameters par unconstrained. might wonder earth RTMB can calculate gradient parameters distributions like gamma von Mises distribution. answer : can’t provides version standard distributions like dnorm(), dbinom(), etc. case dgamma2() dvm() come LaMa non-standard, hood build RTMB functions (dgamma2() actually just convenience function reparametrizes gamma distribution terms mean standard deviation). Actually, standard functions (e.g. sum()), operators (e.g. %*%) methods (e.g. matrix) “overwritten” called inside MakeADFun() typically don’t notice care – magic works. REPORT() function offered RTMB really convenient quantities calculated likelihood function (written code anyway), reported, available optimization, report statements ignored optimization. annoying backtransformations anymore, wohoo! simple parameter transformations, ADREPORT() also great, calculates standard deviations ADREPORT()ed quantities, based delta method. Just note delta method advisable complex non-linear multivariate transformations. defined negative log-likelihood, can now create autmatically differentiable objective function fit model. needs little explanation: point, RTMB takes negative log-likelihood function generates version , including gradient. MakeADFun() now also grabs whatever saved dat global environment bakes objective function. Therefore, changes dat point effect optimization result. set silent = TRUE suppress printing optimization process. Let’s check obj: contains initial parameter par (now tranformed named vector), objective function fn (case just evaluates nll faster), gradient gr Hessian . now call functions without argument, get corresponding values initial parameter vector. now ready optimize objective function. optimization routine nlminb() robust conveniently allows us provide gradient function. Alternatively, can also use optim() optimizer like allows pass gradient function. Indeed, provide Hessian nlminb() evaluating Hessian fast RTMB, optimization still much faster use quasi-Newton algorithm approximates current Hessian based previous gradient evaluations, compared using full Newton-Raphson. can check estimated parameter function value Note naming determined nlminb(). use different optimizer, may called differently. Much nicer however, obj (yes obj opt) automatically updated optimization. Note calling obj$gr() optimization now gives gradient optimum, obj$fn() still gives objective starting value obj$par updated still initial parameter vector (kind confusing). get estimated parameters natural scale, don’t backtransformation manually. can just run reporting: works REPORT() statements likelihood function. Note delta, Gamma allprobs always reported default using forward() useful e.g. state decoding viterbi(), many downstream LaMa functions take arguments inputs. state-dependent parameters depend specific model formulation, need reported manually user specifying negative log-likelihood. parameters, can plot decoded time series  estimated state-dependent distributions.  Lastly, can also use sdreport() function directly give us standard errors unconstrained parameters everything ADREPORT()ed.  can get overview estimated parameters ADREPORT()ed quantities well standard errors get estimated parameters standard errors list format, type get estimates standard errors ADREPORT()ed quantities list format, type","code":"par = list(   logmu = log(c(0.3, 1)),      # initial means for step length (log-transformed)   logsigma = log(c(0.2, 0.7)), # initial sds for step length (log-transformed)   logkappa = log(c(0.2, 0.7)), # initial concentration for turning angle (log-transformed)   eta = rep(-2, 2)             # initial t.p.m. parameters (on logit scale)   )             dat = list(   step = elephant$step[1:5000], # only using a subset of the data for faster computation   angle = elephant$angle[1:5000],    N = 2   ) nll = function(par) {   getAll(par, dat) # makes everything contained available without $   Gamma = tpm(eta) # computes transition probability matrix from unconstrained eta   delta = stationary(Gamma) # computes stationary distribution   # exponentiating because all parameters strictly positive   mu = exp(logmu)   sigma = exp(logsigma)   kappa = exp(logkappa)   # reporting statements for later use   REPORT(mu); ADREPORT(mu)   REPORT(sigma); ADREPORT(sigma)   REPORT(kappa); ADREPORT(kappa)   # calculating all state-dependent densities   allprobs = matrix(1, nrow = length(step), ncol = N)   ind = which(!is.na(step) & !is.na(angle)) # only for non-NA obs.   for(j in 1:N){     allprobs[ind,j] = dgamma2(step[ind],mu[j],sigma[j])*dvm(angle[ind],0,kappa[j])   }   -forward(delta, Gamma, allprobs) # simple forward algorithm } obj = MakeADFun(nll, par, silent = TRUE) # creating the objective function names(obj) #>  [1] \"par\"      \"fn\"       \"gr\"       \"he\"       \"hessian\"  \"method\"   #>  [7] \"retape\"   \"env\"      \"report\"   \"simulate\" obj$par #>      logmu      logmu   logsigma   logsigma   logkappa   logkappa        eta  #> -1.2039728  0.0000000 -1.6094379 -0.3566749 -1.6094379 -0.3566749 -2.0000000  #>        eta  #> -2.0000000 obj$fn() #> [1] 16584.4 obj$gr() #>          [,1]     [,2]     [,3]      [,4]     [,5]      [,6]     [,7]      [,8] #> [1,] 230.5857 -1218.71 56.12643 -5906.308 30.71142 -408.9433 63.43363 -95.75145 opt = nlminb(obj$par, obj$fn, obj$gr) # optimization opt$par #>      logmu      logmu   logsigma   logsigma   logkappa   logkappa        eta  #> -1.1816492  0.9109406 -1.5899770  0.3893447 -2.5112980  0.4258548 -1.6174757  #>        eta  #> -1.5348844 opt$objective #> [1] 13617.45 mod = obj$report() # runs the reporting from the negative log-likelihood once (delta = mod$delta) #>   state 1   state 2  #> 0.4828971 0.5171029 (Gamma = mod$Gamma) #>           [,1]      [,2] #> [1,] 0.8227198 0.1772802 #> [2,] 0.1655533 0.8344467 (mu = mod$mu) #> [1] 0.3067724 2.4866604 (sigma = mod$sigma) #> [1] 0.2039303 1.4760132 (kappa = mod$kappa) #> [1] 0.08116282 1.53089842 mod$states = viterbi(mod$delta, mod$Gamma, mod$allprobs)  # defining color vector color = c(\"orange\", \"deepskyblue\")  plot(elephant$step[1:200], type = \"h\", xlab = \"time\", ylab = \"step length\",       col = color[mod$states[1:200]], bty = \"n\") legend(\"topright\", col = color, lwd = 1, legend = c(\"state 1\", \"state 2\"), bty = \"n\") oldpar = par(mfrow = c(1,2)) hist(elephant$step, prob = TRUE, breaks = 40,       bor = \"white\", main = \"\", xlab = \"step length\") for(j in 1:2) curve(delta[j] * dgamma2(x, mu[j], sigma[j]),                      lwd = 2, add = T, col = color[j]) curve(delta[1]*dgamma2(x, mu[1], sigma[1]) + delta[2]*dgamma2(x, mu[2], sigma[2]),        lwd = 2, lty = 2, add = T) legend(\"top\", lwd = 2, col = color, legend = c(\"state 1\", \"state 2\"), bty = \"n\")  hist(elephant$angle, prob = TRUE, breaks = 40,       bor = \"white\", main = \"\", xlab = \"turning angle\") for(j in 1:2) curve(delta[j] * dvm(x, 0, kappa[j]),                      lwd = 2, add = T, col = color[j]) curve(delta[1]*dvm(x, 0, kappa[1]) + delta[2]*dvm(x, 0, kappa[2]),        lwd = 2, lty = 2, add = T) par(oldpar) # resetting to default sdr = sdreport(obj) summary(sdr) #>             Estimate  Std. Error #> logmu    -1.18164921 0.015816840 #> logmu     0.91094060 0.012568349 #> logsigma -1.58997698 0.023262636 #> logsigma  0.38934467 0.018793398 #> logkappa -2.51129801 0.366127132 #> logkappa  0.42585477 0.027176879 #> eta      -1.61747569 0.058270035 #> eta      -1.53488440 0.056943182 #> mu        0.30677239 0.004852170 #> mu        2.48666039 0.031253215 #> sigma     0.20393031 0.004743956 #> sigma     1.47601320 0.027739303 #> kappa     0.08116282 0.029715911 #> kappa     1.53089842 0.041605041 # estimated parameter in list format as.list(sdr, \"Estimate\") # parameter standard errors in list format as.list(sdr, \"Std\") # adreported parameters as list as.list(sdr, \"Estimate\", report = TRUE) # their standard errors as.list(sdr, \"Std\", report = TRUE)"},{"path":"https://janoleko.github.io/articles/LaMa_and_RTMB.html","id":"covariate-effects","dir":"Articles","previous_headings":"","what":"Covariate effects","title":"LaMa and RTMB","text":"Generalizing covariate effects also straightforward. example, can add time day variation state process. case want obtain state process model form logit(γij(t))=β0(ij)+β1(ij)sin(2πt24)+β2(ij)cos(2πt24)+β3(ij)sin(2πt12)+β4(ij)cos(2πt12), \\text{logit}(\\gamma_{ij}^{(t)}) = \\beta_0^{(ij)} + \\beta_1^{(ij)} \\sin \\bigl(\\frac{2 \\pi t}{24}\\bigr) + \\beta_2^{(ij)} \\cos \\bigl(\\frac{2 \\pi t}{24}\\bigr) + \\beta_3^{(ij)} \\sin \\bigl(\\frac{2 \\pi t}{12}\\bigr) + \\beta_4^{(ij)} \\cos \\bigl(\\frac{2 \\pi t}{12}\\bigr),  tt time day. compute trigonometric basis design matrix Z corresponding predictor add time day dat list. LaMa function trigBasisExp() conveniently. also need change parameter list par include regression parameters time day. regression parameters state process typically form N(N−1)×p+1N (N-1) \\times p+1 matrix, NN number states pp number regressors – format also expected tpm_g() computes array transition matrices based design parameter matrix. Another lovely convenience RTMB allows , parameter list, can matrices, making reshaping vectors matrices inside likelihood function unnessesary. can now define general likelihood function main difference use tpm_g() instead tpm() inclusion time day transition matrix calculation. leads us using stationary_p() instead stationary() calculate initial distribuion forward_g() instead forward() calculate log-likelihood. done , model fit essentially : can look reported results. case, simplicity get standard errors Gamma delta method , general, advisable.","code":"# building trigonometric basis desing matrix (in this case no intercept column) Z = trigBasisExp(1:24, degree = 2) # convenience function from LaMa # only compute the 24 unique values and index later for entire time series dat$Z = Z # adding design matrix to dat dat$tod = elephant$tod # adding time of day to dat for indexing par = list(logmu = log(c(0.3, 1)),             logsigma = log(c(0.2, 0.7)),            logkappa = log(c(0.2, 0.7)),            beta = matrix(c(rep(-2, 2),                             rep(0, 2*ncol(Z))), nrow = 2)) # 2 times 4+1 matrix # replacing eta with regression parameter matrix, initializing slopes at zero nll2 = function(par) {   getAll(par, dat) # makes everything contained available without $   Gamma = tpm_g(Z, beta) # covariate-dependent tpms (in this case only 24 unique)   # tpm_g() automatically checks if intercept column is included   ADREPORT(Gamma) # adreporting   Delta = stationary_p(Gamma) # periodically stationary distribution   ADREPORT(Delta)   delta = Delta[tod[1],] # initial periodically stationary distribution   # exponentiating because all parameters strictly positive   mu = exp(logmu); REPORT(mu)   sigma = exp(logsigma); REPORT(sigma)   kappa = exp(logkappa); REPORT(kappa)   # calculating all state-dependent densities   allprobs = matrix(1, nrow = length(step), ncol = N)   ind = which(!is.na(step) & !is.na(angle)) # only for non-NA obs.   for(j in 1:N){     allprobs[ind,j] = dgamma2(step[ind],mu[j],sigma[j])*dvm(angle[ind],0,kappa[j])   }   -forward_g(delta, Gamma[,,tod], allprobs) # indexing 24 unique tpms by tod in data } obj2 = MakeADFun(nll2, par, silent = TRUE) # creating the objective function opt2 = nlminb(obj2$par, obj2$fn, obj2$gr) # optimization mod2 = obj2$report()  sdr = sdreport(obj2) Gamma = as.list(sdr, \"Estimate\", report = TRUE)$Gamma Gammasd = as.list(sdr, \"Std\", report = TRUE)$Gamma  Delta = as.list(sdr, \"Estimate\", report = TRUE)$Delta Deltasd = as.list(sdr, \"Std\", report = TRUE)$Delta  tod_seq = seq(0, 24, length = 200) # sequence for plotting Z_pred = trigBasisExp(tod_seq, degree = 2) # design matrix for prediction  Gamma_plot = tpm_g(Z_pred, mod2$beta) # interpolating transition probs  plot(tod_seq, Gamma_plot[1,2,], type = \"l\", lwd = 2, ylim = c(0,1),      xlab = \"time of day\", ylab = \"transition probability\", bty = \"n\") segments(x0 = 1:24, y0 = Gamma[1,2,]-1.96*Gammasd[1,2,],           y1 = Gamma[1,2,]+1.96*Gammasd[1,2,]) segments(x0 = 1:24, y0 = Gamma[2,1,]-1.96*Gammasd[2,1,],           y1 = Gamma[2,1,]+1.96*Gammasd[2,1,]) lines(tod_seq, Gamma_plot[2,1,], lwd = 2, lty = 3) legend(\"topleft\", lwd = 2, lty = c(1,3), bty = \"n\",        legend = c(expression(gamma[12]^(t)), expression(gamma[21]^(t)))) plot(Delta[,2], type = \"b\", lwd = 2, xlab = \"time of day\", ylab = \"Pr(active)\",       col = \"deepskyblue\", bty = \"n\", xaxt = \"n\") segments(x0 = 1:24, y0 = Delta[,2]-1.96*Deltasd[,2], lwd = 2,          y1 = Delta[,2]+1.96*Deltasd[,2], col = \"deepskyblue\") axis(1, at = seq(0,24,by=4), labels = seq(0,24,by=4))"},{"path":"https://janoleko.github.io/articles/LaMa_and_RTMB.html","id":"penalized-splines","dir":"Articles","previous_headings":"","what":"Penalized splines","title":"LaMa and RTMB","text":"can go one step model transition probabilities smooth functions time day using cyclic P-splines, .e. logit(γij(t))=β0(ij)+sij(t), \\text{logit}(\\gamma_{ij}^{(t)}) = \\beta_0^{(ij)} + s_{ij}(t),  sij(t)s_{ij}(t) smooth periodic function time day. LaMa provides function make_matrices() creates design penalty matrices based R package mgcv provided formula data. Hence, can use standard mgcv syntax create matrices cyclic P-splines (cp). append dat list. change likelihood function slightly adding penalization. use penalty() function contained LaMa computes sum quadratic form penalties (standard penalty used penalized splines) based penalty matrices, parameters estimated penalty strength parameters. Importantly, now separate non-penalized intercept beta0 penalized spline coefficients now called betaspline. latter, conveniently initialize matrix, row representing coefficient vector one -diagonal element t.p.m. also append lambda argument dat list, initial penalty strength parameter vector. case length two coefficient matrix two rows. model fit can conducted using qreml() function contained LaMa. qREML stands quasi restricted maximum likelihood finds good penalty strength treating spline coefficients random effects. hood, qreml() also constructs AD function RTMB uses qREML algorithm described Koslik (2024) fit model. tell qreml() function parameters spline coefficients providing name corresponding list element par. rules follow using qreml(): likelihood function needs RTMB-compatible, .e. structure likelihood functions vignette – importantly, function parameter list. penalty strength vector lambda needs length correspond total number spline coefficient vectors used. case, number rows betaspline, additionally different spline coefficient parameter list (may different length different penalty matrix), needed elements lambda. penalty() function can called likelihood. several spline coefficients penalized, penalty() expects list coefficient matrices vectors list penalty matrices. summarise multiple spline coefficients matrix parameter list – useful lengths penalty matrix – matrix must arranged row, .e. row one spline coefficient vector. arranged column, qreml() fail. mod object now list contains everything reported likelihood function, also RTMB object created process. fitting model, can also use LaMa function pred_matrix(), takes modmat object created earlier, build new interpolating design matrix using exact basis expansion specified . allows us plot estimated transition probabilities smooth function time day – now ignore confidence bands due laziness.   see allowing flexible relationship, estimated time day effect becomes stronger even sharper peaks concluded using trigonometric approach.","code":"modmat = make_matrices(~ s(tod, bs = \"cp\"),                         data = data.frame(tod = 1:24),                        knots = list(tod = c(0,24))) # where to wrap the cyclic basis Z = modmat$Z # spline design matrix S = modmat$S # penalty matrix dat$Z = Z dat$S = S[[1]] # mgcv returns a list of penalty matrices (even if only one smooth) pnll = function(par) {   getAll(par, dat) # makes everything contained available without $   Gamma = tpm_g(Z, cbind(beta0, betaspline)); ADREPORT(Gamma)   Delta = stationary_p(Gamma); ADREPORT(Delta)   delta = Delta[tod[1],]   # exponentiating because all parameters strictly positive   mu = exp(logmu); REPORT(mu)   sigma = exp(logsigma); REPORT(sigma)   kappa = exp(logkappa); REPORT(kappa)   # calculating all state-dependent densities   allprobs = matrix(1, nrow = length(step), ncol = N)   ind = which(!is.na(step) & !is.na(angle)) # only for non-NA obs.   for(j in 1:N){     allprobs[ind,j] = dgamma2(step[ind],mu[j],sigma[j])*dvm(angle[ind],0,kappa[j])   }   -forward_g(delta, Gamma[,,tod], allprobs) +     penalty(betaspline, S, lambda) # this does all the penalization work } par = list(logmu = log(c(0.3, 2.5)),             logsigma = log(c(0.2, 1.5)),            logkappa = log(c(0.2, 1.5)),            beta0 = c(-2, 2), # intercept now separated!            betaspline = matrix(rep(0, 2*(ncol(Z)-1)), nrow = 2))  dat$lambda = rep(100, 2) # adding initial penalty strength to the dat list system.time(   mod3 <- qreml(pnll, par, dat, random = \"betaspline\") ) #> Creating AD function #> Initializing with lambda: 100 100  #> outer 1 - lambda: 5.844 3.811  #> outer 2 - lambda: 0.781 0.969  #> outer 3 - lambda: 0.289 0.363  #> outer 4 - lambda: 0.205 0.179  #> outer 5 - lambda: 0.184 0.115  #> outer 6 - lambda: 0.178 0.092  #> outer 7 - lambda: 0.176 0.083  #> outer 8 - lambda: 0.175 0.079  #> outer 9 - lambda: 0.175 0.078  #> outer 10 - lambda: 0.175 0.078  #> outer 11 - lambda: 0.175 0.078  #> outer 12 - lambda: 0.175 0.078  #> Converged #>    user  system elapsed  #>   5.043   0.108   5.042 sdr = sdreport(mod3$obj) Gamma = as.list(sdr, \"Estimate\", report = TRUE)$Gamma Delta = as.list(sdr, \"Estimate\", report = TRUE)$Delta  tod_seq = seq(0,24, length=200) Z_pred = pred_matrix(modmat, data.frame(tod = tod_seq))  Gamma_plot = tpm_g(Z_pred, mod3$beta) # interpolating transition probs  plot(tod_seq, Gamma_plot[1,2,], type = \"l\", lwd = 2, ylim = c(0,1),      xlab = \"time of day\", ylab = \"transition probability\", bty = \"n\") lines(tod_seq, Gamma_plot[2,1,], lwd = 2, lty = 3) legend(\"topleft\", lwd = 2, lty = c(1,3), bty = \"n\",        legend = c(expression(gamma[12]^(t)), expression(gamma[21]^(t)))) plot(Delta[,2], type = \"b\", lwd = 2, xlab = \"time of day\", ylab = \"Pr(active)\",       col = \"deepskyblue\", bty = \"n\", xaxt = \"n\") axis(1, at = seq(0,24,by=4), labels = seq(0,24,by=4))"},{"path":"https://janoleko.github.io/articles/LaMa_and_RTMB.html","id":"full-laplace-method","dir":"Articles","previous_headings":"","what":"Full Laplace method","title":"LaMa and RTMB","text":"Lastly, achieved similar fit using slightly accurate full Laplace approximation method, can used fit models via marginal maximum likelihood estimation integrating random effects. natively supported RTMB – actually one core selling points – standard way can now deal kinds random effects. Indeed, qREML algorithm treats spline coefficients Gaussian random effects exploits relatively simple structure yiedling efficient fitting method. full Laplace method much general, allowing flexible random effects, , estimation slower exploit simple structure splines treated random effects. alter likelihood function slightly, Laplace method, need implement joint likelihood data random effect, latter multivariate normal distribution. Specifically, bb random effect spline, b∼N(0,λ−1S−)b \\sim N(0, \\lambda^{-1} S^-). likelihood data given bb (just regular likelihoot treats bb parameter) f(x∣b)f(x \\mid b) density bb fλ(b)f_{\\lambda}(b). Hence joint likelihood can computed f(x,b)=f(x∣b)fλ(b) f(x, b) = f(x \\mid b) f_{\\lambda}(b)  joint negative log-likelihood becomes −logf(x∣b)−logfλ(b)- \\log f(x \\mid b) - \\log f_{\\lambda}(b) implement . conveniently done using dgmrf2() function included LaMa provides density function multivariate normal distribution reparametrized terms (scaled) precision matrix, .e. inverse covariance matrix, case λiS\\lambda_i S spline ii. allows evaluating multiple points , one possibly penalty strength parameter lambda. differs RTMB’s dgmrf() expecting sparse precision matrix robust rank-deficient penalty matrices, typical penalized splines. also include log penalty strength parameter now. create objective function, need tell RTMB betaspline random effect integrated objective function marginal likelihood f(x)=∫f(x,b)db, f(x) = \\int f(x, b) \\,db,  actually negative log course. general algorithm takes ten times model long fit model. Hence, code evaluated. results however similar.","code":"jnll = function(par) {   getAll(par, dat) # makes everything contained available without $   Gamma = tpm_g(Z, cbind(beta0, betaspline)); ADREPORT(Gamma)   Delta = stationary_p(Gamma); ADREPORT(Delta)   delta = Delta[tod[1],]   # exponentiating because all parameters strictly positive   mu = exp(logmu); REPORT(mu)   sigma = exp(logsigma); REPORT(sigma)   kappa = exp(logkappa); REPORT(kappa)   # calculating all state-dependent densities   allprobs = matrix(1, nrow = length(step), ncol = N)   ind = which(!is.na(step) & !is.na(angle)) # only for non-NA obs.   for(j in 1:N){     allprobs[ind,j] = dgamma2(step[ind],mu[j],sigma[j])*dvm(angle[ind],0,kappa[j])   }   -forward_g(delta, Gamma[,,tod], allprobs) -     sum(dgmrf2(betaspline, 0, S, exp(loglambda), log = TRUE)) # just like any other density in R } par$loglambda = log(rep(100, 2)) obj4 = MakeADFun(jnll, par, random = \"betaspline\", silent = TRUE) system.time(   opt4 <- nlminb(obj4$par, obj4$fn, obj4$gr) )"},{"path":"https://janoleko.github.io/articles/LaMa_and_RTMB.html","id":"common-issues-with-rtmb","dir":"Articles","previous_headings":"","what":"Common issues with RTMB","title":"LaMa and RTMB","text":"problems RTMB one keep mind. can bit annoying, opinion benefits automatic differentiation far outweigh drawbacks. list main ones encountered , please tell encounter , can added. typical issue RTMB operators might need overloaded allow automatic differentiation done default. typical model setups LaMa functions , go individualistic route get error like might overload operator . put first line likelihood function. error still prevails also add hopefully fix error. Another common problem occurs initiating objects NA values trying fill numeric values. NA logical screws automatic differentiation due mismatching types. avoid , always initiate numeric NaN values. example, don’t rather avoid error. Furthermore, unfortunate side effects R’s ‘byte compiler’ (enabled default R). encounter error matching previous ones, try disabling byte compiler see error resolved. minor things: ’re used expm::expm() won’t work AD. Use Matrix::expm() instead. CircStats::dvm() also isn’t compatible AD. Use LaMa::dvm() instead. can use statements likelihood function, parameter obviously differentiable. standard distributions available RTMB. need non-standard one, try implementing density function using plain R code. RTMB also provides AD versions many building-block functions (like Gamma Bessel function) might help . information RTMB, check documentation TMB users Google group.","code":"stop(\"Invalid argument to 'advector' (lost class attribute?)\") \"[<-\" <- ADoverload(\"[<-\") \"c\" <- ADoverload(\"c\") \"diag<-\" <- ADoverload(\"diag<-\") X = array(dim = c(1,2,3)) # which is the same as X = array(NA, dim = c(1,2,3)) X = array(NaN, dim = c(1,2,3)) # or X = array(0, dim = c(1,2,3)) compiler::enableJIT(0) #> [1] 3"},{"path":[]},{"path":"https://janoleko.github.io/articles/Longitudinal_data.html","id":"generating-data","dir":"Articles","previous_headings":"Complete pooling","what":"Generating data","title":"Longitudinal data","text":"generate KK separate tracks, exact model:","code":"# loading the package library(\"LaMa\") #> Loading required package: RTMB # parameters are shared across individuals mu = c(15, 60) sigma = c(10, 40) Gamma = matrix(c(0.95, 0.05, 0.15, 0.85), nrow = 2, byrow = TRUE) delta = stationary(Gamma) # stationary HMM  # simulation of all tracks set.seed(123) K = 200 # number of individuals, for example different animals n = 50 # observations per animal only (but many animals)  s = x = rep(NA, n*K) for(k in 1:K){   sk = xk = rep(NA, n)   sk[1] = sample(1:2, 1, prob = delta)   xk[1] = rnorm(1, mu[sk[1]], sigma[sk[1]])   for(t in 2:n){     sk[t] = sample(1:2, 1, prob = Gamma[sk[t-1],])      xk[t] = rnorm(1, mu[sk[t]], sigma[sk[t]])   }   s[(k-1)*n + 1:n] = sk   x[(k-1)*n + 1:n] = xk }  trackID = rep(1:K, each = n)"},{"path":"https://janoleko.github.io/articles/Longitudinal_data.html","id":"writing-the-negative-log-likelihood-function","dir":"Articles","previous_headings":"Complete pooling","what":"Writing the negative log-likelihood function","title":"Longitudinal data","text":"calculate joint log-likelihood independent tracks, slightly modify standard negative log-likelihood function adding additional argument trackInd. vector containing indices new track begins. forward() now calculates sum indivual likelihood contributions, starting respective initial distribution (pool ).","code":"# fast version using trackInd in forward() mllk_pool = function(theta.star, x, trackID){   Gamma = tpm(theta.star[1:2])   delta = stationary(Gamma)   mu = theta.star[3:4]   sigma = exp(theta.star[5:6])   allprobs = matrix(1, length(x), 2)   for(j in 1:2){ allprobs[,j] = dnorm(x, mu[j], sigma[j]) }      # here we add trackInd as an argument to forward()   -forward(delta, Gamma, allprobs, trackID) }  # slow alternative looping over individuals in R mllk_pool_slow = function(theta.star, x, K){   n = length(x) / K   Gamma = tpm(theta.star[1:2])   delta = stationary(Gamma)   mu = theta.star[3:4]   sigma = exp(theta.star[5:6])   allprobs = matrix(1, length(x), 2)   for(j in 1:2){ allprobs[,j] = dnorm(x, mu[j], sigma[j]) }      # here we just loop over individuals in R   l = 0   for(k in 1:K){     l = l + forward(delta, Gamma, allprobs[(k-1)*n + 1:n,])   }   -l }"},{"path":"https://janoleko.github.io/articles/Longitudinal_data.html","id":"estimating-the-model","dir":"Articles","previous_headings":"Complete pooling","what":"Estimating the model","title":"Longitudinal data","text":"Now estimate model complete pooling. compare fast version using forward() trackID slow version also using forward() looping individuals R. example, looping individuals R doubles evaluation time, can much severe complicated models.","code":"# initial parameter vector theta.star = c(-1,-1, # off-diagonals of Gamma (on logit scale)                15,60,log(10),log(40)) # mu and sigma  # fast version: s = Sys.time() mod = nlm(mllk_pool, theta.star, x = x, trackID = trackID) Sys.time()-s #> Time difference of 0.4710402 secs  # slow version s = Sys.time() mod = nlm(mllk_pool_slow, theta.star, x = x, K = K) Sys.time()-s #> Time difference of 1.995578 secs"},{"path":"https://janoleko.github.io/articles/Longitudinal_data.html","id":"partial-pooling","dir":"Articles","previous_headings":"","what":"Partial pooling","title":"Longitudinal data","text":"parameters model individual-specific, rest shared, speak partial pooling. demonstrate 5 individuals transition probability matrices. estimate separate transition probability matrix individual, opt parsimonious approach, transition probabilities depend external, individual-specific covariate. estimate effect covariate transition probabilities.","code":""},{"path":"https://janoleko.github.io/articles/Longitudinal_data.html","id":"generating-data-1","dir":"Articles","previous_headings":"Partial pooling","what":"Generating data","title":"Longitudinal data","text":"","code":"K = 5 # number of individuals, for example different animals  # state-dependent parameters are shared across individuals mu = c(15, 60) sigma = c(10, 40)  # but we define a tpm for each individual depending on covariates set.seed(123) z = rnorm(K) # covariate (e.g. age) beta = matrix(c(-2,-2, 1, -1), nrow = 2) # we calculate 5 tpms depending on individual-specific covariates: Gamma = tpm_g(z, beta) # each individual starts in its stationary distribution: Delta = matrix(NA, K, 2) for(k in 1:K){ Delta[k,] = stationary(Gamma[,,k]) }  # simulation of all tracks set.seed(123) n = 200 # observations per animal only (but many animals) s = x = rep(NA, n*K) for(k in 1:K){   sk = xk = rep(NA, n)   sk[1] = sample(1:2, 1, prob = Delta[k, ])   xk[1] = rnorm(1, mu[sk[1]], sigma[sk[1]])   for(t in 2:n){     sk[t] = sample(1:2, 1, prob = Gamma[sk[t-1],,k])      xk[t] = rnorm(1, mu[sk[t]], sigma[sk[t]])   }   s[(k-1)*n + 1:n] = sk   x[(k-1)*n + 1:n] = xk }"},{"path":"https://janoleko.github.io/articles/Longitudinal_data.html","id":"writing-the-negative-log-likelihood-function-1","dir":"Articles","previous_headings":"Partial pooling","what":"Writing the negative log-likelihood function","title":"Longitudinal data","text":"Now write corresponding negative log-likehood function incorporates structure:","code":"# fast version using trackInd in forward() mllk_partial = function(theta.star, x, z, trackID){   # individual-specific tpms   beta = matrix(theta.star[1:4], nrow = 2)   Gamma = tpm_g(z, beta)   Delta = matrix(NA, length(z), 2)   for(k in 1:length(z)) Delta[k,] = stationary(Gamma[,,k])   mu = theta.star[5:6]   sigma = exp(theta.star[7:8])   allprobs = matrix(1, length(x), 2)   for(j in 1:2){ allprobs[,j] = dnorm(x, mu[j], sigma[j]) }      # just handing a Delta matrix and Gamma array for all individuals to forward()   -forward(Delta, Gamma, allprobs, trackID) }"},{"path":"https://janoleko.github.io/articles/Longitudinal_data.html","id":"estimating-the-model-1","dir":"Articles","previous_headings":"Partial pooling","what":"Estimating the model","title":"Longitudinal data","text":"","code":"# again defining all the indices where a new track begins trackID = rep(1:K, each = n)  # initial parameter vector theta.star = c(-2,-2,0,0, # beta                15,60,log(10),log(40)) # mu and sigma  s = Sys.time() mod_partial = nlm(mllk_partial, theta.star, x = x, z = z, trackID = trackID) Sys.time()-s #> Time difference of 0.376333 secs"},{"path":"https://janoleko.github.io/articles/MMMPPs.html","id":"example-1-markov-modulated-poisson-processes","dir":"Articles","previous_headings":"","what":"Example 1: Markov-modulated Poisson processes","title":"Markov-modulated (marked) Poisson processes","text":"","code":"# loading the package library(\"LaMa\") #> Loading required package: RTMB"},{"path":"https://janoleko.github.io/articles/MMMPPs.html","id":"setting-parameters","dir":"Articles","previous_headings":"Example 1: Markov-modulated Poisson processes","what":"Setting parameters","title":"Markov-modulated (marked) Poisson processes","text":"choose considerably higher rate shorter stays underlying Markov chain state 2, .e. state 2 bursty.","code":"# state-dependent rates lambda = c(2, 15) # generator matrix of the underlying Markov chain Q = matrix(c(-0.5,0.5,2,-2), nrow = 2, byrow = TRUE)"},{"path":"https://janoleko.github.io/articles/MMMPPs.html","id":"simulating-an-mmpp","dir":"Articles","previous_headings":"Example 1: Markov-modulated Poisson processes","what":"Simulating an MMPP","title":"Markov-modulated (marked) Poisson processes","text":"Let’s visualize simulated MMPP makes MMPP special compared regular Poisson point process burstiness Markov chain second state.","code":"set.seed(123)  k = 200 # number of state switches trans_times = s = rep(NA, k) # time points where the chain transitions s[1] = sample(1:2, 1) # initial distribuion c(0.5, 0.5) # exponentially distributed waiting times trans_times[1] = rexp(1, -Q[s[1],s[1]]) # in a fixed interval, the number of arrivals is Pois(lambda * interval_length) n_arrivals = rpois(1, lambda[s[1]]*trans_times[1])  # arrival times within fixed interval are uniformly distributed arrival_times = runif(n_arrivals, 0, trans_times[1]) for(t in 2:k){   s[t] = c(1,2)[-s[t-1]] # for 2-states, always a state swith when transitioning   # exponentially distributed waiting times   trans_times[t] = trans_times[t-1] + rexp(1, -Q[s[t], s[t]])   # in a fixed interval, the number of arrivals is Pois(lambda * interval_length)   n_arrivals = rpois(1, lambda[s[t]]*(trans_times[t]-trans_times[t-1]))   # arrival times within fixed interval are uniformly distributed   arrival_times = c(arrival_times,                      runif(n_arrivals, trans_times[t-1], trans_times[t])) } arrival_times = sort(arrival_times) n = length(arrival_times) color = c(\"orange\", \"deepskyblue\") plot(arrival_times[1:100], rep(0.5,100), type = \"h\", bty = \"n\", ylim = c(0,1),       yaxt = \"n\", xlab = \"arrival times\", ylab = \"\") segments(x0 = c(0,trans_times[1:98]), x1 = trans_times[1:99],           y0 = rep(0,100), y1 = rep(0,100), col = color[s[1:99]], lwd = 4) legend(\"top\", lwd = 2, col = color, legend = c(\"state 1\", \"state 2\"), box.lwd = 0)"},{"path":"https://janoleko.github.io/articles/MMMPPs.html","id":"writing-the-negative-log-likelihood-function","dir":"Articles","previous_headings":"Example 1: Markov-modulated Poisson processes","what":"Writing the negative log-likelihood function","title":"Markov-modulated (marked) Poisson processes","text":"likelihood stationary MMPP waiting times x1,…,xnx_1, \\dots, x_n (Meier-Hellstern (1987), Langrock, Borchers, Skaug (2013)) L(θ)=δ(∏=1nexp((Q−Λ)xi)Λ)1, L(\\theta) = \\delta \\bigl(\\prod_{=1}^n \\exp((Q-\\Lambda)x_i)\\Lambda\\bigr)1,  QQ generator matrix continuous-time Markov chain, Λ\\Lambda diagonal matrix state-dependent Poisson intensities, δ\\delta stationary distribution continuous-time Markov chain, 11 column vector ones. details continuous-time Markov chains, see vignette continuous-time HMMs also Dobrow (2016). can easily calculate log expression using standard implementation general forward algorithm forward_g() choosing first matrix state-dependent densities identity (.e.) first row allprobs matrix one matrices state-dependent density matrices Λ\\Lambda.","code":"mllk = function(theta.star, timediff, N=2){   lambda = exp(theta.star[1:N]) # state specific rates   Q = diag(N) # generator matrix   Q[!Q] = exp(theta.star[N+1:(N*(N-1))])   diag(Q) = 0   diag(Q) = -rowSums(Q)   Qube = tpm_cont(Q-diag(lambda), timediff) # exp((Q-Lambda)*deltat)   allprobs = matrix(lambda, nrow = length(timediff+1), ncol = N, byrow = T)   allprobs[1,] = 1   delta = solve(t(Q+1), rep(1,N))   -LaMa::forward_g(delta, Qube, allprobs) }"},{"path":"https://janoleko.github.io/articles/MMMPPs.html","id":"fitting-an-mmpp-to-the-data","dir":"Articles","previous_headings":"Example 1: Markov-modulated Poisson processes","what":"Fitting an MMPP to the data","title":"Markov-modulated (marked) Poisson processes","text":"","code":"theta.star = log(c(2, 15, # lambda                    2, 0.5)) # off-diagonals of Q  timediff = diff(arrival_times)  t1 = Sys.time() mod = nlm(mllk, theta.star, timediff=timediff, stepmax = 10) # we often need the stepmax, as the matrix exponential can be numerically unstable Sys.time()-t1 #> Time difference of 0.2689133 secs"},{"path":"https://janoleko.github.io/articles/MMMPPs.html","id":"results","dir":"Articles","previous_headings":"Example 1: Markov-modulated Poisson processes","what":"Results","title":"Markov-modulated (marked) Poisson processes","text":"","code":"exp(mod$estimate) #> [1]  1.9496892 15.0831216  1.8998849  0.4003955"},{"path":"https://janoleko.github.io/articles/MMMPPs.html","id":"example-2-markov-modulated-marked-poisson-processes","dir":"Articles","previous_headings":"","what":"Example 2: Markov-modulated marked Poisson processes","title":"Markov-modulated (marked) Poisson processes","text":"processes can also carry additional information, called marks, every arrival time also observe realization different random variable depends underlying states continuous-time Markov chain. example patient arrivals hospital observe biomarker every arrival time. Information underlying health status present , arrival times (sick patients visit often) biomarkers.","code":"# state-dependent rates lambda = c(1, 5, 20) # generator matrix of the underlying Markov chain Q = matrix(c(-0.5,0.3,0.2,              0.7, -1, 0.3,              1 ,1,-2), nrow = 3, byrow = TRUE) # parmeters for distributions of state-dependent marks # (here normally distributed) mu = c(-5, 0, 5) sigma = c(2, 1, 2)  color = c(\"orange\", \"deepskyblue\", \"seagreen2\") curve(dnorm(x, 0, 1), xlim = c(-10,10), bty = \"n\", lwd = 2, col = color[2],        n = 200, ylab = \"density\", xlab = \"mark\") curve(dnorm(x, -5, 2), add = TRUE, lwd = 2, col = color[1], n = 200) curve(dnorm(x, 5, 2), add = TRUE, lwd = 2, col = color[3], n = 200)"},{"path":"https://janoleko.github.io/articles/MMMPPs.html","id":"simulating-an-mmmpp","dir":"Articles","previous_headings":"Example 2: Markov-modulated marked Poisson processes","what":"Simulating an MMMPP","title":"Markov-modulated (marked) Poisson processes","text":"now show simulate MMMPP additionally generalize two hidden states. Let’s visualize simulated MMMPP","code":"set.seed(123) k = 200 # number of state switches trans_times = s = rep(NA, k) # time points where the chain transitions s[1] = sample(1:3, 1) # initial distribuion uniformly # exponentially distributed waiting times trans_times[1] = rexp(1, -Q[s[1],s[1]]) # in a fixed interval, the number of arrivals is Pois(lambda * interval_length) n_arrivals = rpois(1, lambda[s[1]]*trans_times[1])  # arrival times within fixed interval are uniformly distributed arrival_times = runif(n_arrivals, 0, trans_times[1]) # marks are iid in interval, given underlying state marks = rnorm(n_arrivals, mu[s[1]], sigma[s[1]])  for(t in 2:k){   # off-diagonal elements of the s[t-1] row of Q divided by the diagonal element   # give the probabilites of the next state   s[t] = sample(c(1:3)[-s[t-1]], 1, prob = Q[s[t-1],-s[t-1]]/-Q[s[t-1],s[t-1]])   # exponentially distributed waiting times   trans_times[t] = trans_times[t-1] + rexp(1, -Q[s[t],s[t]])   # in a fixed interval, the number of arrivals is Pois(lambda * interval_length)   n_arrivals = rpois(1, lambda[s[t]]*(trans_times[t]-trans_times[t-1]))   # arrival times within fixed interval are uniformly distributed   arrival_times = c(arrival_times,                      runif(n_arrivals, trans_times[t-1], trans_times[t]))   # marks are iid in interval, given underlying state   marks = c(marks, rnorm(n_arrivals, mu[s[t]], sigma[s[t]])) } arrival_times = sort(arrival_times) n = length(arrival_times) plot(arrival_times[1:100], marks[1:100], pch = 16, bty = \"n\",       ylim = c(-9,9), xlab = \"arrival times\", ylab = \"marks\") segments(x0 = c(0,trans_times[1:98]), x1 = trans_times[1:99],           y0 = rep(-9,100), y1 = rep(-9,100), col = color[s[1:99]], lwd = 4) legend(\"topright\", lwd = 2, col = color,         legend = c(\"state 1\", \"state 2\", \"state 3\"), box.lwd = 0)"},{"path":"https://janoleko.github.io/articles/MMMPPs.html","id":"writing-the-negative-log-likelihood-function-1","dir":"Articles","previous_headings":"Example 2: Markov-modulated marked Poisson processes","what":"Writing the negative log-likelihood function","title":"Markov-modulated (marked) Poisson processes","text":"likelihood stationary MMMPP waiting times x1,…,xnx_1, \\dots, x_n marks y0,y1,…,yny_0, y_1, \\dotsc, y_n changes slightly MMPP likelihood, include matrix state-specific densities (Lu (2012), Mews et al. (2023)): L(θ)=δP(y0)(∏=1nexp((Q−Λ)xi)ΛP(yi))1, L(\\theta) = \\delta P(y_0) \\bigl(\\prod_{=1}^n \\exp((Q-\\Lambda) x_i)\\Lambda P(y_i) \\bigr)1,  QQ, Λ\\Lambda δ\\delta P(yi)P(y_i) diagonal matrix state-dependent densites observation time tit_i. can easily calculate log expression using standard implementation general forward algorithm forward_g() first calculating allprobs matrix state-dependent densities marks (usual HMMs) multiplying row except first one element-wise state-dependent rates.","code":"mllk = function(theta.star, y, timediff, N){   lambda = exp(theta.star[1:N]) # state specific rates   mu = theta.star[N+1:N]   sigma = exp(theta.star[2*N+1:N])   Q = diag(N) # generator matrix   Q[!Q] = exp(theta.star[3*N+1:(N*(N-1))])   diag(Q) = 0   diag(Q) = -rowSums(Q)   delta = solve(t(Q+1), rep(1,N))   Qube = tpm_cont(Q-diag(lambda), timediff) # exp((Q-Lambda)*deltat)   allprobs = matrix(1, length(y), N)   for(j in 1:N){     allprobs[,j] = dnorm(y, mu[j], sigma[j])   }   allprobs[-1,] = allprobs[-1,] * matrix(lambda, length(y)-1, N, byrow = T)   -forward_g(delta, Qube, allprobs) }"},{"path":"https://janoleko.github.io/articles/MMMPPs.html","id":"fitting-an-mmpp-to-the-data-1","dir":"Articles","previous_headings":"Example 2: Markov-modulated marked Poisson processes","what":"Fitting an MMPP to the data","title":"Markov-modulated (marked) Poisson processes","text":"","code":"theta.star = c(log(c(1, 5, 20)), # lambda                    -5, 0, 5, # mu                log(c(2, 1, 2)), # sigma                log(c(0.7, 1, 0.3, 1, 0.2, 0.3))) # Q timediff = diff(arrival_times) t1 = Sys.time() mod2 = nlm(mllk, theta.star, y = marks, timediff=timediff, N=3, stepmax = 5) Sys.time()-t1 #> Time difference of 2.323014 secs"},{"path":"https://janoleko.github.io/articles/MMMPPs.html","id":"results-1","dir":"Articles","previous_headings":"Example 2: Markov-modulated marked Poisson processes","what":"Results","title":"Markov-modulated (marked) Poisson processes","text":"","code":"N = 3 round(exp(mod2$estimate[1:N]),2) #> [1]  0.96  4.86 19.50 # mu round(mod2$estimate[N+1:N], 2) #> [1] -5.19 -0.09  4.81 # sigma round(exp(mod2$estimate[2*N+1:N]), 2) #> [1] 1.79 0.96 2.01 Q = diag(N) Q[!Q] = exp(mod2$estimate[3*N+1:(N*(N-1))]) diag(Q) = 0 diag(Q) = -rowSums(Q) round(Q, 3) #>        [,1]   [,2]   [,3] #> [1,] -0.591  0.279  0.312 #> [2,]  0.926 -1.180  0.254 #> [3,]  1.193  1.210 -2.403"},{"path":[]},{"path":"https://janoleko.github.io/articles/Periodic_HMM.html","id":"setting-parameters-for-simulation","dir":"Articles","previous_headings":"","what":"Setting parameters for simulation","title":"Periodic HMMs","text":"choose bimodal activity pattern . can conveniently calculate transition probability matrices periodically stationary distributions using tpm_p() stationary_p().","code":"# loading the package library(\"LaMa\") #> Loading required package: RTMB # parameters mu = c(4, 14) sigma = c(3, 5)  L = 48 # half-hourly data: 48 observations per day beta = matrix(c(-1, 1, -1, -1, 1,                 -2, -1, 2, 2, -2), nrow = 2, byrow = TRUE) Gamma = tpm_p(seq(1, 48, by = 1), L, beta, degree = 2) Delta = stationary_p(Gamma)  # having a look at the periodically stationary distribution color = c(\"orange\", \"deepskyblue\") plot(Delta[,1], type = \"l\", lwd = 3, col = color[1], bty = \"n\",       xlab = \"time of day\", ylab = \"Pr(state 1)\") points(Delta[,1], pch = 19, col = color[1]) # only plotting one state, as the other probability is just 1-delta"},{"path":"https://janoleko.github.io/articles/Periodic_HMM.html","id":"simulating-data","dir":"Articles","previous_headings":"","what":"Simulating data","title":"Periodic HMMs","text":"","code":"# simulation z = rep(1:48, 50) # time of day variable, 50 days n = length(z) set.seed(123) s = x = rep(NA, n) s[1] = sample(1:2, 1, prob = Delta[z[1],]) x[1] = stats::rnorm(1, mu[s[1]], sigma[s[1]]) for(t in 2:n){   s[t] = sample(1:2, 1, prob = Gamma[s[t-1],,z[t]])   x[t] = rnorm(1, mu[s[t]], sigma[s[t]]) }  oldpar = par(mfrow = c(1,2)) plot(x[1:400], bty = \"n\", pch = 20, ylab = \"x\",       col = c(color[1], color[2])[s[1:400]]) boxplot(x ~ z, xlab = \"time of day\") # we see a periodic pattern in the data par(oldpar)"},{"path":[]},{"path":"https://janoleko.github.io/articles/Periodic_HMM.html","id":"writing-the-negative-log-likelihood-function","dir":"Articles","previous_headings":"Trigonometric modeling of the transition probalities","what":"Writing the negative log-likelihood function","title":"Periodic HMMs","text":"specify likelihood function pretend know degree trigonometric link , practice, never case. use tpm_p() compute periodically stationary start using stationary_p() additional argument specifies time point compute.","code":"mllk = function(theta.star, x, z){   beta = matrix(theta.star[1:10], nrow = 2) # matrix of coefficients   Gamma = tpm_p(tod = 1:48, L = 48, beta = beta, degree = 2) # calculating all L tpms   delta = stationary_p(Gamma, t = z[1]) # periodically stationary start   mu = theta.star[11:12]   sigma = exp(theta.star[13:14])   # calculate all state-dependent probabilities   allprobs = matrix(1, length(x), 2)   for(j in 1:2){ allprobs[,j] = stats::dnorm(x, mu[j], sigma[j]) }   # return negative for minimization   -forward_p(delta, Gamma, allprobs, z) }"},{"path":"https://janoleko.github.io/articles/Periodic_HMM.html","id":"fitting-an-hmm-to-the-data","dir":"Articles","previous_headings":"Trigonometric modeling of the transition probalities","what":"Fitting an HMM to the data","title":"Periodic HMMs","text":"","code":"theta.star = c(-1,-2, rep(0, 8), # starting values state process                4, 14 ,log(3),log(5)) # starting values state-dependent process s = Sys.time() mod = nlm(mllk, theta.star, x = x, z = z) Sys.time()-s #> Time difference of 0.5123947 secs"},{"path":"https://janoleko.github.io/articles/Periodic_HMM.html","id":"visualizing-results","dir":"Articles","previous_headings":"Trigonometric modeling of the transition probalities","what":"Visualizing results","title":"Periodic HMMs","text":", use tpm_p() stationary_p() tranform parameters.","code":"# transform parameters to working beta_hat = matrix(mod$estimate[1:10], nrow = 2) Gamma_hat = tpm_p(tod = 1:48, L = 48, beta = beta_hat, degree = 2) Delta_hat = stationary_p(Gamma_hat) mu_hat = mod$estimate[11:12] sigma_hat = exp(mod$estimate[13:14])  delta_hat = apply(Delta_hat, 2, mean)  oldpar = par(mfrow = c(1,2)) hist(x, prob = TRUE, bor = \"white\", breaks = 40, main = \"\") curve(delta_hat[1]*dnorm(x, mu_hat[1], sigma_hat[1]), add = TRUE, lwd = 2,        col = color[1], n=500) curve(delta_hat[2]*dnorm(x, mu_hat[2], sigma_hat[2]), add = TRUE, lwd = 2,        col = color[2], n=500) curve(delta_hat[1]*dnorm(x, mu_hat[1], sigma_hat[1])+         delta_hat[2]*dnorm(x, mu[2], sigma_hat[2]),       add = TRUE, lwd = 2, lty = \"dashed\", n = 500) legend(\"topright\", col = c(color[1], color[2], \"black\"), lwd = 2, bty = \"n\",        lty = c(1,1,2), legend = c(\"state 1\", \"state 2\", \"marginal\"))  plot(Delta_hat[,1], type = \"l\", lwd = 3, col = color[1], bty = \"n\",       xlab = \"time of day\", ylab = \"Pr(state 1)\") points(Delta_hat[,1], pch = 19, col = color[1]) par(oldpar)"},{"path":"https://janoleko.github.io/articles/Periodic_HMM.html","id":"non-parametric-modeling-of-the-transition-probalities","dir":"Articles","previous_headings":"","what":"Non-parametric modeling of the transition probalities","title":"Periodic HMMs","text":"Lcpp also makes non-parametric modeling trivially easy. model transition probabilities using cyclic P-splines similar Feldmann et al. (2023). first calculating design matrix using mgcv can easily handled tpm_p().","code":""},{"path":"https://janoleko.github.io/articles/Periodic_HMM.html","id":"building-the-cyclic-spline-design-matrix","dir":"Articles","previous_headings":"Non-parametric modeling of the transition probalities","what":"Building the cyclic spline design matrix","title":"Periodic HMMs","text":"","code":"nk = 8 # number of basis functions tod = 1:48 L = 48 k = L * 0:nk / nk # equidistant knots Z = mgcv::cSplineDes(tod, k) ## cyclic spline design matrix  # plotting the B-Spline basis functions plot(Z[,1], type = \"l\", lwd = 2, col = 1, bty = \"n\",      xlab = \"time of day\", ylab = \"basis functions\", ylim = c(0,0.8)) for(i in 2:nk){   lines(Z[,i], lwd = 2, col = i) }"},{"path":"https://janoleko.github.io/articles/Periodic_HMM.html","id":"writing-the-negative-log-likelihood-function-1","dir":"Articles","previous_headings":"Non-parametric modeling of the transition probalities","what":"Writing the negative log-likelihood function","title":"Periodic HMMs","text":"need make small changes likelihood function. importantly use tpm_p() additional argument Z, allows using bespoke design matrix. general, penalty curvature also added, done last lines.","code":"mllk_np = function(theta.star, x, z, Z, lambda){   beta = matrix(theta.star[1:(2+2*nk)], nrow = 2) # nk params per off-diagonal element   Gamma = tpm_p(tod = 1:48, L = 48, beta = beta, Z = Z) # calculating all L tpms   delta = stationary_p(Gamma, t = z[1]) # periodically stationary HMM   mu = theta.star[2+2*nk + 1:2]   sigma = exp(theta.star[2+2*nk + 2 + 1:2])   # calculate all state-dependent probabilities   allprobs = matrix(1, length(x), 2)   for(j in 1:2){ allprobs[,j] = stats::dnorm(x, mu[j], sigma[j]) }   # return negative for minimization   l = forward_p(delta, Gamma, allprobs, z)   # penalize curvature   penalty = sum(diff(beta[1,-1], differences = 2)^2)+     sum(diff(beta[2,-1], differences = 2)^2)   return(-l + lambda*penalty) }"},{"path":"https://janoleko.github.io/articles/Periodic_HMM.html","id":"fitting-a-non-parametric-hmm","dir":"Articles","previous_headings":"Non-parametric modeling of the transition probalities","what":"Fitting a non-parametric HMM","title":"Periodic HMMs","text":"model fit still quite fast non-parametric modeling.","code":"theta.star = c(-1,-2, rep(0, 2*nk), # starting values state process                4, 14 ,log(3),log(5)) # starting values state-dependent process s = Sys.time() mod_np = nlm(mllk_np, theta.star, x = x, z = z, Z = Z, lambda = 0) # in this case we don't seem to need a lot of penalization Sys.time()-s #> Time difference of 1.369772 secs"},{"path":"https://janoleko.github.io/articles/Periodic_HMM.html","id":"visualizing-results-1","dir":"Articles","previous_headings":"Non-parametric modeling of the transition probalities","what":"Visualizing results","title":"Periodic HMMs","text":", use tpm_p() stationary_p() tranform unconstraint parameters working parameters.","code":"# transform parameters to working beta_hat_np = matrix(mod_np$estimate[1:(2+2*nk)], nrow = 2) Gamma_hat_np = tpm_p(tod = 1:48, L = 48, beta = beta_hat_np, Z = Z) Delta_hat_np = stationary_p(Gamma_hat_np)  # comparing the two fits plot(Delta_hat_np[,1], type = \"l\", lwd = 3, col = \"purple\", bty = \"n\",       xlab = \"time of day\", ylab = \"Pr(state 1)\") # parametric fit lines(Delta_hat[,1], lwd = 3, col = color[1])"},{"path":[]},{"path":"https://janoleko.github.io/articles/State_space_models.html","id":"simulating-data-from-the-stochastic-volatility-model","dir":"Articles","previous_headings":"","what":"Simulating data from the stochastic volatility model","title":"State space models","text":"start simulating data specified model:","code":"# loading the package library(\"LaMa\") #> Loading required package: RTMB beta = 2 # baseline standard deviation phi = 0.95 # AR parameter sigma = 0.5 # variability of the AR process  n = 1000 set.seed(123) g = y = rep(NA, n) g[1] = rnorm(1, 0, sigma / sqrt(1-phi^2)) # stationary distribution of AR process y[1] = stats::rnorm(1, 0, beta*exp(g[1]/2))  # conditional distribution of y_1 given underlying volatility for(t in 2:n){   g[t] = rnorm(1, phi*g[t-1] , sigma) # transition density   y[t] = stats::rnorm(1, 0, beta*exp(g[t]/2))    # conditional distribution of y_t given underlying volatility }  # share returns oldpar = par(mar = c(5,4,3,4.5)+0.1) plot(y, type = \"l\", bty = \"n\", ylim = c(-40,20), yaxt = \"n\") # true underlying standard deviation lines(beta*exp(g)/7 - 40, col = \"deepskyblue\", lwd = 2) axis(side=2, at = seq(-20,20,by=5), labels = seq(-20,20,by=5)) axis(side=4, at = seq(0,150,by=75)/7-40, labels = seq(0,150,by=75)) mtext(\"standard deviation\", side=4, line=3, at = -30) par(oldpar)"},{"path":"https://janoleko.github.io/articles/State_space_models.html","id":"writing-the-negative-log-likelihood-function","dir":"Articles","previous_headings":"","what":"Writing the negative log-likelihood function","title":"State space models","text":"likelihood formulation corresponds fine discretization continuous state space intervals b width h midpoints bstar.","code":"mllk = function(theta.star, y, bm, m){   phi = plogis(theta.star[1])   sigma = exp(theta.star[2])   beta = exp(theta.star[3])   b = seq(-bm, bm, length = m+1) # intervals for midpoint quadrature   h = b[2]-b[1] # interval width   bstar = (b[-1] + b[-(m+1)])/2 # interval midpoints   # approximation resulting from midpoint quadrature   Gamma = sapply(bstar, dnorm, mean = phi*bstar, sd = sigma) * h   delta = h * dnorm(bstar, 0, sigma/sqrt(1-phi^2)) # stationary distribution   # approximating state-dependent density based on midpoints   allprobs = t(sapply(y, dnorm, mean = 0, sd = beta * exp(bstar/2)))   # return negative for minimization   -forward(delta, Gamma, allprobs) }"},{"path":"https://janoleko.github.io/articles/State_space_models.html","id":"fitting-an-ssm-to-the-data","dir":"Articles","previous_headings":"","what":"Fitting an SSM to the data","title":"State space models","text":"","code":"theta.star = c(qlogis(0.95), log(0.3), log(1)) bm = 5 # relevant range of underlying volatility (-5,5) m = 50 # number of approximating states  t1 = Sys.time() mod = stats::nlm(mllk, theta.star, y = y, bm = bm, m = m) Sys.time()-t1 #> Time difference of 0.5249267 secs"},{"path":"https://janoleko.github.io/articles/State_space_models.html","id":"results","dir":"Articles","previous_headings":"","what":"Results","title":"State space models","text":"","code":"# parameter estimates (phi = plogis(mod$estimate[1])) #> [1] 0.9305832 (sigma = exp(mod$estimate[2])) #> [1] 0.4796626 (beta = exp(mod$estimate[3])) #> [1] 2.507883  # decoding states b = seq(-bm, bm, length = m+1) # intervals for midpoint quadrature h = b[2]-b[1] # interval width bstar = (b[-1] + b[-(m+1)])/2 # interval midpoints Gamma = sapply(bstar, dnorm, mean = phi*bstar, sd = sigma) * h Gamma = Gamma / rowSums(Gamma) # normalizing out approximation errors delta = h * dnorm(bstar, 0, sigma/sqrt(1-phi^2)) # stationary distribution # approximating state-dependent density based on midpoints allprobs = t(sapply(y, dnorm, mean = 0, sd = beta * exp(bstar/2)))  probs = stateprobs(delta, Gamma, allprobs) states = viterbi(delta, Gamma, allprobs)  oldpar = par(mar = c(5,4,3,4.5)+0.1) plot(y, type = \"l\", bty = \"n\", ylim = c(-50,20), yaxt = \"n\") # when there are so many states it is not too sensable to only plot the most probable state, # as its probability might still be very small. Generally, we are approximating continuous  # distributions, thus it makes sense to plot the entire conditional distribution. maxprobs = apply(probs, 1, max) for(t in 1:1000){   colend = round((probs[t,]/(maxprobs[t]*5))*100)   colend[which(colend<10)] = paste0(\"0\", colend[which(colend<10)])   points(rep(t, m), bstar*4-35, col = paste0(\"#FFA200\",colend), pch = 20) } # we can add the viterbi decoded volatility levels as a \"mean\" lines(bstar[states]*4-35)  axis(side=2, at = seq(-20,20,by=5), labels = seq(-20,20,by=5)) axis(side=4, at = seq(-5,5, by = 5)*4-35, labels = seq(-5,5, by = 5)) mtext(\"g\", side=4, line=3, at = -30) par(oldpar)"},{"path":[]},{"path":"https://janoleko.github.io/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Jan-Ole Koslik. Author, maintainer.","code":""},{"path":"https://janoleko.github.io/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Koslik J (2024). LaMa: Fast Numerical Maximum Likelihood Estimation Latent Markov Models. R package version 2.0.0, https://github.com/janoleko/LaMa, https://janoleko.github.io/software/.","code":"@Manual{,   title = {LaMa: Fast Numerical Maximum Likelihood Estimation for Latent Markov Models},   author = {Jan-Ole Koslik},   year = {2024},   note = {R package version 2.0.0, https://github.com/janoleko/LaMa},   url = {https://janoleko.github.io/software/}, }"},{"path":"https://janoleko.github.io/index.html","id":"lama-","dir":"","previous_headings":"","what":"Fast Numerical Maximum Likelihood Estimation for Latent Markov Models","title":"Fast Numerical Maximum Likelihood Estimation for Latent Markov Models","text":"variety latent Markov models (Mews, Koslik, Langrock 2024), including hidden Markov models (HMMs), hidden semi-Markov models (HSMMs), state space models (SSMs) continuous-time variants can formulated estimated within framework via directly maximizing (approximate) likelihood using -called forward algorithm (details see Zucchini et al. 2016). Applied researchers often need custom models standard software easily support. Writing tailored R code offers flexibility suffers slow estimation speeds. R package solves issues providing easy--use functions (written C++ speed) common tasks like forward algorithm. functions can combined custom models, offering 10-20 times faster estimation via standard numerical optimizers. development version now also allows automatic differentiation RTMB package drastically increases speed accuracy. important families functions forward family calculates log-likelihood various different models, tpm family calculating transition probability matrices, stationary family compute stationary periodically stationary distributions well stateprobs viterbi family local global decoding.","code":""},{"path":"https://janoleko.github.io/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Fast Numerical Maximum Likelihood Estimation for Latent Markov Models","text":"can install released package version CRAN : development version Github:","code":"install.packages(\"LaMa\") # install.packages(\"devtools\") devtools::install_github(\"janoleko/LaMa\")"},{"path":"https://janoleko.github.io/index.html","id":"package-documentation","dir":"","previous_headings":"","what":"Package documentation","title":"Fast Numerical Maximum Likelihood Estimation for Latent Markov Models","text":"aid building fully custom likelihood functions, package contains several vignettes demonstrate simulate data estimate wide range models using functions included package: Introduction LaMa Inhomogeneous HMMs covariate effects Longitudinal data Periodic HMMs State space models Continuous-time HMMs Hidden semi-Markov models Markov-modulated (marked) Poisson processes LaMa RTMB","code":""},{"path":"https://janoleko.github.io/index.html","id":"introductory-example-homogeneous-hmm","dir":"","previous_headings":"","what":"Introductory example: Homogeneous HMM","title":"Fast Numerical Maximum Likelihood Estimation for Latent Markov Models","text":"analyze elephant data set contained package using simple 2-state HMM state-dependent gamma distributions. fit model hourly step lengths. start defining negative log-likelihood function. made really convenient functions tpm() computes transition probability matrix via multinomial logit link, stationary() computes stationary distribution Markov chain forward() calculates log-likelihood via forward algorithm. fit model, define intial parameter vector numerically optimize function using nlm(): Really fast 10.000 data points! tranforming unconstrained parameters working parameters using tpm() stationary(), can visualize results:","code":"library(LaMa) #> Loading required package: RTMB  head(elephant, 3) #>   tod      step     angle state #> 1   9 0.3252437        NA     1 #> 2  10 0.2458265  2.234562     1 #> 3  11 0.2173252 -2.262418     1 nll = function(par, step){   # parameter transformations for unconstraint optimization   Gamma = tpm(par[1:2]) # multinomial logit link   delta = stationary(Gamma) # stationary HMM   mu = exp(par[3:4])   sigma = exp(par[5:6])   # calculate all state-dependent probabilities   allprobs = matrix(1, length(step), 2)   ind = which(!is.na(step))   for(j in 1:2) allprobs[ind,j] = dgamma2(step[ind], mu[j], sigma[j])   # simple forward algorithm to calculate log-likelihood   -forward(delta, Gamma, allprobs) } par = c(-2,-2,             # initial tpm params (logit-scale)         log(c(0.3, 2.5)),    # initial means for step length (log-transformed)         log(c(0.2, 1.5)))  # initial sds for step length (log-transformed)  system.time(   mod <- nlm(nll, par, step = elephant$step) ) #>    user  system elapsed  #>   0.365   0.008   0.375 # transform parameters to working Gamma = tpm(mod$estimate[1:2]) delta = stationary(Gamma) # stationary HMM mu = exp(mod$estimate[3:4]) sigma = exp(mod$estimate[5:6])  hist(elephant$step, prob = TRUE, bor = \"white\", breaks = 40, main = \"\", xlab = \"step length\") curve(delta[1] * dgamma2(x, mu[1], sigma[1]), add = TRUE, lwd = 2, col = \"orange\", n=500) curve(delta[2] * dgamma2(x, mu[2], sigma[2]), add = TRUE, lwd = 2, col = \"deepskyblue\", n=500) legend(\"topright\", col = c(\"orange\", \"deepskyblue\"), lwd = 2, bty = \"n\", legend = c(\"state 1\", \"state 2\"))"},{"path":"https://janoleko.github.io/reference/LaMa-package.html","id":null,"dir":"Reference","previous_headings":"","what":"LaMa: Fast Numerical Maximum Likelihood Estimation for Latent Markov Models — LaMa-package","title":"LaMa: Fast Numerical Maximum Likelihood Estimation for Latent Markov Models — LaMa-package","text":"class latent Markov models, including hidden Markov models, hidden semi-Markov models, state space models, point processes, popular powerful framework inference time series driven latent processes. Furthermore, models can fitted using direct numerical maximum likelihood estimation using -called forward algorithm discussed Zucchini et al. (2016) doi:10.1201/b20790 . However, due great flexibility, researchers using models applied work often need build highly customized models standard software implementation lacking, construction models said software complicated writing fully tailored 'R' code. providing greater flexibility control, latter suffers slow estimation speeds make custom solutions inconvenient. address issues two ways. First, standard blocks code, common model classes, implemented simple--use functions can added like Lego blocks otherwise fully custom likelihood function, making writing custom code much easier. Second, hood, functions written 'C++', allowing 10-20 times faster evaluation time, thus drastically speeding model estimation. aid building fully custom likelihood functions, several vignettes included show simulate data estimate model classes.","code":""},{"path":[]},{"path":"https://janoleko.github.io/reference/LaMa-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"LaMa: Fast Numerical Maximum Likelihood Estimation for Latent Markov Models — LaMa-package","text":"Maintainer: Jan-Ole Koslik jan-ole.koslik@uni-bielefeld.de (ORCID)","code":""},{"path":"https://janoleko.github.io/reference/buildSmoothDens.html","id":null,"dir":"Reference","previous_headings":"","what":"Build the design and penalty matrices for smooth density estimation — buildSmoothDens","title":"Build the design and penalty matrices for smooth density estimation — buildSmoothDens","text":"function can used prepare objects needed estimate mixture models smooth densities using P-Splines. can provide one multiple data streams different types (real, positive, circular) specify initial means sds/concentrations data stream. information converted suitable spline coefficients. buildSmoothDens constructs design penalty matrices standardised B-splines basis functions (integrating one) data stream. types \"real\" \"circular\" knots placed equidistant range data, type \"positive\" knots placed using polynomial spacing.","code":""},{"path":"https://janoleko.github.io/reference/buildSmoothDens.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build the design and penalty matrices for smooth density estimation — buildSmoothDens","text":"","code":"buildSmoothDens(data, type = \"real\", par, k = 20, degree = 3, diff_order = 2)"},{"path":"https://janoleko.github.io/reference/buildSmoothDens.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build the design and penalty matrices for smooth density estimation — buildSmoothDens","text":"data named data frame different data streams type type data stream, either \"real\" data reals, \"positive\" data positive reals \"circular\" angular data par nested named list initial means sds/concentrations data stream k number basis functions data stream degree degree B-spline basis functions data stream, defaults cubic B-splines diff_order order differencing used P-Spline penalty matrix data stream. Defaults second-order differences.","code":""},{"path":"https://janoleko.github.io/reference/buildSmoothDens.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build the design and penalty matrices for smooth density estimation — buildSmoothDens","text":"nested list containing design matrices Z, penalty matrices S, initial coefficients betastart, prediction design matrices Z_predict, prediction grids xseq, details basis expansion data stream.","code":""},{"path":"https://janoleko.github.io/reference/buildSmoothDens.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Build the design and penalty matrices for smooth density estimation — buildSmoothDens","text":"","code":"## 3 data streams, each with one distribution # normal data with mean 0 and sd 1 x1 = rnorm(100, mean = 0, sd = 1) # gamma data with mean 5 and sd 3 x2 = rgamma(100, shape = 5^2/3^2, scale = 3^2/5) # circular data x3 = seq(-pi, pi, length = 100)  data = data.frame(x1 = x1, x2 = x2, x3 = x3)  par = list(x1 = list(mean = 0, sd = 1),            x2 = list(mean = 5, sd = 3),            x3 = list(mean = 0, concentration = 2))  SmoothDens = buildSmoothDens(data,                               type = c(\"real\", \"positive\", \"circular\"),                              par) #> x1  #> Leaving out last column of the penalty matrix, fix the last spline coefficient at zero for identifiability! #> Parameter matrix excludes the last column. Fix this column at zero! #> x2  #> Leaving out last column of the penalty matrix, fix the last spline coefficient at zero for identifiability! #> Parameter matrix excludes the last column. Fix this column at zero! #> x3  #> Leaving out last column of the penalty matrix, fix the last spline coefficient at zero for identifiability! #> Parameter matrix excludes the last column. Fix this column at zero!                               # extracting objects for x1 Z1 = SmoothDens$Z$x1 S1 = SmoothDens$S$x1 coefs1 = SmoothDens$coef$x1  ## one data stream, but mixture of two distributions # normal data with mean 0 and sd 1 x = rnorm(100, mean = 0, sd = 1) data = data.frame(x = x)  # now parameters for mixture of two normals par = list(x = list(mean = c(0, 5), sd = c(1,1)))  SmoothDens = buildSmoothDens(data, par = par) #> x  #> Leaving out last column of the penalty matrix, fix the last spline coefficient at zero for identifiability! #> Parameter matrix excludes the last column. Fix this column at zero!  # extracting objects  Z = SmoothDens$Z$x S = SmoothDens$S$x coefs = SmoothDens$coef$x"},{"path":"https://janoleko.github.io/reference/calc_trackInd.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the index of the first observation of each track based on an ID variable — calc_trackInd","title":"Calculate the index of the first observation of each track based on an ID variable — calc_trackInd","text":"Function conveniently calculate trackInd variable needed internally fitting model longitudinal data multiple tracks.","code":""},{"path":"https://janoleko.github.io/reference/calc_trackInd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the index of the first observation of each track based on an ID variable — calc_trackInd","text":"","code":"calc_trackInd(ID)"},{"path":"https://janoleko.github.io/reference/calc_trackInd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the index of the first observation of each track based on an ID variable — calc_trackInd","text":"ID ID variable track IDs length data analysed","code":""},{"path":"https://janoleko.github.io/reference/calc_trackInd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the index of the first observation of each track based on an ID variable — calc_trackInd","text":"vector indices first observation track can passed forward forward_g sum likelihood contributions track","code":""},{"path":"https://janoleko.github.io/reference/calc_trackInd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate the index of the first observation of each track based on an ID variable — calc_trackInd","text":"","code":"uniqueID = c(\"Animal1\", \"Animal2\", \"Animal3\") ID = rep(uniqueID, c(100, 200, 300)) trackInd = calc_trackInd(ID)"},{"path":"https://janoleko.github.io/reference/dgmrf2.html","id":null,"dir":"Reference","previous_headings":"","what":"Reparametrised multivariate Gaussian distribution — dgmrf2","title":"Reparametrised multivariate Gaussian distribution — dgmrf2","text":"Density function multivariate Gaussian distribution reparametrised terms precision matrix (inverse variance). implementation particularly useful marginal ML penalised splines ..d. random effects multivariate Gaussian distribution precision matrix \\(\\lambda S\\) S fixed penalty matrix. \\(S\\) fixed scaled \\(\\lambda\\), efficient precompute determinant \\(S\\) (normalization constant) scale quadratic form \\(\\lambda\\) multiple spline parameters/ random effects different \\(\\lambda\\)'s penalty matrix \\(S\\) evaluated.","code":""},{"path":"https://janoleko.github.io/reference/dgmrf2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reparametrised multivariate Gaussian distribution — dgmrf2","text":"","code":"dgmrf2(x, mu = 0, S, lambda, logdetS = NULL, log = FALSE)"},{"path":"https://janoleko.github.io/reference/dgmrf2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reparametrised multivariate Gaussian distribution — dgmrf2","text":"x density evaluation point, either vector matrix mu mean parameter. Either scalar vector S unscaled precision matrix lambda precision scaling parameter Can vector x matrix. row x evaluated corresponding lambda. benefitial efficiency perspective determinant S computed . logdetS Optional precomputed log determinant precision matrix S. precision matrix depend parameters, can precomputed passed function. log logical; TRUE, densities returned log scale.","code":""},{"path":"https://janoleko.github.io/reference/dgmrf2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reparametrised multivariate Gaussian distribution — dgmrf2","text":"Vector densities","code":""},{"path":"https://janoleko.github.io/reference/dgmrf2.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Reparametrised multivariate Gaussian distribution — dgmrf2","text":"implementation allows automatic differentiation RTMB.","code":""},{"path":"https://janoleko.github.io/reference/dgmrf2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reparametrised multivariate Gaussian distribution — dgmrf2","text":"","code":"x = matrix(runif(30), nrow = 3)  # iid random effects S = diag(10) sigma = c(1, 2, 3) # random effect standard deviations lambda = 1 / sigma^2 dgmrf2(x, 0, S, lambda) #> [1] 4.205050e-05 6.328077e-08 1.412618e-09  # P-splines L = diff(diag(10), diff = 2) # second-order difference matrix S = t(L) %*% L lambda = c(1,2,3) dgmrf2(x, 0, S, lambda, log = TRUE) #> [1] -8.511807 -3.820223 -4.899150"},{"path":"https://janoleko.github.io/reference/dvm.html","id":null,"dir":"Reference","previous_headings":"","what":"von Mises Density Function — dvm","title":"von Mises Density Function — dvm","text":"Returns density function van Mises distribution evaluated particular value.","code":""},{"path":"https://janoleko.github.io/reference/dvm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"von Mises Density Function — dvm","text":"","code":"dvm(x, mu, kappa, log = FALSE)"},{"path":"https://janoleko.github.io/reference/dvm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"von Mises Density Function — dvm","text":"x vector angles measured radians evaluate density function. mu mean direction distribution measured radians. kappa non-negative numeric value concentration parameter distribution. log logical; TRUE, densities returned log scale.","code":""},{"path":"https://janoleko.github.io/reference/dvm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"von Mises Density Function — dvm","text":"Returns density function von Mises density distribution evaluated x.","code":""},{"path":"https://janoleko.github.io/reference/dvm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"von Mises Density Function — dvm","text":"implementation allows automatic differentiation RTMB.","code":""},{"path":"https://janoleko.github.io/reference/dvm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"von Mises Density Function — dvm","text":"","code":"x = c(0, pi/2, pi) dvm(x, 0, 1) #> [1] 0.34171049 0.12570826 0.04624549"},{"path":"https://janoleko.github.io/reference/elephant.html","id":null,"dir":"Reference","previous_headings":"","what":"Elephant data set — elephant","title":"Elephant data set — elephant","text":"Synthetic data set hourly step lengths turning angles elephant.","code":""},{"path":"https://janoleko.github.io/reference/elephant.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Elephant data set — elephant","text":"","code":"elephant"},{"path":"https://janoleko.github.io/reference/elephant.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Elephant data set — elephant","text":"data frame 10.000 rows 4 variables: tod time day variable ranging 1 24 step hourly step lengths kilometres angle hourly turning angles radians state hidden state variable","code":""},{"path":"https://janoleko.github.io/reference/elephant.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Elephant data set — elephant","text":"Generated example purposes.","code":""},{"path":"https://janoleko.github.io/reference/forward.html","id":null,"dir":"Reference","previous_headings":"","what":"Forward algorithm with homogeneous transition probability matrix — forward","title":"Forward algorithm with homogeneous transition probability matrix — forward","text":"Forward algorithm homogeneous transition probability matrix","code":""},{"path":"https://janoleko.github.io/reference/forward.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Forward algorithm with homogeneous transition probability matrix — forward","text":"","code":"forward(delta, Gamma, allprobs, trackID = NULL, ad = NULL, report = TRUE)"},{"path":"https://janoleko.github.io/reference/forward.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Forward algorithm with homogeneous transition probability matrix — forward","text":"delta initial stationary distribution length N, matrix dimension c(k,N) k independent tracks, trackID provided Gamma transition probability matrix dimension c(N,N), array k transition probability matrices dimension c(N,N,k), trackID provided allprobs matrix state-dependent probabilities/ density values dimension c(n, N) trackID optional vector length n containing IDs provided, total log-likelihood sum track's likelihood contribution. case, Gamma can matrix, leading transition probabilities track, array dimension c(N,N,k), one (homogeneous) transition probability matrix track. Furthermore, instead single vector delta corresponding initial distribution, delta matrix initial distributions, dimension c(k,N), can provided, track starts initial distribution. ad optional logical, indicating whether automatic differentiation RTMB used. default, function determines . report logical, indicating whether delta, Gamma allprobs reported fitted model. Defaults TRUE, works ad = TRUE.","code":""},{"path":"https://janoleko.github.io/reference/forward.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Forward algorithm with homogeneous transition probability matrix — forward","text":"log-likelihood given data parameters","code":""},{"path":"https://janoleko.github.io/reference/forward.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Forward algorithm with homogeneous transition probability matrix — forward","text":"","code":"## generating data from homogeneous 2-state HMM mu = c(0, 6) sigma = c(2, 4) Gamma = matrix(c(0.5, 0.05, 0.15, 0.85), nrow = 2, byrow = TRUE) delta = c(0.5, 0.5) # simulation s = x = rep(NA, 500) s[1] = sample(1:2, 1, prob = delta) x[1] = rnorm(1, mu[s[1]], sigma[s[1]]) for(t in 2:500){   s[t] = sample(1:2, 1, prob = Gamma[s[t-1],])   x[t] = rnorm(1, mu[s[t]], sigma[s[t]]) }  ## negative log likelihood function mllk = function(theta.star, x){   # parameter transformations for unconstraint optimization   Gamma = tpm(theta.star[1:2])   delta = stationary(Gamma) # stationary HMM   mu = theta.star[3:4]   sigma = exp(theta.star[5:6])   # calculate all state-dependent probabilities   allprobs = matrix(1, length(x), 2)   for(j in 1:2){ allprobs[,j] = dnorm(x, mu[j], sigma[j]) }   # return negative for minimization   -forward(delta, Gamma, allprobs) }  ## fitting an HMM to the data theta.star = c(-2,-2,0,5,log(2),log(3)) mod = stats::nlm(mllk, theta.star, x = x)"},{"path":"https://janoleko.github.io/reference/forward_g.html","id":null,"dir":"Reference","previous_headings":"","what":"General forward algorithm with time-varying transition probability matrix — forward_g","title":"General forward algorithm with time-varying transition probability matrix — forward_g","text":"General forward algorithm time-varying transition probability matrix","code":""},{"path":"https://janoleko.github.io/reference/forward_g.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"General forward algorithm with time-varying transition probability matrix — forward_g","text":"","code":"forward_g(delta, Gamma, allprobs, trackID = NULL, ad = NULL, report = TRUE)"},{"path":"https://janoleko.github.io/reference/forward_g.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"General forward algorithm with time-varying transition probability matrix — forward_g","text":"delta initial stationary distribution length N, matrix dimension c(k,N) k independent tracks, trackID provided Gamma array transition probability matrices dimension c(N,N,n-1), time series length n, n-1 transitions. array dimension c(N,N,n) single track provided, first slice ignored. elements \\(\\Gamma^{(t)}\\) depend covariate values t covariates t+1 choice calculation array, prior using function. conducting calculation using tpm_g(), choice comes including covariate matrix Z[-1,] oder Z[-n,]. trackInd provided, Gamma needs array dimension c(N,N,n), matching number rows allprobs. track, transition matrix beginning ignored. parameters Gamma pooled across tracks , depends calculation Gamma. pooled, can use tpm_g(Z, beta) calculate entire array transition matrices Z dimension c(n,p). function can also used fit continuous-time HMMs, array entry Markov semigroup \\(\\Gamma(\\Delta t) = \\exp(Q \\Delta t)\\) \\(Q\\) generator continuous-time Markov chain. allprobs matrix state-dependent probabilities/ density values dimension c(n, N) trackID optional vector length n containing IDs provided, total log-likelihood sum track's likelihood contribution. case, Gamma needs array dimension c(N,N,n), matching number rows allprobs. track, transition matrix beginning track ignored (transition tracks). Furthermore, instead single vector delta corresponding initial distribution, delta matrix initial distributions, dimension c(k,N), can provided, track starts initial distribution. ad optional logical, indicating whether automatic differentiation RTMB used. default, function determines . report logical, indicating whether delta, Gamma allprobs reported fitted model. Defaults TRUE, works ad = TRUE.","code":""},{"path":"https://janoleko.github.io/reference/forward_g.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"General forward algorithm with time-varying transition probability matrix — forward_g","text":"log-likelihood given data parameters","code":""},{"path":"https://janoleko.github.io/reference/forward_g.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"General forward algorithm with time-varying transition probability matrix — forward_g","text":"","code":"## generating data from inhomogeneous 2-state HMM mu = c(0, 6) sigma = c(2, 4) beta = matrix(c(-2,-2,0.5,-0.5),nrow=2) delta = c(0.5, 0.5) # simulation n = 2000 s = x = rep(NA, n) z = rnorm(n, 0, 2) s[1] = sample(1:2, 1, prob = delta) x[1] = rnorm(1, mu[s[1]], sigma[s[1]]) for(t in 2:n){   Gamma = diag(2)   Gamma[!Gamma] = exp(beta[,1]+beta[,2]*z[t])   Gamma = Gamma / rowSums(Gamma)   s[t] = sample(1:2, 1, prob = Gamma[s[t-1],])   x[t] = rnorm(1, mu[s[t]], sigma[s[t]]) }  ## negative log likelihood function mllk = function(theta.star, x, z){   # parameter transformations for unconstraint optimization   beta = matrix(theta.star[1:4], 2, 2)   Gamma = tpm_g(Z = z, beta = beta)   delta = c(plogis(theta.star[5]), 1-plogis(theta.star[5]))   mu = theta.star[6:7]   sigma = exp(theta.star[8:9])   # calculate all state-dependent probabilities   allprobs = matrix(1, length(x), 2)   for(j in 1:2){ allprobs[,j] = dnorm(x, mu[j], sigma[j]) }   # return negative for minimization   -forward_g(delta, Gamma, allprobs) }  ## fitting an HMM to the data theta.star = c(-2,-2,1,-1,0,0,5,log(2),log(3)) mod = nlm(mllk, theta.star, x = x, z = z) #> Warning: NA/Inf replaced by maximum positive value"},{"path":"https://janoleko.github.io/reference/forward_hsmm.html","id":null,"dir":"Reference","previous_headings":"","what":"Forward algorithm for homogeneous hidden semi-Markov models — forward_hsmm","title":"Forward algorithm for homogeneous hidden semi-Markov models — forward_hsmm","text":"Hidden semi-Markov models (HSMMs) flexible extension HMMs, state duration distribution explicitly modelled distribution positive integers. direct numerical maximum likelhood estimation, HSMMs can represented HMMs enlarged state space (size \\(M\\)) structured transition probabilities. function designed used automatic differentiation based R package RTMB. slow without !","code":""},{"path":"https://janoleko.github.io/reference/forward_hsmm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Forward algorithm for homogeneous hidden semi-Markov models — forward_hsmm","text":"","code":"forward_hsmm(   dm,   omega,   allprobs,   trackID = NULL,   delta = NULL,   eps = 1e-10,   report = TRUE )"},{"path":"https://janoleko.github.io/reference/forward_hsmm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Forward algorithm for homogeneous hidden semi-Markov models — forward_hsmm","text":"dm list length N containing vectors dwell-time probability mass functions (PMFs) state. vector lengths correspond approximating state aggregate sizes, hence little probablity mass covered . omega matrix dimension c(N,N) conditional transition probabilites, also called embedded transition probability matrix. Contains transition probabilities given current state left. Hence, diagonal elements need zero rows need sum one. Can constructed using tpm_emb. allprobs matrix state-dependent probabilities/ density values dimension c(n, N) automatically converted appropriate dimension. trackID optional vector length n containing IDs provided, total log-likelihood sum track's likelihood contribution. case, dm can nested list, top layer contains k dm lists described . omega can also array dimension c(N,N,k) one conditional transition probability matrix track. Furthermore, instead single vector delta corresponding initial distribution, delta matrix initial distributions, dimension c(k,N), can provided, track starts initial distribution. delta optional vector initial state probabilities length N default, stationary distribution computed (typically recommended). eps small value avoid numerical issues approximating transition matrix construction. Usually, changed. report logical, indicating whether initial distribution, approximating transition probability matrix allprobs matrix reported fitted model. Defaults TRUE.","code":""},{"path":"https://janoleko.github.io/reference/forward_hsmm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Forward algorithm for homogeneous hidden semi-Markov models — forward_hsmm","text":"log-likelihood given data parameters","code":""},{"path":"https://janoleko.github.io/reference/forward_hsmm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Forward algorithm for homogeneous hidden semi-Markov models — forward_hsmm","text":"","code":"# currently no examples"},{"path":"https://janoleko.github.io/reference/forward_ihsmm.html","id":null,"dir":"Reference","previous_headings":"","what":"Forward algorithm for hidden semi-Markov models with inhomogeneous state durations and/ or conditional transition probabilities — forward_ihsmm","title":"Forward algorithm for hidden semi-Markov models with inhomogeneous state durations and/ or conditional transition probabilities — forward_ihsmm","text":"Hidden semi-Markov models (HSMMs) flexible extension HMMs, state duration distribution explicitly modelled distribution positive integers. function can used fit HSMMs state-duration distribution / conditional transition probabilities vary covariates. direct numerical maximum likelhood estimation, HSMMs can represented HMMs enlarged state space (size \\(M\\)) structured transition probabilities. function designed used automatic differentiation based R package RTMB. slow without !","code":""},{"path":"https://janoleko.github.io/reference/forward_ihsmm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Forward algorithm for hidden semi-Markov models with inhomogeneous state durations and/ or conditional transition probabilities — forward_ihsmm","text":"","code":"forward_ihsmm(   dm,   omega,   allprobs,   trackID = NULL,   delta = NULL,   startInd = NULL,   eps = 1e-10,   report = TRUE )"},{"path":"https://janoleko.github.io/reference/forward_ihsmm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Forward algorithm for hidden semi-Markov models with inhomogeneous state durations and/ or conditional transition probabilities — forward_ihsmm","text":"dm list length N containing matrices (vectors) dwell-time probability mass functions (PMFs) state. dwell-time PMFs constant, vectors PMF dwell-time distribution fixed time. vector lengths correspond approximating state aggregate sizes, hence little probablity mass covered . dwell-time PMFs inhomogeneous, matrices need n rows, n number observations. number columns correponds size approximating state aggregates. latter case, first max(sapply(dm, ncol)) - 1 observations used first approximating transition probability matrix needs computed based first max(sapply(dm, ncol)) covariate values (represented dm). omega matrix dimension c(N,N) array dimension c(N,N,n) conditional transition probabilites, also called embedded transition probability matrix. contains transition probabilities given current state left. Hence, diagonal elements need zero rows need sum one. matrix can constructed using tpm_emb array using tpm_emb_g. allprobs matrix state-dependent probabilities/ density values dimension c(n, N) trackID trackID optional vector length n containing IDs provided, total log-likelihood sum track's likelihood contribution. Instead single vector delta corresponding initial distribution, delta matrix initial distributions, dimension c(k,N), can provided, track starts initial distribution. delta optional vector initial state probabilities length N default, instead , stationary distribution computed corresponding first approximating transition probability matrix track computed. Contrary homogeneous case, theoretically motivated just convenience. startInd optional integer index forward algorithm starts. approximating inhomogeneous HSMMs inhomogeneous HMMs, first transition probability matrix can constructed time max(sapply(dm, ncol)) (depends previous covariate values). Hence, provided, startInd chosen max(sapply(dm, ncol)). Fixing startInd value larger max(aggregate sizes) useful models different aggregate sizes fitted data supposed compared. case important models use number observations. eps small value avoid numerical issues approximating transition matrix construction. Usually, changed. report logical, indicating whether initial distribution, approximating transition probability matrix allprobs matrix reported fitted model. Defaults TRUE.","code":""},{"path":"https://janoleko.github.io/reference/forward_ihsmm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Forward algorithm for hidden semi-Markov models with inhomogeneous state durations and/ or conditional transition probabilities — forward_ihsmm","text":"log-likelihood given data parameters","code":""},{"path":"https://janoleko.github.io/reference/forward_ihsmm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Forward algorithm for hidden semi-Markov models with inhomogeneous state durations and/ or conditional transition probabilities — forward_ihsmm","text":"","code":"# currently no examples"},{"path":"https://janoleko.github.io/reference/forward_p.html","id":null,"dir":"Reference","previous_headings":"","what":"Forward algorithm with for periodically varying transition probability matrices — forward_p","title":"Forward algorithm with for periodically varying transition probability matrices — forward_p","text":"transition probability matrix varies periodically (e.g. function time day), \\(L\\) unique matrices \\(L\\) period length (e.g. \\(L=24\\) hourly data time--day variation). Thus, much efficient calculate \\(L\\) matrices index time variable (e.g. time day day year) instead calculating matrix index data set (redundant). function allows , expecting transition probability matrix time point period, integer valued (\\(1, \\dots, L\\)) time variable maps data index according time.","code":""},{"path":"https://janoleko.github.io/reference/forward_p.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Forward algorithm with for periodically varying transition probability matrices — forward_p","text":"","code":"forward_p(delta, Gamma, allprobs, tod)"},{"path":"https://janoleko.github.io/reference/forward_p.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Forward algorithm with for periodically varying transition probability matrices — forward_p","text":"delta initial stationary distribution length N, matrix dimension c(k,N) k independent tracks, trackID provided Gamma array transition probability matrices dimension c(N,N,L). use definition \\(\\Pr(S_t=j \\mid S_{t-1}=) = \\gamma_{ij}^{(t)}\\) transition probabilities time point \\(t-1\\) \\(t\\) element \\(\\Gamma^{(t)}\\). allprobs matrix state-dependent probabilities/ density values dimension c(n, N) tod (Integer valued) variable cycle indexing 1, ..., L, mapping data index generalised time day (length n) half-hourly data L = 48. , however, also day year daily data L = 365.","code":""},{"path":"https://janoleko.github.io/reference/forward_p.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Forward algorithm with for periodically varying transition probability matrices — forward_p","text":"log-likelihood given data parameters","code":""},{"path":"https://janoleko.github.io/reference/forward_p.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Forward algorithm with for periodically varying transition probability matrices — forward_p","text":"","code":"## generating data from periodic 2-state HMM mu = c(0, 6) sigma = c(2, 4) beta = matrix(c(-2,-2,1,-1, 1, -1),nrow=2) delta = c(0.5, 0.5) # simulation n = 2000 s = x = rep(NA, n) tod = rep(1:24, ceiling(2000/24)) s[1] = sample(1:2, 1, prob = delta) x[1] = rnorm(1, mu[s[1]], sigma[s[1]]) # 24 unique t.p.m.s Gamma = array(dim = c(2,2,24)) for(t in 1:24){   G = diag(2)   G[!G] = exp(beta[,1]+beta[,2]*sin(2*pi*t/24)+     beta[,3]*cos(2*pi*t/24)) # trigonometric link   Gamma[,,t] = G / rowSums(G) } for(t in 2:n){   s[t] = sample(1:2, 1, prob = Gamma[s[t-1],,tod[t]])   x[t] = rnorm(1, mu[s[t]], sigma[s[t]]) } # we can also use function from LaMa to make building periodic tpms much easier Gamma = tpm_p(1:24, 24, beta, degree = 1)  ## negative log likelihood function mllk = function(theta.star, x, tod){   # parameter transformations for unconstraint optimization   beta = matrix(theta.star[1:6], 2, 3)   Gamma = tpm_p(tod=tod, L=24, beta=beta)   delta = stationary_p(Gamma, t=tod[1])   mu = theta.star[8:9]   sigma = exp(theta.star[10:11])   # calculate all state-dependent probabilities   allprobs = matrix(1, length(x), 2)   for(j in 1:2){ allprobs[,j] = dnorm(x, mu[j], sigma[j]) }   # return negative for minimization   -forward_p(delta, Gamma, allprobs, tod) }  ## fitting an HMM to the data theta.star = c(-2,-2,1,-1,1,-1,0,0,5,log(2),log(3)) mod = nlm(mllk, theta.star, x = x, tod = tod) #> Warning: NA/Inf replaced by maximum positive value"},{"path":"https://janoleko.github.io/reference/forward_phsmm.html","id":null,"dir":"Reference","previous_headings":"","what":"Forward algorithm for hidden semi-Markov models with periodically inhomogeneous state durations and/ or conditional transition probabilities — forward_phsmm","title":"Forward algorithm for hidden semi-Markov models with periodically inhomogeneous state durations and/ or conditional transition probabilities — forward_phsmm","text":"Hidden semi-Markov models (HSMMs) flexible extension HMMs, state duration distribution explicitly modelled distribution positive integers. function can used fit HSMMs state-duration distribution / conditional transition probabilities vary covariates. direct numerical maximum likelhood estimation, HSMMs can represented HMMs enlarged state space (size \\(M\\)) structured transition probabilities. function can used fit HSMMs state-duration distribution / conditional transition probabilities vary periodically. special case periodic variation (compared arbitrary covariate influence), version preferred forward_ihsmm computes correct periodically stationary distribution observations lost approximation. function designed used automatic differentiation based R package RTMB. slow without !","code":""},{"path":"https://janoleko.github.io/reference/forward_phsmm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Forward algorithm for hidden semi-Markov models with periodically inhomogeneous state durations and/ or conditional transition probabilities — forward_phsmm","text":"","code":"forward_phsmm(   dm,   omega,   allprobs,   tod,   trackID = NULL,   delta = NULL,   eps = 1e-10,   report = TRUE )"},{"path":"https://janoleko.github.io/reference/forward_phsmm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Forward algorithm for hidden semi-Markov models with periodically inhomogeneous state durations and/ or conditional transition probabilities — forward_phsmm","text":"dm list length N containing matrices (vectors) dwell-time probability mass functions (PMFs) state. dwell-time PMFs constant, vectors PMF dwell-time distribution fixed time. vector lengths correspond approximating state aggregate sizes, hence little probablity mass covered . dwell-time PMFs inhomogeneous, matrices need L rows, L cycle length. number columns correpond size approximating state aggregates. omega matrix dimension c(N,N) array dimension c(N,N,L) conditional transition probabilites, also called embedded transition probability matrix contains transition probabilities given current state left. Hence, diagonal elements need zero rows need sum one. matrix can constructed using tpm_emb array using tpm_emb_g. allprobs matrix state-dependent probabilities/ density values dimension c(n, N) tod (Integer valued) variable cycle indexing 1, ..., L, mapping data index generalised time day (length n). half-hourly data L = 48. , however, also day year daily data L = 365. trackID optional vector length n containing IDs provided, total log-likelihood sum track's likelihood contribution. Instead single vector delta corresponding initial distribution, delta matrix initial distributions, dimension c(k,N), can provided, track starts initial distribution. delta Optional vector initial state probabilities length N. default, instead , stationary distribution computed corresponding first approximating t.p.m. track computed. Contrary homogeneous case, theoretically motivated just convenience. eps small value avoid numerical issues approximating transition matrix construction. Usually, changed. report logical, indicating whether initial distribution, approximating transition probability matrix allprobs matrix reported fitted model. Defaults TRUE.","code":""},{"path":"https://janoleko.github.io/reference/forward_phsmm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Forward algorithm for hidden semi-Markov models with periodically inhomogeneous state durations and/ or conditional transition probabilities — forward_phsmm","text":"log-likelihood given data parameters","code":""},{"path":"https://janoleko.github.io/reference/forward_phsmm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Forward algorithm for hidden semi-Markov models with periodically inhomogeneous state durations and/ or conditional transition probabilities — forward_phsmm","text":"","code":"# currently no examples"},{"path":"https://janoleko.github.io/reference/forward_s.html","id":null,"dir":"Reference","previous_headings":"","what":"Forward algorithm for hidden semi-Markov models with homogeneous transition probability matrix — forward_s","title":"Forward algorithm for hidden semi-Markov models with homogeneous transition probability matrix — forward_s","text":"Hidden semi-Markov models (HSMMs) flexible extension HMMs can approximated HMMs enlarged state space (size \\(M\\)) structured transition probabilities.","code":""},{"path":"https://janoleko.github.io/reference/forward_s.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Forward algorithm for hidden semi-Markov models with homogeneous transition probability matrix — forward_s","text":"","code":"forward_s(delta, Gamma, allprobs, sizes)"},{"path":"https://janoleko.github.io/reference/forward_s.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Forward algorithm for hidden semi-Markov models with homogeneous transition probability matrix — forward_s","text":"delta initial stationary distribution length N, matrix dimension c(k,N) k independent tracks, trackID provided Gamma transition probability matrix dimension c(M,M) allprobs matrix state-dependent probabilities/ density values dimension c(n, N) automatically converted appropriate dimension. sizes state aggregate sizes used approximation semi-Markov chain.","code":""},{"path":"https://janoleko.github.io/reference/forward_s.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Forward algorithm for hidden semi-Markov models with homogeneous transition probability matrix — forward_s","text":"log-likelihood given data parameters","code":""},{"path":"https://janoleko.github.io/reference/forward_s.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Forward algorithm for hidden semi-Markov models with homogeneous transition probability matrix — forward_s","text":"","code":"## generating data from homogeneous 2-state HSMM mu = c(0, 6) lambda = c(6, 12) omega = matrix(c(0,1,1,0), nrow = 2, byrow = TRUE) # simulation # for a 2-state HSMM the embedded chain always alternates between 1 and 2 s = rep(1:2, 100) C = x = numeric(0) for(t in 1:100){   dt = rpois(1, lambda[s[t]])+1 # shifted Poisson   C = c(C, rep(s[t], dt))   x = c(x, rnorm(dt, mu[s[t]], 1.5)) # fixed sd 2 for both states }  ## negative log likelihood function mllk = function(theta.star, x, sizes){   # parameter transformations for unconstraint optimization   omega = matrix(c(0,1,1,0), nrow = 2, byrow = TRUE) # omega fixed (2-states)   lambda = exp(theta.star[1:2]) # dwell time means   dm = list(dpois(1:sizes[1]-1, lambda[1]), dpois(1:sizes[2]-1, lambda[2]))   Gamma = tpm_hsmm2(omega, dm)   delta = stationary(Gamma) # stationary   mu = theta.star[3:4]   sigma = exp(theta.star[5:6])   # calculate all state-dependent probabilities   allprobs = matrix(1, length(x), 2)   for(j in 1:2){ allprobs[,j] = dnorm(x, mu[j], sigma[j]) }   # return negative for minimization   -forward_s(delta, Gamma, allprobs, sizes) }  ## fitting an HSMM to the data theta.star = c(log(5), log(10), 1, 4, log(2), log(2)) mod = nlm(mllk, theta.star, x = x, sizes = c(20, 30), stepmax = 5)"},{"path":"https://janoleko.github.io/reference/forward_sp.html","id":null,"dir":"Reference","previous_headings":"","what":"Forward algorithm for hidden semi-Markov models with periodically varying transition probability matrices — forward_sp","title":"Forward algorithm for hidden semi-Markov models with periodically varying transition probability matrices — forward_sp","text":"Hidden semi-Markov models (HSMMs) flexible extension HMMs can approximated HMMs enlarged state space (size \\(M\\)) structured transition probabilities. Recently, inference procedure generalised allow either dwell-time distributions conditional transition probabilities depend external covariates time day. special case implemented . function allows , expecting transition probability matrix time point period, integer valued (\\(1, \\dots, L\\)) time variable maps data index according time.","code":""},{"path":"https://janoleko.github.io/reference/forward_sp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Forward algorithm for hidden semi-Markov models with periodically varying transition probability matrices — forward_sp","text":"","code":"forward_sp(delta, Gamma, allprobs, sizes, tod)"},{"path":"https://janoleko.github.io/reference/forward_sp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Forward algorithm for hidden semi-Markov models with periodically varying transition probability matrices — forward_sp","text":"delta initial stationary distribution length N, matrix dimension c(k,N) k independent tracks, trackID provided Gamma array transition probability matrices dimension c(M,M,L). use definition \\(\\Pr(S_t=j \\mid S_{t-1}=) = \\gamma_{ij}^{(t)}\\) transition probabilities time point \\(t-1\\) \\(t\\) element \\(\\Gamma^{(t)}\\). allprobs matrix state-dependent probabilities/ density values dimension c(n, N) automatically converted appropriate dimension. sizes state aggregate sizes used approximation semi-Markov chain. tod (Integer valued) variable cycle indexing 1, ..., L, mapping data index generalised time day (length n). half-hourly data L = 48. , however, also day year daily data L = 365.","code":""},{"path":"https://janoleko.github.io/reference/forward_sp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Forward algorithm for hidden semi-Markov models with periodically varying transition probability matrices — forward_sp","text":"log-likelihood given data parameters","code":""},{"path":"https://janoleko.github.io/reference/forward_sp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Forward algorithm for hidden semi-Markov models with periodically varying transition probability matrices — forward_sp","text":"","code":"## generating data from homogeneous 2-state HSMM mu = c(0, 6) beta = matrix(c(log(4),log(6),-0.2,0.2,-0.1,0.4), nrow=2) # time varying mean dwell time Lambda = exp(cbind(1, trigBasisExp(1:24, 24, 1))%*%t(beta)) omega = matrix(c(0,1,1,0), nrow = 2, byrow = TRUE) # simulation # for a 2-state HSMM the embedded chain always alternates between 1 and 2 s = rep(1:2, 100) C = x = numeric(0) tod = rep(1:24, 50) # time of day variable time = 1 for(t in 1:100){   dt = rpois(1, Lambda[tod[time], s[t]])+1 # dwell time depending on time of day   time = time + dt   C = c(C, rep(s[t], dt))   x = c(x, rnorm(dt, mu[s[t]], 1.5)) # fixed sd 2 for both states } tod = tod[1:length(x)]  ## negative log likelihood function mllk = function(theta.star, x, sizes, tod){   # parameter transformations for unconstraint optimization   omega = matrix(c(0,1,1,0), nrow = 2, byrow = TRUE) # omega fixed (2-states)   mu = theta.star[1:2]   sigma = exp(theta.star[3:4])   beta = matrix(theta.star[5:10], nrow=2)   # time varying mean dwell time   Lambda = exp(cbind(1, trigBasisExp(1:24, 24, 1))%*%t(beta))   dm = list()   for(j in 1:2){     dm[[j]] = sapply(1:sizes[j]-1, dpois, lambda = Lambda[,j])   }   Gamma = tpm_phsmm2(omega, dm)   delta = stationary_p(Gamma, tod[1])   # calculate all state-dependent probabilities   allprobs = matrix(1, length(x), 2)   for(j in 1:2){ allprobs[,j] = dnorm(x, mu[j], sigma[j]) }   # return negative for minimization   -forward_sp(delta, Gamma, allprobs, sizes, tod) }  ## fitting an HSMM to the data theta.star = c(1, 4, log(2), log(2), # state-dependent parameters                  log(4), log(6), rep(0,4)) # state process parameters dm mod = nlm(mllk, theta.star, x = x, sizes = c(10, 15), tod = tod, stepmax = 5)"},{"path":"https://janoleko.github.io/reference/gamma2.html","id":null,"dir":"Reference","previous_headings":"","what":"Reparametrised gamma distribution — gamma2","title":"Reparametrised gamma distribution — gamma2","text":"Density, distribution function, quantile function random generation gamma distribution reparametrised terms mean standard deviation.","code":""},{"path":"https://janoleko.github.io/reference/gamma2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reparametrised gamma distribution — gamma2","text":"","code":"dgamma2(x, mu = 1, sigma = 1, log = FALSE)  pgamma2(q, mu = 1, sigma = 1, lower.tail = TRUE, log.p = FALSE)  qgamma2(p, mu = 1, sigma = 1, lower.tail = TRUE, log.p = FALSE)  rgamma2(n, mu = 1, sigma = 1)"},{"path":"https://janoleko.github.io/reference/gamma2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reparametrised gamma distribution — gamma2","text":"x, q vector quantiles mu mean parameter, must positive scalar. sigma standard deviation parameter, must positive scalar. log, log.p logical; TRUE, probabilities/ densities \\(p\\) returned \\(\\log(p)\\). lower.tail logical; TRUE, probabilities \\(P[X <= x]\\), otherwise, \\(P[X > x]\\). p vector probabilities n number observations. length(n) > 1, length taken number required.","code":""},{"path":"https://janoleko.github.io/reference/gamma2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reparametrised gamma distribution — gamma2","text":"dgamma2 gives density, pgamma2 gives distribution function, qgamma2 gives quantile function, rgamma2 generates random deviates.","code":""},{"path":"https://janoleko.github.io/reference/gamma2.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Reparametrised gamma distribution — gamma2","text":"implementation allows automatic differentiation RTMB.","code":""},{"path":"https://janoleko.github.io/reference/gamma2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reparametrised gamma distribution — gamma2","text":"","code":"x = rgamma2(1) d = dgamma2(x) p = pgamma2(x) q = qgamma2(p)"},{"path":"https://janoleko.github.io/reference/generator.html","id":null,"dir":"Reference","previous_headings":"","what":"Build the generator matrix of a continuous-time Markov chain — generator","title":"Build the generator matrix of a continuous-time Markov chain — generator","text":"function builds infinitesimal generator matrix continuous-time Markov chain unconstrained parameter vector.","code":""},{"path":"https://janoleko.github.io/reference/generator.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build the generator matrix of a continuous-time Markov chain — generator","text":"","code":"generator(param, byrow = FALSE, report = TRUE)"},{"path":"https://janoleko.github.io/reference/generator.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build the generator matrix of a continuous-time Markov chain — generator","text":"param unconstrained parameter vector length N*(N-1) N number states Markov chain byrow logical indicating transition probability matrix filled row report logical, indicating whether generator matrix Q reported fitted model. Defaults TRUE, works automatic differentiation RTMB used.","code":""},{"path":"https://janoleko.github.io/reference/generator.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build the generator matrix of a continuous-time Markov chain — generator","text":"infinitesimal generator matrix dimension c(N,N)","code":""},{"path":"https://janoleko.github.io/reference/generator.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Build the generator matrix of a continuous-time Markov chain — generator","text":"","code":"# 2 states: 2 free off-diagonal elements generator(rep(-1, 2)) #>            [,1]       [,2] #> [1,] -0.3678794  0.3678794 #> [2,]  0.3678794 -0.3678794 # 3 states: 6 free off-diagonal elements generator(rep(-2, 6)) #>            [,1]       [,2]       [,3] #> [1,] -0.2706706  0.1353353  0.1353353 #> [2,]  0.1353353 -0.2706706  0.1353353 #> [3,]  0.1353353  0.1353353 -0.2706706"},{"path":"https://janoleko.github.io/reference/make_matrices.html","id":null,"dir":"Reference","previous_headings":"","what":"Build the design matrix and the penalty matrix for models involving penalised splines based on a formula and a data set — make_matrices","title":"Build the design matrix and the penalty matrix for models involving penalised splines based on a formula and a data set — make_matrices","text":"Build design matrix penalty matrix models involving penalised splines based formula data set","code":""},{"path":"https://janoleko.github.io/reference/make_matrices.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build the design matrix and the penalty matrix for models involving penalised splines based on a formula and a data set — make_matrices","text":"","code":"make_matrices(formula, data, knots = NULL)"},{"path":"https://janoleko.github.io/reference/make_matrices.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build the design matrix and the penalty matrix for models involving penalised splines based on a formula and a data set — make_matrices","text":"formula right side formula used mgcv data data frame containing variables formula knots optional list containing user specified knot values used basis construction bases user simply supplies knots used, must match k value supplied (note number knots always just k). See mgcv documentation details.","code":""},{"path":"https://janoleko.github.io/reference/make_matrices.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build the design matrix and the penalty matrix for models involving penalised splines based on a formula and a data set — make_matrices","text":"list containing design matrix Z, penalty matrix S, formula, data knots","code":""},{"path":"https://janoleko.github.io/reference/make_matrices.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Build the design matrix and the penalty matrix for models involving penalised splines based on a formula and a data set — make_matrices","text":"","code":"modmat = make_matrices(~ s(x), data.frame(x = 1:10))"},{"path":"https://janoleko.github.io/reference/make_matrices_dens.html","id":null,"dir":"Reference","previous_headings":"","what":"Build a standardised P-Spline design matrix and the associated P-Spline penalty matrix — make_matrices_dens","title":"Build a standardised P-Spline design matrix and the associated P-Spline penalty matrix — make_matrices_dens","text":"function builds B-spline design matrix given data vector x. Importantly, B-spline basis functions normalised integral basis function 1, hence basis can used spline-based density estimation, basis functions weighted non-negative weights summing one.","code":""},{"path":"https://janoleko.github.io/reference/make_matrices_dens.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build a standardised P-Spline design matrix and the associated P-Spline penalty matrix — make_matrices_dens","text":"","code":"make_matrices_dens(   x,   k,   type = \"real\",   degree = 3,   npoints = 10000,   diff_order = 2,   pow = 0.5 )"},{"path":"https://janoleko.github.io/reference/make_matrices_dens.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build a standardised P-Spline design matrix and the associated P-Spline penalty matrix — make_matrices_dens","text":"x data vector k number basis functions type type data, either \"real\" data reals, \"positive\" data positive reals \"circular\" circular data like angles. degree degree B-spline basis functions, defaults cubic B-splines npoints number points used numerical integration normalizing B-spline basis functions diff_order order differencing used P-Spline penalty matrix data stream. Defaults second-order differences. pow power polynomial knot spacing non-equidistant knot spacing used type = \"positive\".","code":""},{"path":"https://janoleko.github.io/reference/make_matrices_dens.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build a standardised P-Spline design matrix and the associated P-Spline penalty matrix — make_matrices_dens","text":"list containing design matrix Z, penalty matrix S, prediction design matrix Z_predict, prediction grid xseq, details basis expansion.","code":""},{"path":"https://janoleko.github.io/reference/make_matrices_dens.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Build a standardised P-Spline design matrix and the associated P-Spline penalty matrix — make_matrices_dens","text":"","code":"modmat = make_matrices_dens(x = (-50):50, k = 20) #> Leaving out last column of the penalty matrix, fix the last spline coefficient at zero for identifiability! modmat = make_matrices_dens(x = 1:100, k = 20, type = \"positive\") #> Leaving out last column of the penalty matrix, fix the last spline coefficient at zero for identifiability! modmat = make_matrices_dens(x = seq(-pi,pi), k = 20, type = \"circular\") #> Leaving out last column of the penalty matrix, fix the last spline coefficient at zero for identifiability!"},{"path":"https://janoleko.github.io/reference/penalty.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes penalty based on quadratic form — penalty","title":"Computes penalty based on quadratic form — penalty","text":"function computes quadratic penalties form $$0.5 \\sum_{} \\lambda_i b_i^T S_i b_i,$$ smoothing parameters \\(\\lambda_i\\), coefficient vectors \\(b_i\\), fixed penalty matrices \\(S_i\\). intended used inside negative penalized log-likelihood function fitting models penalised splines simple random effects via quasi restricted maximum likelihood (qREML) qreml function. qreml work, likelihood function needs compatible RTMB R package enable automatic differentiation.","code":""},{"path":"https://janoleko.github.io/reference/penalty.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes penalty based on quadratic form — penalty","text":"","code":"penalty(re_coef, S, lambda)"},{"path":"https://janoleko.github.io/reference/penalty.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes penalty based on quadratic form — penalty","text":"re_coef coefficient vector/ matrix list coefficient vectors/ matrices list entry corresponds different smooth/ random effect associated penalty matrix S. several smooths/ random effects kind present, convenient pass matrix, row corresponds one smooth/ random effect. way rows can use penalty matrix. Caution: formatting re_coef needs match structure parameter list penalized negative log-likelihood function, .e. two random effect vectors different names (different list elements parameter list), combine matrix inside likelihood pass matrix penalty. seperate random effects, name, need passed list penalty. Moreover, ordering re_coef needs match character vector random specified qreml. S fixed penalty matrix list penalty matrices matching structure re_coef also dimension individuals smooths/ random effects lambda penalty strength parameter vector length corresponding total number random effects/ spline coefficients re_coef E.g. re_coef contains one vector one matrix 4 rows, lambda needs length 5.","code":""},{"path":"https://janoleko.github.io/reference/penalty.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes penalty based on quadratic form — penalty","text":"returns penalty value reports qreml.","code":""},{"path":"https://janoleko.github.io/reference/penalty.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes penalty based on quadratic form — penalty","text":"","code":"# Example with a single random effect re = rep(0, 5) S = diag(5) lambda = 1 penalty(re, S, lambda) #> [1] 0  # Example with two random effects,  # where one element contains two random effects of similar structure re = list(matrix(0, 2, 5), rep(0, 4)) S = list(diag(5), diag(4)) lambda = c(1,1,2) # length = total number of random effects penalty(re, S, lambda) #> [1] 0  # Full model-fitting example data = elephant[1:1000,] # subset  # initial parameter list par = list(logmu = log(c(0.3, 1)), # step mean            logsigma = log(c(0.2, 0.7)), # step sd            beta0 = c(-2,2), # state process intercept            betaspline = matrix(rep(0, 18), nrow = 2)) # state process spline coefs            # data object with initial penalty strength lambda dat = list(step = data$step, # step length            tod = data$tod, # time of day covariate            N = 2, # number of states            lambda = rep(10,2)) # initial penalty strength  # building model matrices modmat = make_matrices(~ s(tod, bs = \"cp\"),                         data = data.frame(tod = 1:24),                         knots = list(tod = c(0,24))) # wrapping points dat$Z = modmat$Z # spline design matrix dat$S = modmat$S # penalty matrix  # penalized negative log-likelihood function pnll = function(par) {   getAll(par, dat) # makes everything contained available without $   Gamma = tpm_g(Z, cbind(beta0, betaspline), ad = TRUE) # transition probabilities   delta = stationary_p(Gamma, t = 1, ad = TRUE) # initial distribution   mu = exp(logmu) # step mean   sigma = exp(logsigma) # step sd   # calculating all state-dependent densities   allprobs = matrix(1, nrow = length(step), ncol = N)   ind = which(!is.na(step)) # only for non-NA obs.   for(j in 1:N) allprobs[ind,j] = dgamma2(step[ind],mu[j],sigma[j])   -forward_g(delta, Gamma[,,tod], allprobs, ad = TRUE) +       penalty(betaspline, S, lambda) # this does all the penalization work }  # model fitting mod = qreml(pnll, par, dat, random = \"betaspline\") #> Creating AD function #> Initializing with lambda: 10 10  #> outer 1 - lambda: 3.636 2.859  #> outer 2 - lambda: 1.691 1.652  #> outer 3 - lambda: 0.967 1.184  #> outer 4 - lambda: 0.671 0.919  #> outer 5 - lambda: 0.546 0.739  #> outer 6 - lambda: 0.493 0.603  #> outer 7 - lambda: 0.472 0.494  #> outer 8 - lambda: 0.464 0.406  #> outer 9 - lambda: 0.463 0.334  #> outer 10 - lambda: 0.464 0.276  #> outer 11 - lambda: 0.467 0.23  #> outer 12 - lambda: 0.471 0.194  #> outer 13 - lambda: 0.474 0.166  #> outer 14 - lambda: 0.477 0.146  #> outer 15 - lambda: 0.48 0.131  #> outer 16 - lambda: 0.483 0.12  #> outer 17 - lambda: 0.484 0.112  #> outer 18 - lambda: 0.486 0.106  #> outer 19 - lambda: 0.487 0.102  #> outer 20 - lambda: 0.488 0.099  #> outer 21 - lambda: 0.489 0.097  #> outer 22 - lambda: 0.489 0.095  #> outer 23 - lambda: 0.49 0.094  #> outer 24 - lambda: 0.49 0.093  #> outer 25 - lambda: 0.49 0.093  #> outer 26 - lambda: 0.49 0.092  #> outer 27 - lambda: 0.49 0.092  #> outer 28 - lambda: 0.49 0.092  #> outer 29 - lambda: 0.49 0.092  #> outer 30 - lambda: 0.49 0.092  #> Converged"},{"path":"https://janoleko.github.io/reference/pred_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Build the prediction design matrix based on new data and model_matrices object created by make_matrices — pred_matrix","title":"Build the prediction design matrix based on new data and model_matrices object created by make_matrices — pred_matrix","text":"Build prediction design matrix based new data model_matrices object created make_matrices","code":""},{"path":"https://janoleko.github.io/reference/pred_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build the prediction design matrix based on new data and model_matrices object created by make_matrices — pred_matrix","text":"","code":"pred_matrix(model_matrices, newdata)"},{"path":"https://janoleko.github.io/reference/pred_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build the prediction design matrix based on new data and model_matrices object created by make_matrices — pred_matrix","text":"model_matrices model_matrices object returned make_matrices newdata data frame containing variables formula new data evaluate basis","code":""},{"path":"https://janoleko.github.io/reference/pred_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build the prediction design matrix based on new data and model_matrices object created by make_matrices — pred_matrix","text":"prediction design matrix newdata basis used model_matrices","code":""},{"path":"https://janoleko.github.io/reference/pred_matrix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Build the prediction design matrix based on new data and model_matrices object created by make_matrices — pred_matrix","text":"","code":"modmat = make_matrices(~ s(x), data.frame(x = 1:10)) pred_matrix(modmat, data.frame(x = 1:10 - 0.5)) #>    (Intercept)      s(x).1      s(x).2        s(x).3       s(x).4      s(x).5 #> 1            1  0.46118237  0.21156924 -0.0256091836 -0.191971478 -0.32923247 #> 2            1  0.31185772  0.21209861 -0.0003812272 -0.158402320 -0.29483666 #> 3            1  0.01969137  0.18861678  0.0209673950 -0.122478005 -0.25477355 #> 4            1 -0.38342506  0.09294038  0.0376097063 -0.068706422 -0.18502185 #> 5            1 -0.64184786 -0.04572279  0.0292354017  0.004680691 -0.07075549 #> 6            1 -0.64034312 -0.14363485 -0.0026182668  0.058635019  0.06302960 #> 7            1 -0.38895573 -0.16825538 -0.0221630097  0.080658435  0.16329472 #> 8            1  0.01392078 -0.12902186 -0.0194282673  0.092172561  0.21116803 #> 9            1  0.42018443 -0.06485091 -0.0064707431  0.096711643  0.22578658 #> 10           1  0.68010703 -0.03219759 -0.0120073009  0.080488284  0.20993527 #>         s(x).6      s(x).7      s(x).8     s(x).9 #> 1  -0.44621628 -0.57145368 -0.59142334 -1.7407766 #> 2  -0.41764610 -0.55858669 -0.27025266 -1.3926212 #> 3  -0.38096313 -0.53450963  0.03726824 -1.0444659 #> 4  -0.30609458 -0.46212294  0.28467716 -0.6963106 #> 5  -0.16919750 -0.30791440  0.42268222 -0.3481553 #> 6   0.01589457 -0.07489431  0.43307228  0.0000000 #> 7   0.20552433  0.20233992  0.31945668  0.3481553 #> 8   0.33400451  0.45959259  0.10136387  0.6963106 #> 9   0.38212735  0.60777584 -0.18918280  1.0444659 #> 10  0.37737588  0.63756750 -0.50865096  1.3926212 #> attr(,\"model.offset\") #> [1] 0"},{"path":"https://janoleko.github.io/reference/qreml.html","id":null,"dir":"Reference","previous_headings":"","what":"Quasi restricted maximum likelihood (qREML) algorithm for models with penalised splines or simple i.i.d. random effects — qreml","title":"Quasi restricted maximum likelihood (qREML) algorithm for models with penalised splines or simple i.i.d. random effects — qreml","text":"algorithm can used flexibly fit statistical models involve penalised splines simple ..d. random effects, .e. penalties form $$0.5 \\sum_{} \\lambda_i b_i^T S_i b_i,$$ smoothing parameters \\(\\lambda_i\\), coefficient vectors \\(b_i\\), fixed penalty matrices \\(S_i\\). qREML algorithm typically much faster REML marginal ML using full Laplace approximation method, may slightly less accurate regarding estimation penalty strength parameters. hood, qreml uses R package RTMB automatic differentiation inner optimisation. user specify penalised negative log-likelihood function pnll structured dictated RTMB use penalty function compute quadratic-form penalty inside likelihood.","code":""},{"path":"https://janoleko.github.io/reference/qreml.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Quasi restricted maximum likelihood (qREML) algorithm for models with penalised splines or simple i.i.d. random effects — qreml","text":"","code":"qreml(   pnll,   par,   dat,   random,   penalty = \"lambda\",   alpha = 0,   maxiter = 100,   tol = 1e-05,   control = list(reltol = 1e-10, maxit = 1000),   silent = 1,   saveall = FALSE )"},{"path":"https://janoleko.github.io/reference/qreml.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Quasi restricted maximum likelihood (qREML) algorithm for models with penalised splines or simple i.i.d. random effects — qreml","text":"pnll penalised negative log-likelihood function structured dictated RTMB uses penalty function LaMa compute penalty Needs function named list initial parameters par . par named list initial parameters random effects/ spline coefficients can vectors matrices, latter summarising several random effects structure, one row matrix. dat initial data list contains data used likelihood function, hyperparameters, initial penalty strength initial penalty strength vector called lambda, need specify name dat using penalty argument . length needs match total number random effects. random vector names random effects par penalised. Caution: ordering random needs match order random effects passed penalty inside likelihood function. penalty optional name given penalty parameter dat. Defaults \"lambda\". alpha optional hyperparamater exponential smoothing penalty strengths larger values smoother convergence expected algorithm may need iterations. maxiter maximum number iterations outer optimisation penalty strength parameters. tol Convergence tolerance penalty strength parameters. control list control parameters optim use inner optimisation. , optim uses BFGS method changed. advise changing default values reltol maxit can decrease accuracy Laplace approximation. silent integer silencing level: 0 corresponds full printing inner outer iterations, 1 printing outer iterations , 2 printing. saveall logical, TRUE, model objects iteration saved final model object.","code":""},{"path":"https://janoleko.github.io/reference/qreml.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Quasi restricted maximum likelihood (qREML) algorithm for models with penalised splines or simple i.i.d. random effects — qreml","text":"returns model list influenced users report statements pnll","code":""},{"path":"https://janoleko.github.io/reference/qreml.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Quasi restricted maximum likelihood (qREML) algorithm for models with penalised splines or simple i.i.d. random effects — qreml","text":"","code":"data = elephant[1:1000,] # subset  # initial parameter list par = list(logmu = log(c(0.3, 1)), # step mean            logsigma = log(c(0.2, 0.7)), # step sd            beta0 = c(-2,2), # state process intercept            betaspline = matrix(rep(0, 18), nrow = 2)) # state process spline coefs            # data object with initial penalty strength lambda dat = list(step = data$step, # step length            tod = data$tod, # time of day covariate            N = 2, # number of states            lambda = rep(10,2)) # initial penalty strength  # building model matrices modmat = make_matrices(~ s(tod, bs = \"cp\"),                         data = data.frame(tod = 1:24),                         knots = list(tod = c(0,24))) # wrapping points dat$Z = modmat$Z # spline design matrix dat$S = modmat$S # penalty matrix  # penalized negative log-likelihood function pnll = function(par) {   getAll(par, dat) # makes everything contained available without $   Gamma = tpm_g(Z, cbind(beta0, betaspline), ad = TRUE) # transition probabilities   delta = stationary_p(Gamma, t = 1, ad = TRUE) # initial distribution   mu = exp(logmu) # step mean   sigma = exp(logsigma) # step sd   # calculating all state-dependent densities   allprobs = matrix(1, nrow = length(step), ncol = N)   ind = which(!is.na(step)) # only for non-NA obs.   for(j in 1:N) allprobs[ind,j] = dgamma2(step[ind],mu[j],sigma[j])   -forward_g(delta, Gamma[,,tod], allprobs, ad = TRUE) +       penalty(betaspline, S, lambda) # this does all the penalization work }  # model fitting mod = qreml(pnll, par, dat, random = \"betaspline\") #> Creating AD function #> Initializing with lambda: 10 10  #> outer 1 - lambda: 3.636 2.859  #> outer 2 - lambda: 1.691 1.652  #> outer 3 - lambda: 0.967 1.184  #> outer 4 - lambda: 0.671 0.919  #> outer 5 - lambda: 0.546 0.739  #> outer 6 - lambda: 0.493 0.603  #> outer 7 - lambda: 0.472 0.494  #> outer 8 - lambda: 0.464 0.406  #> outer 9 - lambda: 0.463 0.334  #> outer 10 - lambda: 0.464 0.276  #> outer 11 - lambda: 0.467 0.23  #> outer 12 - lambda: 0.471 0.194  #> outer 13 - lambda: 0.474 0.166  #> outer 14 - lambda: 0.477 0.146  #> outer 15 - lambda: 0.48 0.131  #> outer 16 - lambda: 0.483 0.12  #> outer 17 - lambda: 0.484 0.112  #> outer 18 - lambda: 0.486 0.106  #> outer 19 - lambda: 0.487 0.102  #> outer 20 - lambda: 0.488 0.099  #> outer 21 - lambda: 0.489 0.097  #> outer 22 - lambda: 0.489 0.095  #> outer 23 - lambda: 0.49 0.094  #> outer 24 - lambda: 0.49 0.093  #> outer 25 - lambda: 0.49 0.093  #> outer 26 - lambda: 0.49 0.092  #> outer 27 - lambda: 0.49 0.092  #> outer 28 - lambda: 0.49 0.092  #> outer 29 - lambda: 0.49 0.092  #> outer 30 - lambda: 0.49 0.092  #> Converged"},{"path":"https://janoleko.github.io/reference/sdreportMC.html","id":null,"dir":"Reference","previous_headings":"","what":"Monte Carlo version of sdreport — sdreportMC","title":"Monte Carlo version of sdreport — sdreportMC","text":"optimization AD model, sdreportMC can used calculate samples confidence intervals model parameters REPORT()ed quantities including non linear functions random effects parameters.","code":""},{"path":"https://janoleko.github.io/reference/sdreportMC.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Monte Carlo version of sdreport — sdreportMC","text":"","code":"sdreportMC(   obj,   what,   Hessian = NULL,   CI = FALSE,   n = 1000,   probs = c(0.025, 0.975) )"},{"path":"https://janoleko.github.io/reference/sdreportMC.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Monte Carlo version of sdreport — sdreportMC","text":"obj Object returned MakeADFun() optimization Vector strings names parameters REPORT()ed quantities reported Hessian Optional Hessian matrix. provided, computed object CI Logical. TRUE, confidence intervals instead samples returned n Number samples draw multivariate normal distribution MLE probs Vector probabilities confidence intervals (ignored CIs computed)","code":""},{"path":"https://janoleko.github.io/reference/sdreportMC.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Monte Carlo version of sdreport — sdreportMC","text":"Named list corresponding elements . element structure corresponding quantity additional dimension added samples. example, quantity vector, list contains matrix. quantity matrix, list contains array.","code":""},{"path":"https://janoleko.github.io/reference/sdreportMC.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Monte Carlo version of sdreport — sdreportMC","text":"","code":"# currently no examples"},{"path":"https://janoleko.github.io/reference/stateprobs.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate conditional local state probabilities for homogeneous HMMs — stateprobs","title":"Calculate conditional local state probabilities for homogeneous HMMs — stateprobs","text":"Computes $$\\Pr(S_t = j \\mid X_1, ..., X_T)$$ homogeneous HMMs","code":""},{"path":"https://janoleko.github.io/reference/stateprobs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate conditional local state probabilities for homogeneous HMMs — stateprobs","text":"","code":"stateprobs(delta, Gamma, allprobs, trackID = NULL)"},{"path":"https://janoleko.github.io/reference/stateprobs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate conditional local state probabilities for homogeneous HMMs — stateprobs","text":"delta initial stationary distribution length N, matrix dimension c(k,N) k independent tracks, trackID provided Gamma transition probability matrix dimension c(N,N), array k transition probability matrices dimension c(N,N,k), trackID provided allprobs matrix state-dependent probabilities/ density values dimension c(n, N) trackID optional vector length n containing IDs provided, total log-likelihood sum track's likelihood contribution. case, Gamma can matrix, leading transition probabilities track, array dimension c(N,N,k), one (homogeneous) transition probability matrix track. Furthermore, instead single vector delta corresponding initial distribution, delta matrix initial distributions, dimension c(k,N), can provided, track starts initial distribution.","code":""},{"path":"https://janoleko.github.io/reference/stateprobs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate conditional local state probabilities for homogeneous HMMs — stateprobs","text":"matrix conditional state probabilities dimension c(n,N)","code":""},{"path":"https://janoleko.github.io/reference/stateprobs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate conditional local state probabilities for homogeneous HMMs — stateprobs","text":"","code":"Gamma = tpm(c(-1,-2)) delta = stationary(Gamma) allprobs = matrix(runif(200), nrow = 100, ncol = 2)  probs = stateprobs(delta, Gamma, allprobs)"},{"path":"https://janoleko.github.io/reference/stateprobs_g.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate conditional local state probabilities for inhomogeneous HMMs — stateprobs_g","title":"Calculate conditional local state probabilities for inhomogeneous HMMs — stateprobs_g","text":"Computes $$\\Pr(S_t = j \\mid X_1, ..., X_T)$$ inhomogeneous HMMs","code":""},{"path":"https://janoleko.github.io/reference/stateprobs_g.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate conditional local state probabilities for inhomogeneous HMMs — stateprobs_g","text":"","code":"stateprobs_g(delta, Gamma, allprobs, trackID = NULL)"},{"path":"https://janoleko.github.io/reference/stateprobs_g.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate conditional local state probabilities for inhomogeneous HMMs — stateprobs_g","text":"delta initial stationary distribution length N, matrix dimension c(k,N) k independent tracks, trackID provided Gamma array transition probability matrices dimension c(N,N,n-1), time series length n, n-1 transitions array dimension c(N,N,n) single track provided, first slice ignored. trackID provided, Gamma needs array dimension c(N,N,n), n number rows allprobs. track first transition matrix ignored. allprobs matrix state-dependent probabilities/ density values dimension c(n, N) trackID optional vector k track IDs, multiple tracks need decoded separately","code":""},{"path":"https://janoleko.github.io/reference/stateprobs_g.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate conditional local state probabilities for inhomogeneous HMMs — stateprobs_g","text":"matrix conditional state probabilities dimension c(n,N)","code":""},{"path":"https://janoleko.github.io/reference/stateprobs_g.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate conditional local state probabilities for inhomogeneous HMMs — stateprobs_g","text":"","code":"Gamma = tpm_g(runif(99), matrix(c(-1,-1,1,-2), nrow = 2, byrow = TRUE)) delta = c(0.5, 0.5) allprobs = matrix(runif(200), nrow = 100, ncol = 2)  probs = stateprobs_g(delta, Gamma, allprobs)"},{"path":"https://janoleko.github.io/reference/stateprobs_p.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate conditional local state probabilities for periodically inhomogeneous HMMs — stateprobs_p","title":"Calculate conditional local state probabilities for periodically inhomogeneous HMMs — stateprobs_p","text":"Computes $$\\Pr(S_t = j \\mid X_1, ..., X_T)$$ periodically inhomogeneous HMMs","code":""},{"path":"https://janoleko.github.io/reference/stateprobs_p.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate conditional local state probabilities for periodically inhomogeneous HMMs — stateprobs_p","text":"","code":"stateprobs_p(delta, Gamma, allprobs, tod, trackID = NULL)"},{"path":"https://janoleko.github.io/reference/stateprobs_p.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate conditional local state probabilities for periodically inhomogeneous HMMs — stateprobs_p","text":"delta initial stationary distribution length N, matrix dimension c(k,N) k independent tracks, trackID provided e.g. periodically stationary distribution (track) computed stationary_p. Gamma array transition probability matrices time point cycle dimension c(N,N,L), L length cycle. allprobs matrix state-dependent probabilities/ density values dimension c(n, N) tod (Integer valued) variable cycle indexing 1, ..., L, mapping data index generalised time day (length n). half-hourly data L = 48. , however, also day year daily data L = 365. trackID optional vector k track IDs, multiple tracks need decoded separately","code":""},{"path":"https://janoleko.github.io/reference/stateprobs_p.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate conditional local state probabilities for periodically inhomogeneous HMMs — stateprobs_p","text":"matrix conditional state probabilities dimension c(n,N)","code":""},{"path":"https://janoleko.github.io/reference/stateprobs_p.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate conditional local state probabilities for periodically inhomogeneous HMMs — stateprobs_p","text":"","code":"L = 24 beta = matrix(c(-1, 2, -1, -2, 1, -1), nrow = 2, byrow = TRUE) Gamma = tpm_p(1:L, L, beta, degree = 1) delta = stationary_p(Gamma, 1) allprobs = matrix(runif(200), nrow = 100, ncol = 2) tod = rep(1:24, 5)[1:100]  probs = stateprobs_p(delta, Gamma, allprobs, tod)"},{"path":"https://janoleko.github.io/reference/stationary.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the stationary distribution of a homogeneous Markov chain — stationary","title":"Compute the stationary distribution of a homogeneous Markov chain — stationary","text":"homogeneous, finite state Markov chain irreducible aperiodic converges unique stationary distribution, called \\(\\delta\\). stationary, distribution satisfies $$\\delta \\Gamma = \\delta,$$ subject \\(\\sum_{j=1}^N \\delta_j = 1\\), \\(\\Gamma\\) transition probability matrix. function solves linear system equations .","code":""},{"path":"https://janoleko.github.io/reference/stationary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the stationary distribution of a homogeneous Markov chain — stationary","text":"","code":"stationary(Gamma)"},{"path":"https://janoleko.github.io/reference/stationary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the stationary distribution of a homogeneous Markov chain — stationary","text":"Gamma transition probability matrix dimension c(N,N)","code":""},{"path":"https://janoleko.github.io/reference/stationary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the stationary distribution of a homogeneous Markov chain — stationary","text":"stationary distribution Markov chain given transition probability matrix","code":""},{"path":"https://janoleko.github.io/reference/stationary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute the stationary distribution of a homogeneous Markov chain — stationary","text":"","code":"Gamma = tpm(c(rep(-2,3), rep(-3,3))) delta = stationary(Gamma)"},{"path":"https://janoleko.github.io/reference/stationary_cont.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the stationary distribution of a continuous-time Markov chain — stationary_cont","title":"Compute the stationary distribution of a continuous-time Markov chain — stationary_cont","text":"well-behaved continuous-time Markov chain converges unique stationary distribution, called \\(\\pi\\). distribution satisfies $$\\pi Q = 0,$$ subject \\(\\sum_{j=1}^N \\pi_j = 1\\), \\(Q\\) infinitesimal generator Markov chain. function solves linear system equations .","code":""},{"path":"https://janoleko.github.io/reference/stationary_cont.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the stationary distribution of a continuous-time Markov chain — stationary_cont","text":"","code":"stationary_cont(Q)"},{"path":"https://janoleko.github.io/reference/stationary_cont.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the stationary distribution of a continuous-time Markov chain — stationary_cont","text":"Q infinitesimal generator matrix dimension c(N,N)","code":""},{"path":"https://janoleko.github.io/reference/stationary_cont.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the stationary distribution of a continuous-time Markov chain — stationary_cont","text":"stationary distribution continuous-time Markov chain given generator matrix","code":""},{"path":"https://janoleko.github.io/reference/stationary_cont.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute the stationary distribution of a continuous-time Markov chain — stationary_cont","text":"","code":"Q = generator(c(-2,-2)) Pi = stationary_cont(Q)"},{"path":"https://janoleko.github.io/reference/stationary_p.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the periodically stationary distribution of a periodically inhomogeneous Markov chain — stationary_p","title":"Compute the periodically stationary distribution of a periodically inhomogeneous Markov chain — stationary_p","text":"transition probability matrix inhomogeneous Markov chain varies periodically (period length \\(L\\)), converges -called periodically stationary distribution. happens, thinned Markov chain, full cycle time step, homogeneous transition probability matrix $$\\Gamma_t = \\Gamma^{(t)} \\Gamma^{(t+1)} \\dots \\Gamma^{(t+L-1)}$$ \\(t = 1, \\dots, L.\\) stationary distribution time \\(t\\) satifies \\(\\delta^{(t)} \\Gamma_t = \\delta^{(t)}\\). function calculates said periodically stationary distribution.","code":""},{"path":"https://janoleko.github.io/reference/stationary_p.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the periodically stationary distribution of a periodically inhomogeneous Markov chain — stationary_p","text":"","code":"stationary_p(Gamma, t = NULL, ad = NULL)"},{"path":"https://janoleko.github.io/reference/stationary_p.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the periodically stationary distribution of a periodically inhomogeneous Markov chain — stationary_p","text":"Gamma array transition probability matrices dimension c(N,N,L) t integer index time point cycle, calculate stationary distribution t provided, function calculates stationary distributions time point cycle. ad optional logical, indicating whether automatic differentiation RTMB used. default, function determines .","code":""},{"path":"https://janoleko.github.io/reference/stationary_p.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the periodically stationary distribution of a periodically inhomogeneous Markov chain — stationary_p","text":"either periodically stationary distribution time t periodically stationary distributions.","code":""},{"path":"https://janoleko.github.io/reference/stationary_p.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute the periodically stationary distribution of a periodically inhomogeneous Markov chain — stationary_p","text":"","code":"L = 24 beta = matrix(c(-1, 2, -1, -2, 1, -1), nrow = 2, byrow = TRUE) Gamma = tpm_p(1:L, L, beta, degree = 1) # Periodically stationary distribution for specific time point delta = stationary_p(Gamma, 4)  # All periodically stationary distributions Delta = stationary_p(Gamma)"},{"path":"https://janoleko.github.io/reference/stationary_p_sparse.html","id":null,"dir":"Reference","previous_headings":"","what":"Sparse version of stationary_p — stationary_p_sparse","title":"Sparse version of stationary_p — stationary_p_sparse","text":"function computes periodically stationary distribution Markov chain given list L sparse transition probability matrices. Compatible automatic differentiation RTMB","code":""},{"path":"https://janoleko.github.io/reference/stationary_p_sparse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sparse version of stationary_p — stationary_p_sparse","text":"","code":"stationary_p_sparse(Gamma, t = NULL)"},{"path":"https://janoleko.github.io/reference/stationary_p_sparse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sparse version of stationary_p — stationary_p_sparse","text":"Gamma sist length L containing sparse transition probability matrices one cycle. t integer index time point cycle, calculate stationary distribution t provided, function calculates stationary distributions time point cycle.","code":""},{"path":"https://janoleko.github.io/reference/stationary_p_sparse.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sparse version of stationary_p — stationary_p_sparse","text":"either periodically stationary distribution time t periodically stationary distributions.","code":""},{"path":"https://janoleko.github.io/reference/stationary_p_sparse.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sparse version of stationary_p — stationary_p_sparse","text":"","code":"## periodic HSMM example (here the approximating tpm is sparse) N = 2 # number of states L = 24 # cycle length # time-varying mean dwell times Z = trigBasisExp(1:L) # trigonometric basis functions design matrix beta = matrix(c(2, 2, 0.1, -0.1, -0.2, 0.2), nrow = 2) Lambda = exp(cbind(1, Z) %*% t(beta)) sizes = c(20, 20) # approximating chain with 40 states # state dwell-time distributions dm = lapply(1:N, function(i) sapply(1:sizes[i]-1, dpois, lambda = Lambda[,i])) omega = matrix(c(0,1,1,0), nrow = N, byrow = TRUE) # embedded t.p.m.  # calculating extended-state-space t.p.m.s Gamma = tpm_phsmm(omega, dm) # Periodically stationary distribution for specific time point delta = stationary_p_sparse(Gamma, 4)  # All periodically stationary distributions Delta = stationary_p_sparse(Gamma)"},{"path":"https://janoleko.github.io/reference/stationary_sparse.html","id":null,"dir":"Reference","previous_headings":"","what":"Sparse version of stationary — stationary_sparse","title":"Sparse version of stationary — stationary_sparse","text":"function computes stationary distribution Markov chain given sparse transition probability matrix. Compatible automatic differentiation RTMB","code":""},{"path":"https://janoleko.github.io/reference/stationary_sparse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sparse version of stationary — stationary_sparse","text":"","code":"stationary_sparse(Gamma)"},{"path":"https://janoleko.github.io/reference/stationary_sparse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sparse version of stationary — stationary_sparse","text":"Gamma sparse transition probability matrix dimension c(N,N)","code":""},{"path":"https://janoleko.github.io/reference/stationary_sparse.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sparse version of stationary — stationary_sparse","text":"stationary distribution Markov chain given transition probability matrix","code":""},{"path":"https://janoleko.github.io/reference/stationary_sparse.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sparse version of stationary — stationary_sparse","text":"","code":"## HSMM example (here the approximating tpm is sparse) # building the t.p.m. of the embedded Markov chain omega = matrix(c(0,1,1,0), nrow = 2, byrow = TRUE) # defining state aggregate sizes sizes = c(20, 30) # defining state dwell-time distributions lambda = c(5, 11) dm = list(dpois(1:sizes[1]-1, lambda[1]), dpois(1:sizes[2]-1, lambda[2])) # calculating extended-state-space t.p.m. Gamma = tpm_hsmm(omega, dm) delta = stationary_sparse(Gamma)"},{"path":"https://janoleko.github.io/reference/tpm.html","id":null,"dir":"Reference","previous_headings":"","what":"Build the transition probability matrix from unconstrained parameter vector — tpm","title":"Build the transition probability matrix from unconstrained parameter vector — tpm","text":"Markov chains parametrised terms transition probability matrix \\(\\Gamma\\), row contains conditional probability distribution next state given current state. Hence, row entries 0 1 need sum one. numerical optimisation, parametrise terms unconstrained parameters, thus function computes said matrix unconstrained paramter vector via inverse multinomial logistic link (also known softmax) applied row.","code":""},{"path":"https://janoleko.github.io/reference/tpm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build the transition probability matrix from unconstrained parameter vector — tpm","text":"","code":"tpm(param, byrow = FALSE)"},{"path":"https://janoleko.github.io/reference/tpm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build the transition probability matrix from unconstrained parameter vector — tpm","text":"param unconstraint parameter vector length N*(N-1) N number states Markov chain byrow logical indicating transition probability matrix filled row Defaults FALSE, set TRUE one wants work matrix beta parameters returned popular HMM packages like moveHMM, momentuHMM, hmmTMB.","code":""},{"path":"https://janoleko.github.io/reference/tpm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build the transition probability matrix from unconstrained parameter vector — tpm","text":"Transition probability matrix dimension c(N,N)","code":""},{"path":"https://janoleko.github.io/reference/tpm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Build the transition probability matrix from unconstrained parameter vector — tpm","text":"","code":"# 2 states: 2 free off-diagonal elements param1 = rep(-1, 2) Gamma1 = tpm(param1)  # 3 states: 6 free off-diagonal elements param2 = rep(-2, 6) Gamma2 = tpm(param2)"},{"path":"https://janoleko.github.io/reference/tpm_cont.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate continuous time transition probabilities — tpm_cont","title":"Calculate continuous time transition probabilities — tpm_cont","text":"continuous-time Markov chain described infinitesimal generator matrix \\(Q\\). observing data time points \\(t_1, \\dots, t_n\\) transition probabilites \\(t_i\\) \\(t_{+1}\\) caluclated $$\\Gamma(\\Delta t_i) = \\exp(Q \\Delta t_i),$$ \\(\\exp()\\) matrix exponential. mapping \\(\\Gamma(\\Delta t)\\) also called Markov semigroup. function calculates transition matrices based given generator time differences.","code":""},{"path":"https://janoleko.github.io/reference/tpm_cont.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate continuous time transition probabilities — tpm_cont","text":"","code":"tpm_cont(Q, timediff, ad = NULL, report = TRUE)"},{"path":"https://janoleko.github.io/reference/tpm_cont.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate continuous time transition probabilities — tpm_cont","text":"Q infinitesimal generator matrix continuous-time Markov chain dimension c(N,N) timediff time differences observations length n-1 based n observations ad optional logical, indicating whether automatic differentiation RTMB used. default, function determines . report logical, indicating whether Q reported fitted model. Defaults TRUE, works ad = TRUE.","code":""},{"path":"https://janoleko.github.io/reference/tpm_cont.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate continuous time transition probabilities — tpm_cont","text":"array continuous-time transition matrices dimension c(N,N,n-1)","code":""},{"path":"https://janoleko.github.io/reference/tpm_cont.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate continuous time transition probabilities — tpm_cont","text":"","code":"# building a Q matrix for a 3-state cont.-time Markov chain Q = diag(3) Q[!Q] = rexp(6) diag(Q) = 0 diag(Q) = - rowSums(Q)  # draw time differences timediff = rexp(1000, 10)  Gamma = tpm_cont(Q, timediff)"},{"path":"https://janoleko.github.io/reference/tpm_emb.html","id":null,"dir":"Reference","previous_headings":"","what":"Build the embedded transition probability matrix of an HSMM from unconstrained parameter vector — tpm_emb","title":"Build the embedded transition probability matrix of an HSMM from unconstrained parameter vector — tpm_emb","text":"Hidden semi-Markov models defined terms state durations embedded transition probability matrix contains conditional transition probabilities given current state left. matrix necessarily diagonal entries equal zero self-transitions impossible. function builds embedded/ conditional transition probability matrix unconstrained parameter vector. row matrix, inverse multinomial logistic link applied. matrix dimension c(N,N), number free -diagonal elements N*(N-2), hence also length param. means, 2 states, function needs called without arguments, 3-states vector length 3, 4 states vector length 8, etc. Compatible automatic differentiation RTMB","code":""},{"path":"https://janoleko.github.io/reference/tpm_emb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build the embedded transition probability matrix of an HSMM from unconstrained parameter vector — tpm_emb","text":"","code":"tpm_emb(param = NULL)"},{"path":"https://janoleko.github.io/reference/tpm_emb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build the embedded transition probability matrix of an HSMM from unconstrained parameter vector — tpm_emb","text":"param unconstrained parameter vector length N*(N-2) N number states Markov chain function called without param, return conditional transition probability matrix 2-state HSMM, fixed 0 diagonal entries -diagonal entries equal 1.","code":""},{"path":"https://janoleko.github.io/reference/tpm_emb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build the embedded transition probability matrix of an HSMM from unconstrained parameter vector — tpm_emb","text":"embedded/ conditional transition probability matrix dimension c(N,N)","code":""},{"path":"https://janoleko.github.io/reference/tpm_emb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Build the embedded transition probability matrix of an HSMM from unconstrained parameter vector — tpm_emb","text":"","code":"# 2 states: no free off-diagonal elements omega = tpm_emb()  # 3 states: 3 free off-diagonal elements param = rep(0, 3) omega = tpm_emb(param)  # 4 states: 8 free off-diagonal elements param = rep(0, 8) omega = tpm_emb(param)"},{"path":"https://janoleko.github.io/reference/tpm_emb_g.html","id":null,"dir":"Reference","previous_headings":"","what":"Build all embedded transition probability matrices of an inhomogeneous HSMM — tpm_emb_g","title":"Build all embedded transition probability matrices of an inhomogeneous HSMM — tpm_emb_g","text":"Hidden semi-Markov models defined terms state durations embedded transition probability matrix contains conditional transition probabilities given current state left. matrix necessarily diagonal entries equal zero self-transitions impossible. can allow matrix vary covariates, purpose function. builds embedded/ conditional transition probability matrices based design parameter matrix. row matrix, inverse multinomial logistic link applied. matrix dimension c(N,N), number free -diagonal elements N*(N-2) determines number rows parameter matrix. Compatible automatic differentiation RTMB","code":""},{"path":"https://janoleko.github.io/reference/tpm_emb_g.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build all embedded transition probability matrices of an inhomogeneous HSMM — tpm_emb_g","text":"","code":"tpm_emb_g(Z, beta, report = TRUE)"},{"path":"https://janoleko.github.io/reference/tpm_emb_g.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build all embedded transition probability matrices of an inhomogeneous HSMM — tpm_emb_g","text":"Z covariate design matrix without intercept column, .e. dimension c(n, p) c(n, p+1) Z p columns, intercept column ones added automatically. beta matrix coefficients -diagonal elements embedded transition probability matrix Needs dimension c(N*(N-2), p+1), first column contains intercepts. p can 0, case model homogeneous. report logical, indicating whether coefficient matrix beta reported fitted model. Defaults TRUE.","code":""},{"path":"https://janoleko.github.io/reference/tpm_emb_g.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build all embedded transition probability matrices of an inhomogeneous HSMM — tpm_emb_g","text":"array embedded/ conditional transition probability matrices dimension c(N,N,n)","code":""},{"path":"https://janoleko.github.io/reference/tpm_emb_g.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Build all embedded transition probability matrices of an inhomogeneous HSMM — tpm_emb_g","text":"","code":"## parameter matrix for 3-state HSMM beta = matrix(c(rep(0, 3), -0.2, 0.2, 0.1), nrow = 3) # no intercept Z = rnorm(100) omega = tpm_emb_g(Z, beta) # intercept Z = cbind(1, Z) omega = tpm_emb_g(Z, beta)"},{"path":"https://janoleko.github.io/reference/tpm_g.html","id":null,"dir":"Reference","previous_headings":"","what":"Build all transition probability matrices of an inhomogeneous HMM — tpm_g","title":"Build all transition probability matrices of an inhomogeneous HMM — tpm_g","text":"HMM, model influence covariates state process linking transition probabiltiy matrix. commonly, done specifying linear predictor $$ \\eta_{ij}^{(t)} = \\beta^{(ij)}_0 + \\beta^{(ij)}_1 z_{t1} + \\dots + \\beta^{(ij)}_p z_{tp} $$ -diagonal element (\\(\\neq j\\)) transition probability matrix applying inverse multinomial logistic link (also known softmax) row. function efficiently calculates transition probabilty matrices given design matrix \\(Z\\) parameter matrix beta.","code":""},{"path":"https://janoleko.github.io/reference/tpm_g.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build all transition probability matrices of an inhomogeneous HMM — tpm_g","text":"","code":"tpm_g(Z, beta, byrow = FALSE, ad = NULL, report = TRUE)"},{"path":"https://janoleko.github.io/reference/tpm_g.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build all transition probability matrices of an inhomogeneous HMM — tpm_g","text":"Z covariate design matrix without intercept column, .e. dimension c(n, p) c(n, p+1) Z p columns, intercept column ones added automatically. beta matrix coefficients -diagonal elements transition probability matrix Needs dimension c(N*(N-1), p+1), first column contains intercepts. byrow logical indicating transition probability matrix filled row Defaults FALSE, set TRUE one wants work matrix beta parameters returned popular HMM packages like moveHMM, momentuHMM, hmmTMB. ad optional logical, indicating whether automatic differentiation RTMB used. default, function determines . report logical, indicating whether coefficient matrix beta reported fitted model. Defaults TRUE, works ad = TRUE.","code":""},{"path":"https://janoleko.github.io/reference/tpm_g.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build all transition probability matrices of an inhomogeneous HMM — tpm_g","text":"array transition probability matrices dimension c(N,N,n)","code":""},{"path":"https://janoleko.github.io/reference/tpm_g.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Build all transition probability matrices of an inhomogeneous HMM — tpm_g","text":"","code":"n = 1000 Z = matrix(runif(n*2), ncol = 2) beta = matrix(c(-1, 1, 2, -2, 1, -2), nrow = 2, byrow = TRUE) Gamma = tpm_g(Z, beta)"},{"path":"https://janoleko.github.io/reference/tpm_hsmm.html","id":null,"dir":"Reference","previous_headings":"","what":"Builds the transition probability matrix of an HSMM-approximating HMM — tpm_hsmm","title":"Builds the transition probability matrix of an HSMM-approximating HMM — tpm_hsmm","text":"Hidden semi-Markov models (HSMMs) flexible extension HMMs, state duration distribution explicitly modelled. direct numerical maximum likelhood estimation, HSMMs can represented HMMs enlarged state space (size \\(M\\)) structured transition probabilities. function computes transition matrix approximate given HSMM HMM larger state space.","code":""},{"path":"https://janoleko.github.io/reference/tpm_hsmm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Builds the transition probability matrix of an HSMM-approximating HMM — tpm_hsmm","text":"","code":"tpm_hsmm(omega, dm, Fm = NULL, sparse = TRUE, eps = 1e-10)"},{"path":"https://janoleko.github.io/reference/tpm_hsmm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Builds the transition probability matrix of an HSMM-approximating HMM — tpm_hsmm","text":"omega embedded transition probability matrix dimension c(N,N) computed tpm_emb. dm state dwell-time distributions arranged list length(N). list element needs vector length N_i, N_i state aggregate size. Fm optional list length N containing cumulative distribution functions dwell-time distributions. sparse logical, indicating whether output sparse matrix. Defaults TRUE. eps rounding value: entry transition probabily matrix smaller, rounded zero. Usually, changed.","code":""},{"path":"https://janoleko.github.io/reference/tpm_hsmm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Builds the transition probability matrix of an HSMM-approximating HMM — tpm_hsmm","text":"extended-state-space transition probability matrix approximating HMM","code":""},{"path":"https://janoleko.github.io/reference/tpm_hsmm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Builds the transition probability matrix of an HSMM-approximating HMM — tpm_hsmm","text":"","code":"# building the t.p.m. of the embedded Markov chain omega = matrix(c(0,1,1,0), nrow = 2, byrow = TRUE) # defining state aggregate sizes sizes = c(20, 30) # defining state dwell-time distributions lambda = c(5, 11) dm = list(dpois(1:sizes[1]-1, lambda[1]), dpois(1:sizes[2]-1, lambda[2])) # calculating extended-state-space t.p.m. Gamma = tpm_hsmm(omega, dm)"},{"path":"https://janoleko.github.io/reference/tpm_hsmm2.html","id":null,"dir":"Reference","previous_headings":"","what":"Build the transition probability matrix of an HSMM-approximating HMM — tpm_hsmm2","title":"Build the transition probability matrix of an HSMM-approximating HMM — tpm_hsmm2","text":"Hidden semi-Markov models (HSMMs) flexible extension HMMs. direct numerical maximum likelhood estimation, HSMMs can represented HMMs enlarged state space (size \\(M\\)) structured transition probabilities. function computes transition matrix HSMM.","code":""},{"path":"https://janoleko.github.io/reference/tpm_hsmm2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build the transition probability matrix of an HSMM-approximating HMM — tpm_hsmm2","text":"","code":"tpm_hsmm2(omega, dm, eps = 1e-10)"},{"path":"https://janoleko.github.io/reference/tpm_hsmm2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build the transition probability matrix of an HSMM-approximating HMM — tpm_hsmm2","text":"omega embedded transition probability matrix dimension c(N,N) dm state dwell-time distributions arranged list length(N). list element needs vector length N_i, N_i state aggregate size. eps rounding value: entry transition probabily matrix smaller, rounded zero.","code":""},{"path":"https://janoleko.github.io/reference/tpm_hsmm2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build the transition probability matrix of an HSMM-approximating HMM — tpm_hsmm2","text":"extended-state-space transition probability matrix approximating HMM","code":""},{"path":"https://janoleko.github.io/reference/tpm_hsmm2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Build the transition probability matrix of an HSMM-approximating HMM — tpm_hsmm2","text":"","code":"# building the t.p.m. of the embedded Markov chain omega = matrix(c(0,1,1,0), nrow = 2, byrow = TRUE) # defining state aggregate sizes sizes = c(20, 30) # defining state dwell-time distributions lambda = c(5, 11) dm = list(dpois(1:sizes[1]-1, lambda[1]), dpois(1:sizes[2]-1, lambda[2])) # calculating extended-state-space t.p.m. Gamma = tpm_hsmm(omega, dm)"},{"path":"https://janoleko.github.io/reference/tpm_ihsmm.html","id":null,"dir":"Reference","previous_headings":"","what":"Builds all transition probability matrices of an inhomogeneous-HSMM-approximating HMM — tpm_ihsmm","title":"Builds all transition probability matrices of an inhomogeneous-HSMM-approximating HMM — tpm_ihsmm","text":"Hidden semi-Markov models (HSMMs) flexible extension HMMs. direct numerical maximum likelhood estimation, HSMMs can represented HMMs enlarged state space (size \\(M\\)) structured transition probabilities. function computes transition matrices periodically inhomogeneos HSMMs.","code":""},{"path":"https://janoleko.github.io/reference/tpm_ihsmm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Builds all transition probability matrices of an inhomogeneous-HSMM-approximating HMM — tpm_ihsmm","text":"","code":"tpm_ihsmm(omega, dm, eps = 1e-10)"},{"path":"https://janoleko.github.io/reference/tpm_ihsmm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Builds all transition probability matrices of an inhomogeneous-HSMM-approximating HMM — tpm_ihsmm","text":"omega embedded transition probability matrix Either matrix dimension c(N,N) homogeneous conditional transition probabilities (computed tpm_emb), array dimension c(N,N,n) inhomogeneous conditional transition probabilities (computed tpm_emb_g). dm state dwell-time distributions arranged list length N list element needs matrix dimension c(n, N_i), row t (approximate) probability mass function state time t. eps rounding value: entry transition probabily matrix smaller, rounded zero. Usually, changed.","code":""},{"path":"https://janoleko.github.io/reference/tpm_ihsmm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Builds all transition probability matrices of an inhomogeneous-HSMM-approximating HMM — tpm_ihsmm","text":"list dimension length n - max(sapply(dm, ncol)), containing sparse extended-state-space transition probability matrices time point (except first max(sapply(dm, ncol)) - 1).","code":""},{"path":"https://janoleko.github.io/reference/tpm_ihsmm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Builds all transition probability matrices of an inhomogeneous-HSMM-approximating HMM — tpm_ihsmm","text":"","code":"N = 2 # time-varying mean dwell times n = 100 z = runif(n) beta = matrix(c(2, 2, 0.1, -0.1), nrow = 2) Lambda = exp(cbind(1, z) %*% t(beta)) sizes = c(15, 15) # approximating chain with 30 states # state dwell-time distributions dm = lapply(1:N, function(i) sapply(1:sizes[i]-1, dpois, lambda = Lambda[,i]))  ## homogeneous conditional transition probabilites # diagonal elements are zero, rowsums are one omega = matrix(c(0,1,1,0), nrow = N, byrow = TRUE)  # calculating extended-state-space t.p.m.s Gamma = tpm_ihsmm(omega, dm)  ## inhomogeneous conditional transition probabilites # omega can be an array omega = array(omega, dim = c(N,N,n))  # calculating extended-state-space t.p.m.s Gamma = tpm_ihsmm(omega, dm)"},{"path":"https://janoleko.github.io/reference/tpm_p.html","id":null,"dir":"Reference","previous_headings":"","what":"Build all transition probability matrices of a periodically inhomogeneous HMM — tpm_p","title":"Build all transition probability matrices of a periodically inhomogeneous HMM — tpm_p","text":"Given periodically varying variable time day day year associated cycle length, function calculates transition probability matrices applying inverse multinomial logistic link (also known softmax) linear predictors form $$  \\eta^{(t)}_{ij} = \\beta_0^{(ij)} + \\sum_{k=1}^K \\bigl( \\beta_{1k}^{(ij)} \\sin(\\frac{2 \\pi k t}{L}) + \\beta_{2k}^{(ij)} \\cos(\\frac{2 \\pi k t}{L}) \\bigr) $$ -diagonal elements (\\(\\neq j\\)) transition probability matrix. relevant modeling e.g. diurnal variation flexibility can increased adding smaller frequencies (.e. increasing \\(K\\)).","code":""},{"path":"https://janoleko.github.io/reference/tpm_p.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build all transition probability matrices of a periodically inhomogeneous HMM — tpm_p","text":"","code":"tpm_p(   tod = 1:24,   L = 24,   beta,   degree = 1,   Z = NULL,   byrow = FALSE,   ad = NULL,   report = TRUE )"},{"path":"https://janoleko.github.io/reference/tpm_p.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build all transition probability matrices of a periodically inhomogeneous HMM — tpm_p","text":"tod equidistant sequence cyclic variable time day e.g. half-hourly data, 1, ..., L L = 48, 0.5, 1, 1.5, ..., 24 L = 24. L length one full cycle, scale tod beta matrix coefficients -diagonal elements transition probability matrix Needs dimension c(N *(N-1), 2*degree+1), first column contains intercepts. degree degree trigonometric link function additional degree, one sine one cosine frequency added. Z pre-calculated design matrix (excluding intercept column) Defaults NULL trigonometric link calculated. efficiency perspective, Z pre-calculated within likelihood function, basis expansion redundantly calculated. can done using trigBasisExp. byrow logical indicating transition probability matrix filled row Defaults FALSE, set TRUE one wants work matrix beta parameters returned popular HMM packages like moveHMM, momentuHMM, hmmTMB. ad optional logical, indicating whether automatic differentiation RTMB used. default, function determines . report logical, indicating whether coefficient matrix beta reported fitted model. Defaults TRUE, works ad = TRUE.","code":""},{"path":"https://janoleko.github.io/reference/tpm_p.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build all transition probability matrices of a periodically inhomogeneous HMM — tpm_p","text":"array transition probability matrices dimension c(N,N,length(tod))","code":""},{"path":"https://janoleko.github.io/reference/tpm_p.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Build all transition probability matrices of a periodically inhomogeneous HMM — tpm_p","text":"Note using function inside negative log-likelihood function convenient, performs basis expansion sine cosine terms time called. change optimisation, using tpm_g pre-calculated (trigBasisExp) design matrix efficient.","code":""},{"path":"https://janoleko.github.io/reference/tpm_p.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Build all transition probability matrices of a periodically inhomogeneous HMM — tpm_p","text":"","code":"# hourly data  tod = seq(1, 24, by = 1) L = 24 beta = matrix(c(-1, 2, -1, -2, 1, -1), nrow = 2, byrow = TRUE) Gamma = tpm_p(tod, L, beta, degree = 1)  # half-hourly data ## integer tod sequence tod = seq(1, 48, by = 1) L = 48 beta = matrix(c(-1, 2, -1, -2, 1, -1), nrow = 2, byrow = TRUE) Gamma1 = tpm_p(tod, L, beta, degree = 1)  ## equivalent specification tod = seq(0.5, 24, by = 0.5) L = 24 beta = matrix(c(-1, 2, -1, -2, 1, -1), nrow = 2, byrow = TRUE) Gamma2 = tpm_p(tod, L, beta, degree = 1)  Gamma1-Gamma2 # same result #> , , 1 #>  #>      [,1] [,2] #> [1,]    0    0 #> [2,]    0    0 #>  #> , , 2 #>  #>      [,1] [,2] #> [1,]    0    0 #> [2,]    0    0 #>  #> , , 3 #>  #>      [,1] [,2] #> [1,]    0    0 #> [2,]    0    0 #>  #> , , 4 #>  #>      [,1] [,2] #> [1,]    0    0 #> [2,]    0    0 #>  #> , , 5 #>  #>      [,1] [,2] #> [1,]    0    0 #> [2,]    0    0 #>  #> , , 6 #>  #>      [,1] [,2] #> [1,]    0    0 #> [2,]    0    0 #>  #> , , 7 #>  #>      [,1] [,2] #> [1,]    0    0 #> [2,]    0    0 #>  #> , , 8 #>  #>      [,1] [,2] #> [1,]    0    0 #> [2,]    0    0 #>  #> , , 9 #>  #>      [,1] [,2] #> [1,]    0    0 #> [2,]    0    0 #>  #> , , 10 #>  #>      [,1] [,2] #> [1,]    0    0 #> [2,]    0    0 #>  #> , , 11 #>  #>      [,1] [,2] #> [1,]    0    0 #> [2,]    0    0 #>  #> , , 12 #>  #>      [,1] [,2] #> [1,]    0    0 #> [2,]    0    0 #>  #> , , 13 #>  #>      [,1] [,2] #> [1,]    0    0 #> [2,]    0    0 #>  #> , , 14 #>  #>      [,1] [,2] #> [1,]    0    0 #> [2,]    0    0 #>  #> , , 15 #>  #>      [,1] [,2] #> [1,]    0    0 #> [2,]    0    0 #>  #> , , 16 #>  #>      [,1] [,2] #> [1,]    0    0 #> [2,]    0    0 #>  #> , , 17 #>  #>      [,1] [,2] #> [1,]    0    0 #> [2,]    0    0 #>  #> , , 18 #>  #>      [,1] [,2] #> [1,]    0    0 #> [2,]    0    0 #>  #> , , 19 #>  #>      [,1] [,2] #> [1,]    0    0 #> [2,]    0    0 #>  #> , , 20 #>  #>      [,1] [,2] #> [1,]    0    0 #> [2,]    0    0 #>  #> , , 21 #>  #>      [,1] [,2] #> [1,]    0    0 #> [2,]    0    0 #>  #> , , 22 #>  #>      [,1] [,2] #> [1,]    0    0 #> [2,]    0    0 #>  #> , , 23 #>  #>      [,1] [,2] #> [1,]    0    0 #> [2,]    0    0 #>  #> , , 24 #>  #>      [,1] [,2] #> [1,]    0    0 #> [2,]    0    0 #>  #> , , 25 #>  #>      [,1] [,2] #> [1,]    0    0 #> [2,]    0    0 #>  #> , , 26 #>  #>      [,1] [,2] #> [1,]    0    0 #> [2,]    0    0 #>  #> , , 27 #>  #>      [,1] [,2] #> [1,]    0    0 #> [2,]    0    0 #>  #> , , 28 #>  #>      [,1] [,2] #> [1,]    0    0 #> [2,]    0    0 #>  #> , , 29 #>  #>      [,1] [,2] #> [1,]    0    0 #> [2,]    0    0 #>  #> , , 30 #>  #>      [,1] [,2] #> [1,]    0    0 #> [2,]    0    0 #>  #> , , 31 #>  #>      [,1] [,2] #> [1,]    0    0 #> [2,]    0    0 #>  #> , , 32 #>  #>      [,1] [,2] #> [1,]    0    0 #> [2,]    0    0 #>  #> , , 33 #>  #>      [,1] [,2] #> [1,]    0    0 #> [2,]    0    0 #>  #> , , 34 #>  #>      [,1] [,2] #> [1,]    0    0 #> [2,]    0    0 #>  #> , , 35 #>  #>      [,1] [,2] #> [1,]    0    0 #> [2,]    0    0 #>  #> , , 36 #>  #>      [,1] [,2] #> [1,]    0    0 #> [2,]    0    0 #>  #> , , 37 #>  #>      [,1] [,2] #> [1,]    0    0 #> [2,]    0    0 #>  #> , , 38 #>  #>      [,1] [,2] #> [1,]    0    0 #> [2,]    0    0 #>  #> , , 39 #>  #>      [,1] [,2] #> [1,]    0    0 #> [2,]    0    0 #>  #> , , 40 #>  #>      [,1] [,2] #> [1,]    0    0 #> [2,]    0    0 #>  #> , , 41 #>  #>      [,1] [,2] #> [1,]    0    0 #> [2,]    0    0 #>  #> , , 42 #>  #>      [,1] [,2] #> [1,]    0    0 #> [2,]    0    0 #>  #> , , 43 #>  #>      [,1] [,2] #> [1,]    0    0 #> [2,]    0    0 #>  #> , , 44 #>  #>      [,1] [,2] #> [1,]    0    0 #> [2,]    0    0 #>  #> , , 45 #>  #>      [,1] [,2] #> [1,]    0    0 #> [2,]    0    0 #>  #> , , 46 #>  #>      [,1] [,2] #> [1,]    0    0 #> [2,]    0    0 #>  #> , , 47 #>  #>      [,1] [,2] #> [1,]    0    0 #> [2,]    0    0 #>  #> , , 48 #>  #>      [,1] [,2] #> [1,]    0    0 #> [2,]    0    0 #>   # cubic P-splines set.seed(123) nk = 8 # number of basis functions tod = seq(0.5, 24, by = 0.5) L = 24 k = L * 0:nk / nk # equidistant knots Z = mgcv::cSplineDes(tod, k) ## cyclic spline design matrix beta = matrix(c(-1, runif(8, -2, 2), # 9 parameters per off-diagonal element                  -2, runif(8, -2, 2)), nrow = 2, byrow = TRUE) Gamma = tpm_p(tod, L, beta, Z = Z)"},{"path":"https://janoleko.github.io/reference/tpm_phsmm.html","id":null,"dir":"Reference","previous_headings":"","what":"Builds all transition probability matrices of an periodic-HSMM-approximating HMM — tpm_phsmm","title":"Builds all transition probability matrices of an periodic-HSMM-approximating HMM — tpm_phsmm","text":"Hidden semi-Markov models (HSMMs) flexible extension HMMs. direct numerical maximum likelhood estimation, HSMMs can represented HMMs enlarged state space (size \\(M\\)) structured transition probabilities. function computes transition matrices periodically inhomogeneos HSMMs.","code":""},{"path":"https://janoleko.github.io/reference/tpm_phsmm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Builds all transition probability matrices of an periodic-HSMM-approximating HMM — tpm_phsmm","text":"","code":"tpm_phsmm(omega, dm, eps = 1e-10)"},{"path":"https://janoleko.github.io/reference/tpm_phsmm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Builds all transition probability matrices of an periodic-HSMM-approximating HMM — tpm_phsmm","text":"omega embedded transition probability matrix Either matrix dimension c(N,N) homogeneous conditional transition probabilities (computed tpm_emb), array dimension c(N,N,L) inhomogeneous conditional transition probabilities (computed tpm_emb_g). dm state dwell-time distributions arranged list length N list element needs matrix dimension c(L, N_i), row t (approximate) probability mass function state time t. eps rounding value: entry transition probabily matrix smaller, rounded zero. Usually, changed.","code":""},{"path":"https://janoleko.github.io/reference/tpm_phsmm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Builds all transition probability matrices of an periodic-HSMM-approximating HMM — tpm_phsmm","text":"list dimension length L, containing sparse extended-state-space transition probability matrices approximating HMM time point cycle.","code":""},{"path":"https://janoleko.github.io/reference/tpm_phsmm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Builds all transition probability matrices of an periodic-HSMM-approximating HMM — tpm_phsmm","text":"","code":"N = 2 # number of states L = 24 # cycle length # time-varying mean dwell times Z = trigBasisExp(1:L) # trigonometric basis functions design matrix beta = matrix(c(2, 2, 0.1, -0.1, -0.2, 0.2), nrow = 2) Lambda = exp(cbind(1, Z) %*% t(beta)) sizes = c(20, 20) # approximating chain with 40 states # state dwell-time distributions dm = lapply(1:N, function(i) sapply(1:sizes[i]-1, dpois, lambda = Lambda[,i]))  ## homogeneous conditional transition probabilites # diagonal elements are zero, rowsums are one omega = matrix(c(0,1,1,0), nrow = N, byrow = TRUE)  # calculating extended-state-space t.p.m.s Gamma = tpm_phsmm(omega, dm)  ## inhomogeneous conditional transition probabilites # omega can be an array omega = array(omega, dim = c(N,N,L))  # calculating extended-state-space t.p.m.s Gamma = tpm_phsmm(omega, dm)"},{"path":"https://janoleko.github.io/reference/tpm_phsmm2.html","id":null,"dir":"Reference","previous_headings":"","what":"Build all transition probability matrices of an periodic-HSMM-approximating HMM — tpm_phsmm2","title":"Build all transition probability matrices of an periodic-HSMM-approximating HMM — tpm_phsmm2","text":"Hidden semi-Markov models (HSMMs) flexible extension HMMs. direct numerical maximum likelhood estimation, HSMMs can represented HMMs enlarged state space (size \\(M\\)) structured transition probabilities. function computes transition matrices periodically inhomogeneos HSMMs.","code":""},{"path":"https://janoleko.github.io/reference/tpm_phsmm2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build all transition probability matrices of an periodic-HSMM-approximating HMM — tpm_phsmm2","text":"","code":"tpm_phsmm2(omega, dm, eps = 1e-10)"},{"path":"https://janoleko.github.io/reference/tpm_phsmm2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build all transition probability matrices of an periodic-HSMM-approximating HMM — tpm_phsmm2","text":"omega embedded transition probability matrix Either matrix dimension c(N,N) homogeneous conditional transition probabilities, array dimension c(N,N,L) inhomogeneous conditional transition probabilities. dm state dwell-time distributions arranged list length(N) list element needs matrix dimension c(L, N_i), row t (approximate) probability mass function state time t. eps rounding value: entry transition probabily matrix smaller, rounded zero.","code":""},{"path":"https://janoleko.github.io/reference/tpm_phsmm2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build all transition probability matrices of an periodic-HSMM-approximating HMM — tpm_phsmm2","text":"array dimension c(N,N,L), containing extended-state-space transition probability matrices approximating HMM time point cycle.","code":""},{"path":"https://janoleko.github.io/reference/tpm_phsmm2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Build all transition probability matrices of an periodic-HSMM-approximating HMM — tpm_phsmm2","text":"","code":"N = 3 L = 24 # time-varying mean dwell times Lambda = exp(matrix(rnorm(L*N, 2, 0.5), nrow = L)) sizes = c(25, 25, 25) # approximating chain with 75 states # state dwell-time distributions dm = list() for(i in 1:3){   dmi = matrix(nrow = L, ncol = sizes[i])   for(t in 1:L){     dmi[t,] = dpois(1:sizes[i]-1, Lambda[t,i])   }   dm[[i]] = dmi }  ## homogeneous conditional transition probabilites # diagonal elements are zero, rowsums are one omega = matrix(c(0,0.5,0.5,0.2,0,0.8,0.7,0.3,0), nrow = N, byrow = TRUE)  # calculating extended-state-space t.p.m.s Gamma = tpm_phsmm(omega, dm)  ## inhomogeneous conditional transition probabilites # omega can be an array omega = array(rep(omega,L), dim = c(N,N,L)) omega[1,,4] = c(0, 0.2, 0.8) # small change for inhomogeneity  # calculating extended-state-space t.p.m.s Gamma = tpm_phsmm(omega, dm)"},{"path":"https://janoleko.github.io/reference/tpm_thinned.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the transition probability matrix of a thinned periodically inhomogeneous Markov chain. — tpm_thinned","title":"Compute the transition probability matrix of a thinned periodically inhomogeneous Markov chain. — tpm_thinned","text":"transition probability matrix inhomogeneous Markov chain varies periodically (period length \\(L\\)), converges -called periodically stationary distribution. happens, thinned Markov chain, full cycle time step, homogeneous transition probability matrix $$\\Gamma_t = \\Gamma^{(t)} \\Gamma^{(t+1)} \\dots \\Gamma^{(t+L-1)}$$ \\(t = 1, \\dots, L.\\) function calculates matrix efficiently preliminery step calculating periodically stationary distribution.","code":""},{"path":"https://janoleko.github.io/reference/tpm_thinned.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the transition probability matrix of a thinned periodically inhomogeneous Markov chain. — tpm_thinned","text":"","code":"tpm_thinned(Gamma, t)"},{"path":"https://janoleko.github.io/reference/tpm_thinned.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the transition probability matrix of a thinned periodically inhomogeneous Markov chain. — tpm_thinned","text":"Gamma array transition probability matrices dimension c(N,N,L). t integer index time point cycle, calculate thinned transition probility matrix","code":""},{"path":"https://janoleko.github.io/reference/tpm_thinned.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the transition probability matrix of a thinned periodically inhomogeneous Markov chain. — tpm_thinned","text":"thinned transition probabilty matrix dimension c(N,N)","code":""},{"path":"https://janoleko.github.io/reference/tpm_thinned.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute the transition probability matrix of a thinned periodically inhomogeneous Markov chain. — tpm_thinned","text":"","code":"# setting parameters for trigonometric link beta = matrix(c(-1, -2, 2, -1, 2, -4), nrow = 2, byrow = TRUE) # building trigonometric design matrix Z = cbind(1,trigBasisExp(1:24, 24, 1)) # calculating all 24 linear predictor vectors Eta = Z%*%t(beta) # building all 24 t.p.m.s Gamma = array(dim = c(2,2,24)) for(t in 1:24){   Gamma[,,t] = tpm(Eta[t,]) } # calculating  tpm_thinned(Gamma, 4) #>           [,1]      [,2] #> [1,] 0.8926642 0.1073358 #> [2,] 0.8926642 0.1073358"},{"path":"https://janoleko.github.io/reference/trigBasisExp.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the design matrix for a trigonometric basis expansion — trigBasisExp","title":"Compute the design matrix for a trigonometric basis expansion — trigBasisExp","text":"Given periodically varying variable time day day year associated cycle length, function performs basis expansion efficiently calculate linear predictor form $$  \\eta^{(t)} = \\beta_0 + \\sum_{k=1}^K \\bigl( \\beta_{1k} \\sin(\\frac{2 \\pi k t}{L}) + \\beta_{2k} \\cos(\\frac{2 \\pi k t}{L}) \\bigr).  $$  relevant modeling e.g. diurnal variation flexibility can increased adding smaller frequencies (.e. increasing \\(K\\)).","code":""},{"path":"https://janoleko.github.io/reference/trigBasisExp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the design matrix for a trigonometric basis expansion — trigBasisExp","text":"","code":"trigBasisExp(tod, L = 24, degree = 1)"},{"path":"https://janoleko.github.io/reference/trigBasisExp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the design matrix for a trigonometric basis expansion — trigBasisExp","text":"tod equidistant sequence cyclic variable time day e.g. half-hourly data, 1, ..., L L = 48, 0.5, 1, 1.5, ..., 24 L = 24. L length one cycle scale time variable. time day, 24. degree degree K trigonometric link . Increasing K increases flexibility.","code":""},{"path":"https://janoleko.github.io/reference/trigBasisExp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the design matrix for a trigonometric basis expansion — trigBasisExp","text":"design matrix (without intercept column), ordered sin1, cos1, sin2, cos2, ...","code":""},{"path":"https://janoleko.github.io/reference/trigBasisExp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute the design matrix for a trigonometric basis expansion — trigBasisExp","text":"","code":"## hourly data tod = rep(1:24, 10) Z = trigBasisExp(tod, L = 24, degree = 2)  ## half-hourly data tod = rep(1:48/2, 10) # in [0,24] -> L = 24 Z1 = trigBasisExp(tod, L = 24, degree = 3)  tod = rep(1:48, 10) # in [1,48] -> L = 48 Z2 = trigBasisExp(tod, L = 48, degree = 3)  Z1 - Z2 #>        sin_1 cos_1 sin_2 cos_2 sin_3 cos_3 #>   [1,]     0     0     0     0     0     0 #>   [2,]     0     0     0     0     0     0 #>   [3,]     0     0     0     0     0     0 #>   [4,]     0     0     0     0     0     0 #>   [5,]     0     0     0     0     0     0 #>   [6,]     0     0     0     0     0     0 #>   [7,]     0     0     0     0     0     0 #>   [8,]     0     0     0     0     0     0 #>   [9,]     0     0     0     0     0     0 #>  [10,]     0     0     0     0     0     0 #>  [11,]     0     0     0     0     0     0 #>  [12,]     0     0     0     0     0     0 #>  [13,]     0     0     0     0     0     0 #>  [14,]     0     0     0     0     0     0 #>  [15,]     0     0     0     0     0     0 #>  [16,]     0     0     0     0     0     0 #>  [17,]     0     0     0     0     0     0 #>  [18,]     0     0     0     0     0     0 #>  [19,]     0     0     0     0     0     0 #>  [20,]     0     0     0     0     0     0 #>  [21,]     0     0     0     0     0     0 #>  [22,]     0     0     0     0     0     0 #>  [23,]     0     0     0     0     0     0 #>  [24,]     0     0     0     0     0     0 #>  [25,]     0     0     0     0     0     0 #>  [26,]     0     0     0     0     0     0 #>  [27,]     0     0     0     0     0     0 #>  [28,]     0     0     0     0     0     0 #>  [29,]     0     0     0     0     0     0 #>  [30,]     0     0     0     0     0     0 #>  [31,]     0     0     0     0     0     0 #>  [32,]     0     0     0     0     0     0 #>  [33,]     0     0     0     0     0     0 #>  [34,]     0     0     0     0     0     0 #>  [35,]     0     0     0     0     0     0 #>  [36,]     0     0     0     0     0     0 #>  [37,]     0     0     0     0     0     0 #>  [38,]     0     0     0     0     0     0 #>  [39,]     0     0     0     0     0     0 #>  [40,]     0     0     0     0     0     0 #>  [41,]     0     0     0     0     0     0 #>  [42,]     0     0     0     0     0     0 #>  [43,]     0     0     0     0     0     0 #>  [44,]     0     0     0     0     0     0 #>  [45,]     0     0     0     0     0     0 #>  [46,]     0     0     0     0     0     0 #>  [47,]     0     0     0     0     0     0 #>  [48,]     0     0     0     0     0     0 #>  [49,]     0     0     0     0     0     0 #>  [50,]     0     0     0     0     0     0 #>  [51,]     0     0     0     0     0     0 #>  [52,]     0     0     0     0     0     0 #>  [53,]     0     0     0     0     0     0 #>  [54,]     0     0     0     0     0     0 #>  [55,]     0     0     0     0     0     0 #>  [56,]     0     0     0     0     0     0 #>  [57,]     0     0     0     0     0     0 #>  [58,]     0     0     0     0     0     0 #>  [59,]     0     0     0     0     0     0 #>  [60,]     0     0     0     0     0     0 #>  [61,]     0     0     0     0     0     0 #>  [62,]     0     0     0     0     0     0 #>  [63,]     0     0     0     0     0     0 #>  [64,]     0     0     0     0     0     0 #>  [65,]     0     0     0     0     0     0 #>  [66,]     0     0     0     0     0     0 #>  [67,]     0     0     0     0     0     0 #>  [68,]     0     0     0     0     0     0 #>  [69,]     0     0     0     0     0     0 #>  [70,]     0     0     0     0     0     0 #>  [71,]     0     0     0     0     0     0 #>  [72,]     0     0     0     0     0     0 #>  [73,]     0     0     0     0     0     0 #>  [74,]     0     0     0     0     0     0 #>  [75,]     0     0     0     0     0     0 #>  [76,]     0     0     0     0     0     0 #>  [77,]     0     0     0     0     0     0 #>  [78,]     0     0     0     0     0     0 #>  [79,]     0     0     0     0     0     0 #>  [80,]     0     0     0     0     0     0 #>  [81,]     0     0     0     0     0     0 #>  [82,]     0     0     0     0     0     0 #>  [83,]     0     0     0     0     0     0 #>  [84,]     0     0     0     0     0     0 #>  [85,]     0     0     0     0     0     0 #>  [86,]     0     0     0     0     0     0 #>  [87,]     0     0     0     0     0     0 #>  [88,]     0     0     0     0     0     0 #>  [89,]     0     0     0     0     0     0 #>  [90,]     0     0     0     0     0     0 #>  [91,]     0     0     0     0     0     0 #>  [92,]     0     0     0     0     0     0 #>  [93,]     0     0     0     0     0     0 #>  [94,]     0     0     0     0     0     0 #>  [95,]     0     0     0     0     0     0 #>  [96,]     0     0     0     0     0     0 #>  [97,]     0     0     0     0     0     0 #>  [98,]     0     0     0     0     0     0 #>  [99,]     0     0     0     0     0     0 #> [100,]     0     0     0     0     0     0 #> [101,]     0     0     0     0     0     0 #> [102,]     0     0     0     0     0     0 #> [103,]     0     0     0     0     0     0 #> [104,]     0     0     0     0     0     0 #> [105,]     0     0     0     0     0     0 #> [106,]     0     0     0     0     0     0 #> [107,]     0     0     0     0     0     0 #> [108,]     0     0     0     0     0     0 #> [109,]     0     0     0     0     0     0 #> [110,]     0     0     0     0     0     0 #> [111,]     0     0     0     0     0     0 #> [112,]     0     0     0     0     0     0 #> [113,]     0     0     0     0     0     0 #> [114,]     0     0     0     0     0     0 #> [115,]     0     0     0     0     0     0 #> [116,]     0     0     0     0     0     0 #> [117,]     0     0     0     0     0     0 #> [118,]     0     0     0     0     0     0 #> [119,]     0     0     0     0     0     0 #> [120,]     0     0     0     0     0     0 #> [121,]     0     0     0     0     0     0 #> [122,]     0     0     0     0     0     0 #> [123,]     0     0     0     0     0     0 #> [124,]     0     0     0     0     0     0 #> [125,]     0     0     0     0     0     0 #> [126,]     0     0     0     0     0     0 #> [127,]     0     0     0     0     0     0 #> [128,]     0     0     0     0     0     0 #> [129,]     0     0     0     0     0     0 #> [130,]     0     0     0     0     0     0 #> [131,]     0     0     0     0     0     0 #> [132,]     0     0     0     0     0     0 #> [133,]     0     0     0     0     0     0 #> [134,]     0     0     0     0     0     0 #> [135,]     0     0     0     0     0     0 #> [136,]     0     0     0     0     0     0 #> [137,]     0     0     0     0     0     0 #> [138,]     0     0     0     0     0     0 #> [139,]     0     0     0     0     0     0 #> [140,]     0     0     0     0     0     0 #> [141,]     0     0     0     0     0     0 #> [142,]     0     0     0     0     0     0 #> [143,]     0     0     0     0     0     0 #> [144,]     0     0     0     0     0     0 #> [145,]     0     0     0     0     0     0 #> [146,]     0     0     0     0     0     0 #> [147,]     0     0     0     0     0     0 #> [148,]     0     0     0     0     0     0 #> [149,]     0     0     0     0     0     0 #> [150,]     0     0     0     0     0     0 #> [151,]     0     0     0     0     0     0 #> [152,]     0     0     0     0     0     0 #> [153,]     0     0     0     0     0     0 #> [154,]     0     0     0     0     0     0 #> [155,]     0     0     0     0     0     0 #> [156,]     0     0     0     0     0     0 #> [157,]     0     0     0     0     0     0 #> [158,]     0     0     0     0     0     0 #> [159,]     0     0     0     0     0     0 #> [160,]     0     0     0     0     0     0 #> [161,]     0     0     0     0     0     0 #> [162,]     0     0     0     0     0     0 #> [163,]     0     0     0     0     0     0 #> [164,]     0     0     0     0     0     0 #> [165,]     0     0     0     0     0     0 #> [166,]     0     0     0     0     0     0 #> [167,]     0     0     0     0     0     0 #> [168,]     0     0     0     0     0     0 #> [169,]     0     0     0     0     0     0 #> [170,]     0     0     0     0     0     0 #> [171,]     0     0     0     0     0     0 #> [172,]     0     0     0     0     0     0 #> [173,]     0     0     0     0     0     0 #> [174,]     0     0     0     0     0     0 #> [175,]     0     0     0     0     0     0 #> [176,]     0     0     0     0     0     0 #> [177,]     0     0     0     0     0     0 #> [178,]     0     0     0     0     0     0 #> [179,]     0     0     0     0     0     0 #> [180,]     0     0     0     0     0     0 #> [181,]     0     0     0     0     0     0 #> [182,]     0     0     0     0     0     0 #> [183,]     0     0     0     0     0     0 #> [184,]     0     0     0     0     0     0 #> [185,]     0     0     0     0     0     0 #> [186,]     0     0     0     0     0     0 #> [187,]     0     0     0     0     0     0 #> [188,]     0     0     0     0     0     0 #> [189,]     0     0     0     0     0     0 #> [190,]     0     0     0     0     0     0 #> [191,]     0     0     0     0     0     0 #> [192,]     0     0     0     0     0     0 #> [193,]     0     0     0     0     0     0 #> [194,]     0     0     0     0     0     0 #> [195,]     0     0     0     0     0     0 #> [196,]     0     0     0     0     0     0 #> [197,]     0     0     0     0     0     0 #> [198,]     0     0     0     0     0     0 #> [199,]     0     0     0     0     0     0 #> [200,]     0     0     0     0     0     0 #> [201,]     0     0     0     0     0     0 #> [202,]     0     0     0     0     0     0 #> [203,]     0     0     0     0     0     0 #> [204,]     0     0     0     0     0     0 #> [205,]     0     0     0     0     0     0 #> [206,]     0     0     0     0     0     0 #> [207,]     0     0     0     0     0     0 #> [208,]     0     0     0     0     0     0 #> [209,]     0     0     0     0     0     0 #> [210,]     0     0     0     0     0     0 #> [211,]     0     0     0     0     0     0 #> [212,]     0     0     0     0     0     0 #> [213,]     0     0     0     0     0     0 #> [214,]     0     0     0     0     0     0 #> [215,]     0     0     0     0     0     0 #> [216,]     0     0     0     0     0     0 #> [217,]     0     0     0     0     0     0 #> [218,]     0     0     0     0     0     0 #> [219,]     0     0     0     0     0     0 #> [220,]     0     0     0     0     0     0 #> [221,]     0     0     0     0     0     0 #> [222,]     0     0     0     0     0     0 #> [223,]     0     0     0     0     0     0 #> [224,]     0     0     0     0     0     0 #> [225,]     0     0     0     0     0     0 #> [226,]     0     0     0     0     0     0 #> [227,]     0     0     0     0     0     0 #> [228,]     0     0     0     0     0     0 #> [229,]     0     0     0     0     0     0 #> [230,]     0     0     0     0     0     0 #> [231,]     0     0     0     0     0     0 #> [232,]     0     0     0     0     0     0 #> [233,]     0     0     0     0     0     0 #> [234,]     0     0     0     0     0     0 #> [235,]     0     0     0     0     0     0 #> [236,]     0     0     0     0     0     0 #> [237,]     0     0     0     0     0     0 #> [238,]     0     0     0     0     0     0 #> [239,]     0     0     0     0     0     0 #> [240,]     0     0     0     0     0     0 #> [241,]     0     0     0     0     0     0 #> [242,]     0     0     0     0     0     0 #> [243,]     0     0     0     0     0     0 #> [244,]     0     0     0     0     0     0 #> [245,]     0     0     0     0     0     0 #> [246,]     0     0     0     0     0     0 #> [247,]     0     0     0     0     0     0 #> [248,]     0     0     0     0     0     0 #> [249,]     0     0     0     0     0     0 #> [250,]     0     0     0     0     0     0 #> [251,]     0     0     0     0     0     0 #> [252,]     0     0     0     0     0     0 #> [253,]     0     0     0     0     0     0 #> [254,]     0     0     0     0     0     0 #> [255,]     0     0     0     0     0     0 #> [256,]     0     0     0     0     0     0 #> [257,]     0     0     0     0     0     0 #> [258,]     0     0     0     0     0     0 #> [259,]     0     0     0     0     0     0 #> [260,]     0     0     0     0     0     0 #> [261,]     0     0     0     0     0     0 #> [262,]     0     0     0     0     0     0 #> [263,]     0     0     0     0     0     0 #> [264,]     0     0     0     0     0     0 #> [265,]     0     0     0     0     0     0 #> [266,]     0     0     0     0     0     0 #> [267,]     0     0     0     0     0     0 #> [268,]     0     0     0     0     0     0 #> [269,]     0     0     0     0     0     0 #> [270,]     0     0     0     0     0     0 #> [271,]     0     0     0     0     0     0 #> [272,]     0     0     0     0     0     0 #> [273,]     0     0     0     0     0     0 #> [274,]     0     0     0     0     0     0 #> [275,]     0     0     0     0     0     0 #> [276,]     0     0     0     0     0     0 #> [277,]     0     0     0     0     0     0 #> [278,]     0     0     0     0     0     0 #> [279,]     0     0     0     0     0     0 #> [280,]     0     0     0     0     0     0 #> [281,]     0     0     0     0     0     0 #> [282,]     0     0     0     0     0     0 #> [283,]     0     0     0     0     0     0 #> [284,]     0     0     0     0     0     0 #> [285,]     0     0     0     0     0     0 #> [286,]     0     0     0     0     0     0 #> [287,]     0     0     0     0     0     0 #> [288,]     0     0     0     0     0     0 #> [289,]     0     0     0     0     0     0 #> [290,]     0     0     0     0     0     0 #> [291,]     0     0     0     0     0     0 #> [292,]     0     0     0     0     0     0 #> [293,]     0     0     0     0     0     0 #> [294,]     0     0     0     0     0     0 #> [295,]     0     0     0     0     0     0 #> [296,]     0     0     0     0     0     0 #> [297,]     0     0     0     0     0     0 #> [298,]     0     0     0     0     0     0 #> [299,]     0     0     0     0     0     0 #> [300,]     0     0     0     0     0     0 #> [301,]     0     0     0     0     0     0 #> [302,]     0     0     0     0     0     0 #> [303,]     0     0     0     0     0     0 #> [304,]     0     0     0     0     0     0 #> [305,]     0     0     0     0     0     0 #> [306,]     0     0     0     0     0     0 #> [307,]     0     0     0     0     0     0 #> [308,]     0     0     0     0     0     0 #> [309,]     0     0     0     0     0     0 #> [310,]     0     0     0     0     0     0 #> [311,]     0     0     0     0     0     0 #> [312,]     0     0     0     0     0     0 #> [313,]     0     0     0     0     0     0 #> [314,]     0     0     0     0     0     0 #> [315,]     0     0     0     0     0     0 #> [316,]     0     0     0     0     0     0 #> [317,]     0     0     0     0     0     0 #> [318,]     0     0     0     0     0     0 #> [319,]     0     0     0     0     0     0 #> [320,]     0     0     0     0     0     0 #> [321,]     0     0     0     0     0     0 #> [322,]     0     0     0     0     0     0 #> [323,]     0     0     0     0     0     0 #> [324,]     0     0     0     0     0     0 #> [325,]     0     0     0     0     0     0 #> [326,]     0     0     0     0     0     0 #> [327,]     0     0     0     0     0     0 #> [328,]     0     0     0     0     0     0 #> [329,]     0     0     0     0     0     0 #> [330,]     0     0     0     0     0     0 #> [331,]     0     0     0     0     0     0 #> [332,]     0     0     0     0     0     0 #> [333,]     0     0     0     0     0     0 #> [334,]     0     0     0     0     0     0 #> [335,]     0     0     0     0     0     0 #> [336,]     0     0     0     0     0     0 #> [337,]     0     0     0     0     0     0 #> [338,]     0     0     0     0     0     0 #> [339,]     0     0     0     0     0     0 #> [340,]     0     0     0     0     0     0 #> [341,]     0     0     0     0     0     0 #> [342,]     0     0     0     0     0     0 #> [343,]     0     0     0     0     0     0 #> [344,]     0     0     0     0     0     0 #> [345,]     0     0     0     0     0     0 #> [346,]     0     0     0     0     0     0 #> [347,]     0     0     0     0     0     0 #> [348,]     0     0     0     0     0     0 #> [349,]     0     0     0     0     0     0 #> [350,]     0     0     0     0     0     0 #> [351,]     0     0     0     0     0     0 #> [352,]     0     0     0     0     0     0 #> [353,]     0     0     0     0     0     0 #> [354,]     0     0     0     0     0     0 #> [355,]     0     0     0     0     0     0 #> [356,]     0     0     0     0     0     0 #> [357,]     0     0     0     0     0     0 #> [358,]     0     0     0     0     0     0 #> [359,]     0     0     0     0     0     0 #> [360,]     0     0     0     0     0     0 #> [361,]     0     0     0     0     0     0 #> [362,]     0     0     0     0     0     0 #> [363,]     0     0     0     0     0     0 #> [364,]     0     0     0     0     0     0 #> [365,]     0     0     0     0     0     0 #> [366,]     0     0     0     0     0     0 #> [367,]     0     0     0     0     0     0 #> [368,]     0     0     0     0     0     0 #> [369,]     0     0     0     0     0     0 #> [370,]     0     0     0     0     0     0 #> [371,]     0     0     0     0     0     0 #> [372,]     0     0     0     0     0     0 #> [373,]     0     0     0     0     0     0 #> [374,]     0     0     0     0     0     0 #> [375,]     0     0     0     0     0     0 #> [376,]     0     0     0     0     0     0 #> [377,]     0     0     0     0     0     0 #> [378,]     0     0     0     0     0     0 #> [379,]     0     0     0     0     0     0 #> [380,]     0     0     0     0     0     0 #> [381,]     0     0     0     0     0     0 #> [382,]     0     0     0     0     0     0 #> [383,]     0     0     0     0     0     0 #> [384,]     0     0     0     0     0     0 #> [385,]     0     0     0     0     0     0 #> [386,]     0     0     0     0     0     0 #> [387,]     0     0     0     0     0     0 #> [388,]     0     0     0     0     0     0 #> [389,]     0     0     0     0     0     0 #> [390,]     0     0     0     0     0     0 #> [391,]     0     0     0     0     0     0 #> [392,]     0     0     0     0     0     0 #> [393,]     0     0     0     0     0     0 #> [394,]     0     0     0     0     0     0 #> [395,]     0     0     0     0     0     0 #> [396,]     0     0     0     0     0     0 #> [397,]     0     0     0     0     0     0 #> [398,]     0     0     0     0     0     0 #> [399,]     0     0     0     0     0     0 #> [400,]     0     0     0     0     0     0 #> [401,]     0     0     0     0     0     0 #> [402,]     0     0     0     0     0     0 #> [403,]     0     0     0     0     0     0 #> [404,]     0     0     0     0     0     0 #> [405,]     0     0     0     0     0     0 #> [406,]     0     0     0     0     0     0 #> [407,]     0     0     0     0     0     0 #> [408,]     0     0     0     0     0     0 #> [409,]     0     0     0     0     0     0 #> [410,]     0     0     0     0     0     0 #> [411,]     0     0     0     0     0     0 #> [412,]     0     0     0     0     0     0 #> [413,]     0     0     0     0     0     0 #> [414,]     0     0     0     0     0     0 #> [415,]     0     0     0     0     0     0 #> [416,]     0     0     0     0     0     0 #> [417,]     0     0     0     0     0     0 #> [418,]     0     0     0     0     0     0 #> [419,]     0     0     0     0     0     0 #> [420,]     0     0     0     0     0     0 #> [421,]     0     0     0     0     0     0 #> [422,]     0     0     0     0     0     0 #> [423,]     0     0     0     0     0     0 #> [424,]     0     0     0     0     0     0 #> [425,]     0     0     0     0     0     0 #> [426,]     0     0     0     0     0     0 #> [427,]     0     0     0     0     0     0 #> [428,]     0     0     0     0     0     0 #> [429,]     0     0     0     0     0     0 #> [430,]     0     0     0     0     0     0 #> [431,]     0     0     0     0     0     0 #> [432,]     0     0     0     0     0     0 #> [433,]     0     0     0     0     0     0 #> [434,]     0     0     0     0     0     0 #> [435,]     0     0     0     0     0     0 #> [436,]     0     0     0     0     0     0 #> [437,]     0     0     0     0     0     0 #> [438,]     0     0     0     0     0     0 #> [439,]     0     0     0     0     0     0 #> [440,]     0     0     0     0     0     0 #> [441,]     0     0     0     0     0     0 #> [442,]     0     0     0     0     0     0 #> [443,]     0     0     0     0     0     0 #> [444,]     0     0     0     0     0     0 #> [445,]     0     0     0     0     0     0 #> [446,]     0     0     0     0     0     0 #> [447,]     0     0     0     0     0     0 #> [448,]     0     0     0     0     0     0 #> [449,]     0     0     0     0     0     0 #> [450,]     0     0     0     0     0     0 #> [451,]     0     0     0     0     0     0 #> [452,]     0     0     0     0     0     0 #> [453,]     0     0     0     0     0     0 #> [454,]     0     0     0     0     0     0 #> [455,]     0     0     0     0     0     0 #> [456,]     0     0     0     0     0     0 #> [457,]     0     0     0     0     0     0 #> [458,]     0     0     0     0     0     0 #> [459,]     0     0     0     0     0     0 #> [460,]     0     0     0     0     0     0 #> [461,]     0     0     0     0     0     0 #> [462,]     0     0     0     0     0     0 #> [463,]     0     0     0     0     0     0 #> [464,]     0     0     0     0     0     0 #> [465,]     0     0     0     0     0     0 #> [466,]     0     0     0     0     0     0 #> [467,]     0     0     0     0     0     0 #> [468,]     0     0     0     0     0     0 #> [469,]     0     0     0     0     0     0 #> [470,]     0     0     0     0     0     0 #> [471,]     0     0     0     0     0     0 #> [472,]     0     0     0     0     0     0 #> [473,]     0     0     0     0     0     0 #> [474,]     0     0     0     0     0     0 #> [475,]     0     0     0     0     0     0 #> [476,]     0     0     0     0     0     0 #> [477,]     0     0     0     0     0     0 #> [478,]     0     0     0     0     0     0 #> [479,]     0     0     0     0     0     0 #> [480,]     0     0     0     0     0     0 # The latter two are equivalent specifications!"},{"path":"https://janoleko.github.io/reference/viterbi.html","id":null,"dir":"Reference","previous_headings":"","what":"Viterbi algorithm for state decoding in homogeneous HMMs — viterbi","title":"Viterbi algorithm for state decoding in homogeneous HMMs — viterbi","text":"Viterbi algorithm allows one decode probable state sequence HMM.","code":""},{"path":"https://janoleko.github.io/reference/viterbi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Viterbi algorithm for state decoding in homogeneous HMMs — viterbi","text":"","code":"viterbi(delta, Gamma, allprobs, trackID = NULL)"},{"path":"https://janoleko.github.io/reference/viterbi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Viterbi algorithm for state decoding in homogeneous HMMs — viterbi","text":"delta initial distribution length N, matrix dimension c(k,N) k independent tracks, trackID provided Gamma transition probability matrix dimension c(N,N) array transition probability matrices dimension c(N,N,k) trackID provided allprobs matrix state-dependent probabilities/ density values dimension c(n, N) trackID optional vector k track IDs, multiple tracks need decoded separately","code":""},{"path":"https://janoleko.github.io/reference/viterbi.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Viterbi algorithm for state decoding in homogeneous HMMs — viterbi","text":"vector decoded states length n","code":""},{"path":"https://janoleko.github.io/reference/viterbi.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Viterbi algorithm for state decoding in homogeneous HMMs — viterbi","text":"","code":"delta = c(0.5, 0.5) Gamma = matrix(c(0.9, 0.1, 0.2, 0.8), nrow = 2, byrow = TRUE) allprobs = matrix(runif(200), nrow = 100, ncol = 2) states = viterbi(delta, Gamma, allprobs)"},{"path":"https://janoleko.github.io/reference/viterbi_g.html","id":null,"dir":"Reference","previous_headings":"","what":"Viterbi algorithm for state decoding in inhomogeneous HMMs — viterbi_g","title":"Viterbi algorithm for state decoding in inhomogeneous HMMs — viterbi_g","text":"Viterbi algorithm allows one decode probable state sequence HMM.","code":""},{"path":"https://janoleko.github.io/reference/viterbi_g.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Viterbi algorithm for state decoding in inhomogeneous HMMs — viterbi_g","text":"","code":"viterbi_g(delta, Gamma, allprobs, trackID = NULL)"},{"path":"https://janoleko.github.io/reference/viterbi_g.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Viterbi algorithm for state decoding in inhomogeneous HMMs — viterbi_g","text":"delta initial distribution length N, matrix dimension c(k,N) k independent tracks, trackID provided Gamma array transition probability matrices dimension c(N,N,n-1), time series length n, n-1 transitions array dimension c(N,N,n) provided single track, first slice ignored. trackID provided, Gamma needs array dimension c(N,N,n), n number rows allprobs. track first transition matrix ignored. allprobs matrix state-dependent probabilities/ density values dimension c(n, N) trackID optional vector k track IDs, multiple tracks need decoded separately","code":""},{"path":"https://janoleko.github.io/reference/viterbi_g.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Viterbi algorithm for state decoding in inhomogeneous HMMs — viterbi_g","text":"vector decoded states length n","code":""},{"path":"https://janoleko.github.io/reference/viterbi_g.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Viterbi algorithm for state decoding in inhomogeneous HMMs — viterbi_g","text":"","code":"delta = c(0.5, 0.5) Gamma = array(dim = c(2,2,99)) for(t in 1:99){   gammas = rbeta(2, shape1 = 0.4, shape2 = 1)   Gamma[,,t] = matrix(c(1-gammas[1], gammas[1],                        gammas[2], 1-gammas[2]), nrow = 2, byrow = TRUE) } allprobs = matrix(runif(200), nrow = 100, ncol = 2) states = viterbi_g(delta, Gamma, allprobs)"},{"path":"https://janoleko.github.io/reference/viterbi_p.html","id":null,"dir":"Reference","previous_headings":"","what":"Viterbi algorithm for state decoding in periodically inhomogeneous HMMs — viterbi_p","title":"Viterbi algorithm for state decoding in periodically inhomogeneous HMMs — viterbi_p","text":"Viterbi algorithm allows one decode probable state sequence HMM.","code":""},{"path":"https://janoleko.github.io/reference/viterbi_p.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Viterbi algorithm for state decoding in periodically inhomogeneous HMMs — viterbi_p","text":"","code":"viterbi_p(delta, Gamma, allprobs, tod, trackID = NULL)"},{"path":"https://janoleko.github.io/reference/viterbi_p.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Viterbi algorithm for state decoding in periodically inhomogeneous HMMs — viterbi_p","text":"delta initial distribution length N, matrix dimension c(k,N) k independent tracks, trackID provided e.g. periodically stationary distribution (track). Gamma array transition probability matrices time point cycle dimension c(N,N,L), L length cycle allprobs matrix state-dependent probabilities/ density values dimension c(n, N) tod (Integer valued) variable cycle indexing 1, ..., L, mapping data index generalised time day (length n) half-hourly data L = 48. , however, also day year daily data L = 365. trackID optional vector k track IDs, multiple tracks need decoded separately","code":""},{"path":"https://janoleko.github.io/reference/viterbi_p.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Viterbi algorithm for state decoding in periodically inhomogeneous HMMs — viterbi_p","text":"vector decoded states length n","code":""},{"path":"https://janoleko.github.io/reference/viterbi_p.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Viterbi algorithm for state decoding in periodically inhomogeneous HMMs — viterbi_p","text":"","code":"delta = c(0.5, 0.5) beta = matrix(c(-2, 1, -1,                 -2, -1, 1), nrow = 2, byrow = TRUE) Gamma = tpm_p(1:24, 24, beta)  tod = rep(1:24, 10) n = length(tod)  allprobs = matrix(runif(2*n), nrow = n, ncol = 2) states = viterbi_p(delta, Gamma, allprobs, tod)"}]
