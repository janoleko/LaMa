[{"path":"https://janoleko.github.io/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2025 LaMa authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":[]},{"path":"https://janoleko.github.io/articles/Continuous_time_HMMs.html","id":"setting-parameters-for-simulation","dir":"Articles","previous_headings":"Example 1: two states","what":"Setting parameters for simulation","title":"Continuous-time HMMs","text":"start setting parameters simulate data. example, state 1 smaller rate state dwell time state one follows Exp(0.5) distribution, .e. exhibits longer dwell times state 2 rate 1.","code":"# loading the package library(LaMa) #> Loading required package: RTMB # generator matrix Q: Q = matrix(c(-0.5, 0.5, 1, -1),             nrow = 2, byrow = TRUE)  # parameters for the state-dependent (normal) distributions mu = c(5, 20) sigma = c(2, 5)"},{"path":"https://janoleko.github.io/articles/Continuous_time_HMMs.html","id":"simulating-data","dir":"Articles","previous_headings":"Example 1: two states","what":"Simulating data","title":"Continuous-time HMMs","text":"simulate continuous-time Markov chain drawing exponentially distributed state dwell-times. Within stay, can assume whatever structure like observation times, explicitly modeled. choose generate Poisson process rate \\lambda=1, choice arbitrary. details Poisson point processes, see MM(M)PP vignette. Let’s visualise simulated continuous-time HMM:","code":"set.seed(123)  k = 200 # number of state switches trans_times = s = rep(NA, k) # time points where the chain transitions s[1] = sample(1:2, 1) # initial distribuion c(0.5, 0.5) # exponentially distributed waiting times trans_times[1] = rexp(1, -Q[s[1],s[1]]) n_arrivals = rpois(1, trans_times[1]) obs_times = sort(runif(n_arrivals, 0, trans_times[1])) x = rnorm(n_arrivals, mu[s[1]], sigma[s[1]]) for(t in 2:k){   s[t] = c(1,2)[-s[t-1]] # for 2-states, always a state swith when transitioning   # exponentially distributed waiting times   trans_times[t] = trans_times[t-1] + rexp(1, -Q[s[t], s[t]])   n_arrivals = rpois(1, trans_times[t]-trans_times[t-1])   obs_times = c(obs_times,                  sort(runif(n_arrivals, trans_times[t-1], trans_times[t])))   x = c(x, rnorm(n_arrivals, mu[s[t]], sigma[s[t]])) } color = c(\"orange\", \"deepskyblue\")  n = length(obs_times) plot(obs_times[1:50], x[1:50], pch = 16, bty = \"n\", xlab = \"observation times\",       ylab = \"x\", ylim = c(-5,25)) segments(x0 = c(0,trans_times[1:48]), x1 = trans_times[1:49],           y0 = rep(-5,50), y1 = rep(-5,50), col = color[s[1:49]], lwd = 4) legend(\"topright\", lwd = 2, col = color,         legend = c(\"state 1\", \"state 2\"), box.lwd = 0)"},{"path":"https://janoleko.github.io/articles/Continuous_time_HMMs.html","id":"writing-the-negative-log-likelihood-function","dir":"Articles","previous_headings":"Example 1: two states","what":"Writing the negative log-likelihood function","title":"Continuous-time HMMs","text":"likelhood continuous-time HMM observations x_{t_1}, \\dots, x_{t_T} irregular time points t_1, \\dots, t_T exact structure regular HMM likelihood:  L(\\theta) = \\delta^{(1)} \\Gamma(t_1, t_2) P(x_{t_2}) \\Gamma(t_2, t_3) P(x_{t_3}) \\dots \\Gamma(t_{T-1}, t_T) P(x_{t_T}) 1^t,  \\delta^{(1)}, P 1^t usual \\Gamma(t_k, t_{k+1}) computed explained . Thus can fit models using standard implementation general forward algorithm forward_g() time-varying transition probability matrices. can use generator() function compute infinitesimal generator matrix unconstrained parameter vector tpm_cont() compute matrix exponentials.","code":"nll = function(par, timediff, x, N){   mu = par[1:N]   sigma = exp(par[N+1:N])   Q = generator(par[2*N+1:(N*(N-1))]) # generator matrix   Pi = stationary_cont(Q) # stationary dist of CT Markov chain   Qube = tpm_cont(Q, timediff) # this computes exp(Q*timediff)   allprobs = matrix(1, nrow = length(x), ncol = N)   ind = which(!is.na(x))   for(j in 1:N){     allprobs[ind,j] = dnorm(x[ind], mu[j], sigma[j])   }   -forward_g(Pi, Qube, allprobs) }"},{"path":"https://janoleko.github.io/articles/Continuous_time_HMMs.html","id":"fitting-a-continuous-time-hmm-to-the-data","dir":"Articles","previous_headings":"Example 1: two states","what":"Fitting a continuous-time HMM to the data","title":"Continuous-time HMMs","text":"","code":"par = c(mu = c(5, 15), # state-dependent means         logsigma = c(log(3), log(5)), # state-dependent sds         qs = c(log(1), log(0.5))) # off-diagonals of Q  timediff = diff(obs_times)  system.time(   mod <- nlm(nll, par, timediff = timediff, x = x, N = 2) ) #>    user  system elapsed  #>   0.287   0.250   0.275"},{"path":"https://janoleko.github.io/articles/Continuous_time_HMMs.html","id":"results","dir":"Articles","previous_headings":"Example 1: two states","what":"Results","title":"Continuous-time HMMs","text":"","code":"N = 2 # mu round(mod$estimate[1:N],2) #> [1]  5.06 20.24 # sigma round(exp(mod$estimate[N+1:N])) #> [1] 2 5 Q = generator(mod$estimate[2*N+1:(N*(N-1))]) round(Q,3) #>        S1     S2 #> S1 -0.479  0.479 #> S2  0.905 -0.905"},{"path":[]},{"path":"https://janoleko.github.io/articles/Continuous_time_HMMs.html","id":"setting-parameters-for-simulation-1","dir":"Articles","previous_headings":"Example 2: three states","what":"Setting parameters for simulation","title":"Continuous-time HMMs","text":"","code":"# generator matrix Q: Q = matrix(c(-0.5,0.2,0.3,              1,-2, 1,              0.4, 0.6, -1), nrow = 3, byrow = TRUE)  # parameters for the state-dependent (normal) distributions mu = c(5, 15, 30) sigma = c(2, 3, 5)"},{"path":"https://janoleko.github.io/articles/Continuous_time_HMMs.html","id":"simulating-data-1","dir":"Articles","previous_headings":"Example 2: three states","what":"Simulating data","title":"Continuous-time HMMs","text":"simulation similar now also draw state transition , explained beginning.","code":"set.seed(123)  k = 200 # number of state switches trans_times = s = rep(NA, k) # time points where the chain transitions s[1] = sample(1:3, 1) # uniform initial distribuion # exponentially distributed waiting times trans_times[1] = rexp(1, -Q[s[1],s[1]]) n_arrivals = rpois(1, trans_times[1]) obs_times = sort(runif(n_arrivals, 0, trans_times[1])) x = rnorm(n_arrivals, mu[s[1]], sigma[s[1]]) for(t in 2:k){   # off-diagonal elements of the s[t-1] row of Q divided by the diagonal element   # give the probabilites of the next state   s[t] = sample(c(1:3)[-s[t-1]], 1, prob = Q[s[t-1],-s[t-1]]/-Q[s[t-1],s[t-1]])   # exponentially distributed waiting times   trans_times[t] = trans_times[t-1] + rexp(1, -Q[s[t], s[t]])   n_arrivals = rpois(1, trans_times[t]-trans_times[t-1])   obs_times = c(obs_times,                  sort(runif(n_arrivals, trans_times[t-1], trans_times[t])))   x = c(x, rnorm(n_arrivals, mu[s[t]], sigma[s[t]])) }"},{"path":"https://janoleko.github.io/articles/Continuous_time_HMMs.html","id":"fitting-a-3-state-continuous-time-hmm-to-the-data","dir":"Articles","previous_headings":"Example 2: three states","what":"Fitting a 3-state continuous-time HMM to the data","title":"Continuous-time HMMs","text":"","code":"par = c(mu = c(5, 10, 25), # state-dependent means         logsigma = c(log(2), log(2), log(6)), # state-dependent sds         qs = rep(0, 6)) # off-diagonals of Q  timediff = diff(obs_times)  system.time(   mod2 <- nlm(nll, par, timediff = timediff, x = x, N = 3, stepmax = 10) ) #>    user  system elapsed  #>   1.540   2.180   1.242 # without restricting stepmax, we run into numerical problems"},{"path":"https://janoleko.github.io/articles/Continuous_time_HMMs.html","id":"results-1","dir":"Articles","previous_headings":"Example 2: three states","what":"Results","title":"Continuous-time HMMs","text":"Continue reading Markov-modulated Poisson processes.","code":"N = 3 # mu round(mod2$estimate[1:N],2) #> [1]  4.90 15.45 29.10 # sigma round(exp(mod2$estimate[N+1:N]),2) #> [1] 1.80 2.58 5.06 Q = generator(mod2$estimate[2*N+1:(N*(N-1))]) round(Q, 3) #>        S1     S2     S3 #> S1 -0.888  0.565  0.323 #> S2  2.821 -3.469  0.647 #> S3  0.000  0.770 -0.770"},{"path":[]},{"path":"https://janoleko.github.io/articles/HSMMs.html","id":"simulation-example","dir":"Articles","previous_headings":"","what":"Simulation example","title":"Hidden semi-Markov models","text":"begin considering homogeneous HSMMs. models, state associated state dwell-time distribution. transition probability matrix regular HMM replaced distributions conditional transition probabilities given state left.","code":""},{"path":"https://janoleko.github.io/articles/HSMMs.html","id":"setting-parameters","dir":"Articles","previous_headings":"Simulation example","what":"Setting parameters","title":"Hidden semi-Markov models","text":"choose simplest case dwell times shifted Poisson distributed. specify Poisson mean state, conditional transition probability matrix called \\Omega parameters state-dependent process.","code":"# loading the package library(LaMa) #> Loading required package: RTMB lambda = c(7, 4, 4) omega = matrix(c(0, 0.7, 0.3,                  0.5, 0, 0.5,                  0.7, 0.3, 0), nrow = 3, byrow = TRUE) mu = c(10, 40, 100) sigma = c(5, 20, 50)  color = c(\"orange\", \"deepskyblue\", \"seagreen2\") curve(dnorm(x, mu[1], sigma[1]), lwd = 2, col = color[1], bty = \"n\",       xlab = \"x\", ylab = \"density\", xlim = c(0, 150), n = 300) curve(dnorm(x, mu[2], sigma[2]), lwd = 2, col = color[2], add = T) curve(dnorm(x, mu[3], sigma[3]), lwd = 2, col = color[3], add = T)"},{"path":"https://janoleko.github.io/articles/HSMMs.html","id":"simulating-data","dir":"Articles","previous_headings":"Simulation example","what":"Simulating data","title":"Hidden semi-Markov models","text":"simulate data drawing dwell times dwell-time distribution current state draw next state using conditional transition probabilities. state-dependent process drawn conditional current state.","code":"set.seed(123)  k = 50 # number of stays s = rep(NA, k) s[1] = sample(1:3, 1) # uniform initial distribution staylength = rpois(1, lambda[s[1]]) + 1 # drawing dwell time from shifted Poisson C = rep(s[1], staylength) x = rnorm(staylength, mu[s[1]], sigma[s[1]])  for(t in 2:k){   # conditionally drawing state   s[t] = sample(c(1:3)[-s[t-1]], 1, prob = omega[s[t-1], -s[t-1]])   staylength = rpois(1, lambda[s[t]]) + 1 # drawing dwell time from shifted Poisson      C = c(C, rep(s[t], staylength))   x = c(x, rnorm(staylength, mu[s[t]], sigma[s[t]])) }  plot(x, pch = 20, col = color[C], bty = \"n\") legend(\"topright\", col = color, pch = 20,         legend = paste(\"state\", 1:3), box.lwd = 0)"},{"path":"https://janoleko.github.io/articles/HSMMs.html","id":"writing-the-negative-log-likelihood-function","dir":"Articles","previous_headings":"Simulation example","what":"Writing the negative log-likelihood function","title":"Hidden semi-Markov models","text":"now write negative log-likelihood function approximating HMM. semi-Markov chain specified terms state-specific dwell-time distributions conditional transition probabilities given current state left, compute (called dm omega). latter, can use function tpm_emb() constructs transition probability matrix via inverse multinomial logit link (softmax), diagonal entries forced equal zero. transition probability matrix approxmiating HMM can computed function tpm_hsmm() exact procedure detailed Langrock Zucchini (2011). need extra argument agsizes specify aggregate sizes used approximate dwell-time distributions. chosen support state-specific dwell-time distributions covered.","code":"nll = function(par, x, N, agsizes){   mu = par[1:N]   sigma = exp(par[N+1:N])   lambda = exp(par[2*N+1:N])   omega = if(N==2) tpm_emb() else tpm_emb(par[3*N+1:(N*(N-2))])   dm = list() # list of dwell-time distributions   for(j in 1:N) dm[[j]] = dpois(1:agsizes[j]-1, lambda[j]) # shifted Poisson   Gamma = tpm_hsmm(omega, dm, sparse = FALSE)   delta = stationary(Gamma)   allprobs = matrix(1, length(x), N)   ind = which(!is.na(x))   for(j in 1:N){     allprobs[ind,j] = dnorm(x[ind], mu[j], sigma[j])   }   -forward_s(delta, Gamma, allprobs, agsizes) }"},{"path":"https://janoleko.github.io/articles/HSMMs.html","id":"fitting-an-hsmm-as-an-approxiating-hmm-to-the-data","dir":"Articles","previous_headings":"Simulation example","what":"Fitting an HSMM (as an approxiating HMM) to the data","title":"Hidden semi-Markov models","text":"Fitting HSMMs rather slow (even using C++) translate additional model complexity higher computational overhead (31 states ).","code":"# intial values par = c(10, 40, 100, log(c(5, 20, 50)), # state-dependent                log(c(7,4,4)), # dwell time means                rep(0, 3)) # omega  agsizes = qpois(0.95, lambda)+1  system.time(   mod <- nlm(nll, par, x = x, N = 3, agsizes = agsizes, stepmax = 2) ) #>    user  system elapsed  #>   0.945   0.049   0.995"},{"path":"https://janoleko.github.io/articles/HSMMs.html","id":"results","dir":"Articles","previous_headings":"Simulation example","what":"Results","title":"Hidden semi-Markov models","text":"","code":"N = 3 (mu = mod$estimate[1:N]) #> [1]  10.16569  39.06161 107.66034 (sigma = exp(mod$estimate[N+1:N])) #> [1]  4.78882 19.35639 48.56115 (lambda = exp(mod$estimate[2*N+1:N])) #> [1] 6.942983 4.595469 3.354765 (omega = tpm_emb(mod$estimate[3*N+1:(N*(N-2))])) #>           S1        S2        S3 #> S1 0.0000000 0.5541031 0.4458969 #> S2 0.5040939 0.0000000 0.4959061 #> S3 0.6654702 0.3345298 0.0000000"},{"path":"https://janoleko.github.io/articles/HSMMs.html","id":"real-data-application","dir":"Articles","previous_headings":"","what":"Real-data application","title":"Hidden semi-Markov models","text":"now want briefly show analysis real data set using hidden semi-Markov models. purpose use movement track Arctic muskox contained R package PHSMM. Originally data collected Beumer et al. (2020) already analysed Pohle, Adam, Beumer (2022). data already preprossed, can immediately write negative log-likelihood function. modeling dwell-time distribution real processes, typically advisable use flexible distribution shifted Poisson distribution, latter account overdispersion. , employ shifted negative binomial distribution yields Poisson distribution special case dispersion parameter equal zero. state-dependent step lengths modelled gamma distributions, reparametrise gamma distribution terms mean standard deviation opposed shape scale better interpretability using dgamma2().","code":"library(PHSMM) data = muskox[1:1000, ] # only using first 1000 observations for speed head(data) #>                      date tday        x       y       step #> 88273 2013-10-11 22:00:00   15 513299.2 8264867  17.998874 #> 88274 2013-10-11 22:00:00   16 513283.4 8264875   8.214733 #> 88275 2013-10-11 22:00:00   17 513284.3 8264883   7.205098 #> 88276 2013-10-11 22:00:00   18 513280.4 8264877  53.378332 #> 88277 2013-10-11 22:00:00   19 513252.0 8264922 719.242687 #> 88278 2013-10-11 22:00:00   20 513386.7 8265629  10.797127 nll_muskox = function(par, step, N, agsizes){   # parameter transformation from working to natural   mu = exp(par[1:N]) # step mean   sigma = exp(par[N+1:N]) # step standard deviation   mu_dwell = exp(par[2*N+1:N]) # dwell time mean   phi = exp(par[3*N+1:N]) # dwell time dispersion   omega = if(N==2) tpm_emb() else tpm_emb(par[4*N+1:(N*(N-2))])   dm = list() # list of dwell-time distributions   for(j in 1:N){      dm[[j]] = dnbinom(1:agsizes[j]-1, mu=mu_dwell[j], size=1/phi[j])    }   Gamma = tpm_hsmm(omega, dm, sparse = FALSE)   delta = stationary(Gamma)   allprobs = matrix(1, length(step), N)   ind = which(!is.na(step))   for(j in 1:N) allprobs[ind,j] = dgamma2(step[ind], mu[j], sigma[j])   -forward_s(delta, Gamma, allprobs, agsizes) }"},{"path":"https://janoleko.github.io/articles/HSMMs.html","id":"fitting-an-hsmm-as-an-approxiating-hmm-to-the-muskox-data","dir":"Articles","previous_headings":"Real-data application","what":"Fitting an HSMM (as an approxiating HMM) to the muskox data","title":"Hidden semi-Markov models","text":"","code":"# intial values par = c(log(c(4, 50, 300, 4, 50, 300)), # state-dependent mean and sd                log(c(3,3,5)), # dwell time means                log(c(0.01, 0.01, 0.01)), # dwell time dispersion                rep(0, 3)) # omega  agsizes = c(11,11,14)  system.time(   mod_muskox <- nlm(nll_muskox, par, step = data$step, N = 3,                     agsizes = agsizes, iterlim = 500) ) #>    user  system elapsed  #>   3.911   0.018   3.930"},{"path":"https://janoleko.github.io/articles/HSMMs.html","id":"results-1","dir":"Articles","previous_headings":"Real-data application","what":"Results","title":"Hidden semi-Markov models","text":"retransform parameters interpretation case Poisson distribution sufficiently flexible dispersion parameters estimated close zero. can easily visualise estimated state-specific dwell-time distributions:","code":"par = mod_muskox$estimate; N = 3 (mu = exp(par[1:N])) # step mean #> [1]   4.408141  55.517263 306.514625 (sigma = exp(par[N+1:N])) # step standard deviation #> [1]   3.148158  50.339378 331.549209 (mu_dwell = exp(par[2*N+1:N])) # dwell time mean #> [1] 2.544983 2.660373 5.541762 (phi = exp(par[3*N+1:N])) # dwell time dispersion #> [1] 6.502320e-06 3.754676e-02 2.221946e-11 (omega = tpm_emb(par[4*N+1:(N*(N-2))])) # embedded t.p.m. #>           S1        S2           S3 #> S1 0.0000000 0.6865994 3.134006e-01 #> S2 1.0000000 0.0000000 1.827658e-09 #> S3 0.8210754 0.1789246 0.000000e+00 oldpar = par(mfrow = c(1,3)) for(j in 1:N){   plot(1:agsizes[j], dnbinom(1:agsizes[j]-1, mu=mu_dwell[j], size = 1/phi[j]),        type = \"h\", lwd = 2, col = color[j], xlab = \"dwell time (hours)\",        ylab = \"probabilities\", main = paste(\"state\",j), bty = \"n\", ylim = c(0,0.25)) } par(oldpar)"},{"path":[]},{"path":"https://janoleko.github.io/articles/Inhomogeneous_HMMs.html","id":"covariate-effects-in-the-state-process","dir":"Articles","previous_headings":"","what":"Covariate effects in the state process","title":"Inhomogeneous HMMs","text":"covariates affect transition probabilities, implies model transition probability matrix function said covariates. Let z_t vector covariates length p+1 t = 1, \\dots, T, first entry always equal 1 include intercept. Moreover, let \\beta_{ij} vector regression parameters, also length p+1 -diagonal element (\\neq j) transition probability matrix. First, consider linear predictors  \\eta_{ij}^{(t)} = \\beta_{ij}^{'} z_t,  t = 1, \\dots, T. transition probabilities need lie interval (0,1) row transition matrix needs sum one, obtain transition probabilities via inverse multinomial logistic link  \\gamma_{ij}^{(t)} = \\Pr(S_t = j \\mid S_{t-1} = ) = \\frac{\\exp(\\eta_{ij}^{(t)})}{\\sum_{k=1}^N \\exp(\\eta_{ik}^{(t)})},  \\eta_{ii} set zero = 1, \\dots, N identifiability N number hidden states. function tpm_g() conducts calculation elements t.p.m. time points efficiently C++. point want point definition transition probabilities necessarily unique. Indeed data points times 1, \\dots, T need T-1 transition probability matrices. definition means transition probability t-1 t depends covariate values time point t, also defined  \\gamma_{ij}^{(t)} = \\Pr(S_{t+1} = j \\mid S_t = ).  want point two specifications equivalent. HMMs established convention, choice needs made users can important exact timing covariate effect relevant. LaMa comes either passing design matrix excluding first last row tpm_g(), use first option vignette. forget exclude first last row design matrix calculating transition matrices, pass array dimension c(N,N,T) forward_g() likelihood evaluation, function revert first option just ignoring first slice array.","code":""},{"path":"https://janoleko.github.io/articles/Inhomogeneous_HMMs.html","id":"simulation-example","dir":"Articles","previous_headings":"Covariate effects in the state process","what":"Simulation example","title":"Inhomogeneous HMMs","text":"begin simulating data specified model, assuming 2 states Gaussian state-dependent distributions. covariate effects state process fully specified parameter matrix beta dimension c(N*(N-1), p+1). default function tpm_g() fill -diagonal elements transition matrix column, can changed setting byrow = TRUE. latter useful, popular HMM packages like moveHMM momentuHMM return parameter matrix t.p.m. needs filled row.  Let’s now simulate synthetic data specified model.  now model transition probabilities parametrically, paramter intercept, linear effect quadratic effect -diagonal element t.p.m.","code":"# loading the package library(LaMa) #> Loading required package: RTMB # parameters mu = c(5, 20)   # state-dependent means sigma = c(4, 5) # state-dependent standard deviations  # state process regression parameters beta = matrix(c(-2, -2,       # intercepts                 -1, 0.5,      # linear effects                 0.25, -0.25), # quadratic effects               nrow = 2)  n = 1000 # number of observations set.seed(123) z = rnorm(n) # in practice there will be n covariate values. # However, we only have n-1 transitions, thererfore we only need n-1 values: Z = cbind(z, z^2) # quadratic effect of z Gamma = tpm_g(Z = Z[-1,], beta) # of dimension c(2, 2, n-1) delta = c(0.5, 0.5) # non-stationary initial distribution  color = c(\"orange\", \"deepskyblue\")  oldpar = par(mfrow = c(1,2)) zseq = seq(-2,2,by = 0.01) Gamma_seq = tpm_g(Z = cbind(zseq, zseq^2), beta) plot(zseq, Gamma_seq[1,2,], type = \"l\", lwd = 3, bty = \"n\", ylim = c(0,1),       xlab = \"z\", ylab = \"gamma_12\", col = color[1]) plot(zseq, Gamma_seq[2,1,], type = \"l\", lwd = 3, bty = \"n\", ylim = c(0,1),      xlab = \"z\", ylab = \"gamma_21\", col = color[2]) par(oldpar) s = rep(NA, n) s[1] = sample(1:2, 1, prob = delta) # sampling first state from initial distr. for(t in 2:n){   # sampling next state conditional on previous one with tpm at that time point   s[t] = sample(1:2, 1, prob = Gamma[s[t-1],,t-1]) } # sampling observations conditional on the states x = rnorm(n, mu[s], sigma[s])  plot(x[1:200], bty = \"n\", pch = 20, ylab = \"x\",       col = c(color[1], color[2])[s[1:200]])"},{"path":"https://janoleko.github.io/articles/Inhomogeneous_HMMs.html","id":"writing-the-negative-log-likelihood-function","dir":"Articles","previous_headings":"Covariate effects in the state process","what":"Writing the negative log-likelihood function","title":"Inhomogeneous HMMs","text":"specify likelihood function pretend know polynomial degree effect z transition probabilities.","code":"nll = function(par, x, Z){   beta = matrix(par[1:6], nrow = 2) # matrix of coefficients   Gamma = tpm_g(Z[-1,], beta) # excluding the first covariate value -> n-1 tpms   delta = c(1, exp(par[7]))   delta = delta / sum(delta)   mu = par[8:9]   sigma = exp(par[10:11])   # calculate all state-dependent probabilities   allprobs = matrix(1, length(x), 2)   for(j in 1:2) allprobs[,j] = dnorm(x, mu[j], sigma[j])   # forward algorithm   -forward_g(delta, Gamma, allprobs) }"},{"path":"https://janoleko.github.io/articles/Inhomogeneous_HMMs.html","id":"fitting-an-hmm-to-the-data","dir":"Articles","previous_headings":"Covariate effects in the state process","what":"Fitting an HMM to the data","title":"Inhomogeneous HMMs","text":"Really fast!","code":"par = c(beta = c(-2, -2, rep(0,4)), # initialising with homogeneous tpm         logitdelta = 0, # starting value for initial distribution         mu = c(4, 14), # initial state-dependent means         sigma = c(log(3),log(5))) # initial state-dependents sds system.time(   mod <- nlm(nll, par, x = x, Z = Z)  ) #>    user  system elapsed  #>   0.660   0.029   0.689"},{"path":"https://janoleko.github.io/articles/Inhomogeneous_HMMs.html","id":"visualising-results","dir":"Articles","previous_headings":"Covariate effects in the state process","what":"Visualising results","title":"Inhomogeneous HMMs","text":", use tpm_g() stationary() tranform parameters.","code":"# transform parameters to working beta_hat = matrix(mod$estimate[1:6], nrow = 2) Gamma_hat = tpm_g(Z = Z[-1,], beta_hat) delta_hat = c(1, exp(mod$estimate[7])) delta_hat = delta_hat / sum(delta_hat) mu_hat = mod$estimate[8:9] sigma_hat = exp(mod$estimate[10:11])  # we calculate the average state distribution overall all covariate values zseq = seq(-2, 2, by = 0.01) Gamma_seq = tpm_g(Z = cbind(zseq, zseq^2), beta_hat) Prob = matrix(nrow = length(zseq), ncol = 2) for(i in 1:length(zseq)){ Prob[i,] = stationary(Gamma_seq[,,i]) } prob = apply(Prob, 2, mean)  hist(x, prob = TRUE, bor = \"white\", breaks = 20, main = \"\") curve(prob[1]*dnorm(x, mu_hat[1], sigma_hat[1]), add = TRUE, lwd = 3,        col = color[1], n=500) curve(prob[2]*dnorm(x, mu_hat[2], sigma_hat[2]), add = TRUE, lwd = 3,        col = color[2], n=500) curve(prob[1]*dnorm(x, mu_hat[1], sigma_hat[1])+         prob[2]*dnorm(x, mu[2], sigma_hat[2]),       add = TRUE, lwd = 3, lty = \"dashed\", n = 500) legend(\"topright\", col = c(color[1], color[2], \"black\"), lwd = 3, bty = \"n\",        lty = c(1,1,2), legend = c(\"state 1\", \"state 2\", \"marginal\")) oldpar = par(mfrow = c(1,2)) plot(zseq, Gamma_seq[1,2,], type = \"l\", lwd = 3, bty = \"n\", ylim = c(0,1),       xlab = \"z\", ylab = \"gamma_12_hat\", col = color[1]) plot(zseq, Gamma_seq[2,1,], type = \"l\", lwd = 3, bty = \"n\", ylim = c(0,1),      xlab = \"z\", ylab = \"gamma_21_hat\", col = color[2]) par(mfrow = c(1,1)) plot(zseq, Prob[,1], type = \"l\", lwd = 3, bty = \"n\", ylim = c(0,1), xlab = \"z\",       ylab = \"Pr(state 1)\", col = color[1]) par(oldpar)"},{"path":"https://janoleko.github.io/articles/Inhomogeneous_HMMs.html","id":"covariate-effects-in-the-state-dependent-process","dir":"Articles","previous_headings":"","what":"Covariate effects in the state-dependent process","title":"Inhomogeneous HMMs","text":"now look setting covariates influence mean state-dependent distribution, state switching controlled homogeneous Markov chain. often called Markov-switching regression. Assuming observation process conditionally normally distributed, means X_t \\mid S_t = j \\sim N(\\beta_j^{'} z_t, \\: \\sigma_j^2), \\quad j = 1, \\dots, N.","code":""},{"path":"https://janoleko.github.io/articles/Inhomogeneous_HMMs.html","id":"simulation-example-1","dir":"Articles","previous_headings":"Covariate effects in the state-dependent process","what":"Simulation example","title":"Inhomogeneous HMMs","text":"First specify parameters simulation. important change beta now contains regression coefficients state-dependent regressions.","code":"sigma = c(1, 1) # state-dependent standard deviations (homoscedasticity)  # parameter matrix # each row contains parameter vector for the corresponding state beta = matrix(c(8, 10,             # intercepts                 -2, 1, 0.5, -0.5), # slopes               nrow = 2) n = 1000 # number of observations set.seed(123) z = rnorm(n) Z = cbind(z, z^2) # quadratic effect of z  Gamma = matrix(c(0.9, 0.1, 0.05, 0.95),                 nrow = 2, byrow = TRUE) # homogeneous t.p.m. delta = stationary(Gamma) # stationary Markov chain"},{"path":"https://janoleko.github.io/articles/Inhomogeneous_HMMs.html","id":"simulation","dir":"Articles","previous_headings":"Covariate effects in the state-dependent process","what":"Simulation","title":"Inhomogeneous HMMs","text":"simulation code, state-dependent mean now fixed anymore, changes accoring covariate values Z.","code":"s = x = rep(NA, n) s[1] = sample(1:2, 1, prob = delta) x[1] = rnorm(1, beta[s[1],]%*%c(1, Z[1,]), # state-dependent regression                     sigma[s[1]]) for(t in 2:n){   s[t] = sample(1:2, 1, prob = Gamma[s[t-1],])   x[t] = rnorm(1, beta[s[t],]%*%c(1, Z[t,]), # state-dependent regression                       sigma[s[t]]) }  oldpar = par(mfrow = c(1,2)) plot(x[1:400], bty = \"n\", pch = 20, ylab = \"x\",       col = c(color[1], color[2])[s[1:400]])  plot(z[which(s==1)], x[which(s==1)], pch = 16, col = color[1], bty = \"n\",       ylim = c(0,15), xlab = \"z\", ylab = \"x\") points(z[which(s==2)], x[which(s==2)], pch = 16, col = color[2]) par(oldpar)"},{"path":"https://janoleko.github.io/articles/Inhomogeneous_HMMs.html","id":"writing-the-negative-log-likelihood-function-1","dir":"Articles","previous_headings":"Covariate effects in the state-dependent process","what":"Writing the negative log-likelihood function","title":"Inhomogeneous HMMs","text":"likelihood function, also add state-dependent regression loop calculating state-dependent probabilities. code cbind(1,Z) %*% beta[j,] computes linear predictor j-th state.","code":"nllMSR = function(par, x, Z){   Gamma = tpm(par[1:2]) # homogeneous tpm   delta = stationary(Gamma) # stationary Markov chain   beta = matrix(par[2 + 1:(2 + 2*2)], nrow = 2) # parameter matrix   sigma = exp(par[2 + 2 + 2*2 + 1:2])   # calculate all state-dependent probabilities   allprobs = matrix(1, length(x), 2)   # state-dependent regression   for(j in 1:2) allprobs[,j] = dnorm(x, cbind(1,Z) %*% beta[j,], sigma[j])   # forward algorithm   -forward(delta, Gamma, allprobs) }"},{"path":"https://janoleko.github.io/articles/Inhomogeneous_HMMs.html","id":"fitting-a-markov-switching-regression-model","dir":"Articles","previous_headings":"Covariate effects in the state-dependent process","what":"Fitting a Markov-switching regression model","title":"Inhomogeneous HMMs","text":"","code":"par = c(logitgamma = c(-2, -3),      # starting values state process         beta = c(8, 10, rep(0,4)),   # starting values for regression         logsigma = c(log(1),log(1))) # starting values for sigma system.time(   mod_reg <- nlm(nllMSR, par, x = x, Z = Z) ) #>    user  system elapsed  #>   0.309   0.018   0.328"},{"path":"https://janoleko.github.io/articles/Inhomogeneous_HMMs.html","id":"visualising-results-1","dir":"Articles","previous_headings":"Covariate effects in the state-dependent process","what":"Visualising results","title":"Inhomogeneous HMMs","text":"visualise results, transform parameters working parameters add two estimated state-specific regressions scatter plot.  Continue reading Periodic HMMs, LaMa RTMB, Penalised splines.","code":"Gamma_hat_reg = tpm(mod_reg$estimate[1:2]) # calculating all tpms delta_hat_reg = stationary(Gamma_hat_reg) beta_hat_reg = matrix(mod_reg$estimate[2+1:(2*2+2)], nrow = 2) sigma_hat_reg = exp(mod_reg$estimate[2+2*2+2 +1:2])  # we have some label switching plot(z, x, pch = 16, bty = \"n\", xlab = \"z\", ylab = \"x\", col = color[s]) points(z, x, pch = 20) curve(beta_hat_reg[1,1] + beta_hat_reg[1,2]*x + beta_hat_reg[1,3]*x^2,        add = TRUE, lwd = 4, col = color[2]) curve(beta_hat_reg[2,1] + beta_hat_reg[2,2]*x + beta_hat_reg[2,3]*x^2,        add = TRUE, lwd = 4, col = color[1])"},{"path":"https://janoleko.github.io/articles/Intro_to_LaMa.html","id":"introductory-example-homogeneous-hmm","dir":"Articles","previous_headings":"","what":"Introductory example: Homogeneous HMM","title":"Introduction to LaMa","text":"vignette, start simple HMM can think . basic N-state HMM doubly stochastic process discrete time. Observations generated one N possible distributions f_j(x_t), j = 1, \\dots N unobserved N-state Markov chain selecting distribution active given time point. Hence, HMMs can interpreted temporally dependent mixture models popular accross wide range disciplines like ecology, sports finance time-series data underlying sequential dependencies analysed. statements already hint two main assumptions model, namely f(s_t \\mid s_{t-1}, s_{t-2}, \\dots, s_1) = f(s_t \\mid s_{t-1}) (Markov assumption) f(x_t \\mid x_1, \\dots, x_{t-1}, x_{t-1}, x_T, s_1, \\dots, s_T) = f(x_t \\mid s_t) (conditional independence assumption). hidden state process described Markov chain, stochastic process can easily characterised initial distribution \\delta^{(1)} = (\\Pr(S_1 = 1), \\dots, \\Pr(S_1 = N)) one-step transition probabilities \\gamma_{ij} = \\Pr(S_t = j \\mid S_{t-1} = ), \\quad ,j = 1, \\dotsc, N typically summarised -called transition probability matrix (t.p.m.) \\Gamma = (\\gamma_{ij})_{,j = 1, \\dots, N} row conditional one-step ahead distribution state process given current state . matrix -conveniently parameterised unconstrained parameter vector N (N-1) -diagonal elements. row can computed via inverse multinomial logistic link (also known softmax). can done using function tpm(): HMMs homogeneous transition probabilities, often assume stationarity underlying Markov chain, well-behaved Markov chains converge unique stationary distribution. e.g. observe animial model behavioral states Markov chain, reasonable assume chain running long time prior observation thus already converged stationary distribution. distribution (call \\delta) can computed solving system equations  \\delta \\Gamma = \\delta, \\quad \\text{s.t.} \\; \\sum_{j=1}^N \\delta_j = 1,  implemented function stationary(). stationary HMMs, replace initial distribution \\delta^{(1)} stationary distribution. can easily compute stationary distribution associated t.p.m. using stationary distribution can interpreted log-run-time proportion time spent state. conditional distributions observations f_j(x_t), typical choice kind parametric family like normal gamma distributions state-specific means standard deviations. exhaustive description models see Zucchini, MacDonald, Langrock (2016).","code":"(Gamma = tpm(c(-2, -3))) # 2 states -> 2*(1-2) = 2 off-diagonal entries #>           S1         S2 #> S1 0.9525741 0.04742587 #> S2 0.1192029 0.88079708 (delta = stationary(Gamma)) #>        S1        S2  #> 0.7153801 0.2846199"},{"path":"https://janoleko.github.io/articles/Intro_to_LaMa.html","id":"generating-data-from-a-2-state-hmm","dir":"Articles","previous_headings":"Introductory example: Homogeneous HMM","what":"Generating data from a 2-state HMM","title":"Introduction to LaMa","text":"start simulating data simple 2-state HMM Gaussian state-dependent distributions, get intuition. can use stationary() compute stationary distribution.","code":"# parameters mu = c(0, 6)    # state-dependent means sigma = c(2, 4) # state-dependent standard deviations Gamma = matrix(c(0.95, 0.05, 0.15, 0.85), # transition probability matrix                nrow = 2, byrow = TRUE) delta = stationary(Gamma) # stationary distribution  # simulation n = 1000 set.seed(123) s = rep(NA, n) s[1] = sample(1:2, 1, prob = delta) # sampling first state from delta for(t in 2:n){   # drawing the next state conditional on the last one   s[t] = sample(1:2, 1, prob = Gamma[s[t-1],])  } # drawing the observation conditional on the states x = rnorm(n, mu[s], sigma[s])  color = c(\"orange\", \"deepskyblue\") plot(x[1:200], bty = \"n\", pch = 20, ylab = \"x\",       col = color[s[1:200]])"},{"path":"https://janoleko.github.io/articles/Intro_to_LaMa.html","id":"inference-by-direct-numerical-maximum-likelihood-estimation","dir":"Articles","previous_headings":"Introductory example: Homogeneous HMM","what":"Inference by direct numerical maximum likelihood estimation","title":"Introduction to LaMa","text":"Inference HMMs difficult compared e.g. regression modelling observations independent. want estimate model parameters via maximum likelihood estimation, due nice properties possessed maximum likelihood estimator. However, computing HMM likelihood observed data points x_1, \\dots, x_T non-trivial task observe underlying states. thus need sum possible state sequences infeasible general state processes. can, however, exploit Markov property thus calculate likelihood recursively matrix product using -called forward algorithm. closed form, HMM likelihood becomes L(\\theta) = \\delta^{(1)} P(x_1) \\Gamma P(x_2) \\Gamma \\dots \\Gamma P(x_T) 1^t,  \\delta^{(1)} \\Gamma defined , P(x_t) diagonal matrix state-dependent densities probability mass functions f_j(x_t) = f(x_t \\mid S_t = j) diagonal 1 row vector ones length N. model parameters summarised vector \\theta. able evaluate likelihood function, can numerically maximised popular optimisers like nlm() optim(). algorithm explained suffers numerical underflow T moderately large likelihood rounded zero. Thus, one can use scaling strategy, detailed Zucchini, MacDonald, Langrock (2016), avoid calculate log-likelihood recursively. version forward algorithm implemented LaMa written C++. Additionally, HMMs often need constrain domains several model parameters \\theta (.e. positive standard deviations transition probability matrix elements 0 1 rows sum one). One now resort contrained numerical optimisation practice better option maximise likelihood w.r.t. transformed version (real number line) model parameters using suitable invertible differenentiable link functions (denoted par code). example use log-link parameters need strictly positive multinomial logistic link transition probability matrix. former can easily coded hand, latter implemented functions tpm family convenience computational speed. efficiency, also advisable evaluate state-dependent densities (probability mass functions) vectorised outside recursive forward algorithm. results matrix containing state-dependent likelihoods data point (rows), conditional state (columns), , throughout package, call allprobs matrix. example, within negative log-likelihood function build homogeneous transition probability matrix using tpm() function compute stationary distribution Markov chain using stationary(). build allprobs matrix calculate log-likelihood using forward() last line. returned negative function can numerically minimised e.g. nlm().","code":"nll = function(par, x){   # parameter transformations for unconstrained optimisation   Gamma = tpm(par[1:2]) # multinomial logistic link   delta = stationary(Gamma) # stationary initial distribution   mu = par[3:4] # no transformation needed   sigma = exp(par[5:6]) # strictly positive   # calculating all state-dependent probabilities outside the forward algorithm   allprobs = matrix(1, length(x), 2)   for(j in 1:2) allprobs[,j] = dnorm(x, mu[j], sigma[j])   # return negative for minimisation   -forward(delta, Gamma, allprobs) }"},{"path":"https://janoleko.github.io/articles/Intro_to_LaMa.html","id":"fitting-an-hmm-to-the-data","dir":"Articles","previous_headings":"Introductory example: Homogeneous HMM","what":"Fitting an HMM to the data","title":"Introduction to LaMa","text":"see implementation forward algorithm C++ leads really fast estimation speeds.","code":"par = c(logitGamma = qlogis(c(0.05, 0.05)),         mu = c(1,4),         logsigma = c(log(1),log(3))) # initial transformed parameters: not chosen too well system.time(   mod <- nlm(nll, par, x = x) ) #>    user  system elapsed  #>   0.116   0.015   0.132"},{"path":"https://janoleko.github.io/articles/Intro_to_LaMa.html","id":"visualising-results","dir":"Articles","previous_headings":"Introductory example: Homogeneous HMM","what":"Visualising results","title":"Introduction to LaMa","text":"model estimation, need retransform unconstrained parameters according code inside likelihood:  can also decode probable state sequence viterbi() function, first computing allprobs matrix:  Lastly, can model checking using pseudo-residuals. First, need compute local state probabilities observations: , can pass observations, state probabilities, parametric family estimated parameters pseudo_res() function get pseudo-residuals model validation. standard normally distributed model correct.  case, model looks really good – simulated exact model. Continue reading LaMa RTMB, Inhomogeneous HMMs, Periodic HMMs, Longitudinal data, State-space models, Hidden semi-Markov models, Continuous-time HMMs.","code":"# transform parameters to working Gamma = tpm(mod$estimate[1:2]) delta = stationary(Gamma) # stationary HMM mu = mod$estimate[3:4] sigma = exp(mod$estimate[5:6])  hist(x, prob = TRUE, bor = \"white\", breaks = 40, main = \"\") curve(delta[1]*dnorm(x, mu[1], sigma[1]), add = TRUE, lwd = 2, col = \"orange\", n=500) curve(delta[2]*dnorm(x, mu[2], sigma[2]), add = TRUE, lwd = 2, col = \"deepskyblue\", n=500) curve(delta[1]*dnorm(x, mu[1], sigma[1])+delta[2]*dnorm(x, mu[2], sigma[2]),       add = TRUE, lwd = 2, lty = \"dashed\", n=500) legend(\"topright\", col = c(color, \"black\"), lwd = 2, bty = \"n\",        lty = c(1,1,2), legend = c(\"state 1\", \"state 2\", \"marginal\")) allprobs = matrix(1, length(x), 2) for(j in 1:2) allprobs[,j] = dnorm(x, mu[j], sigma[j])  states = viterbi(delta, Gamma, allprobs)  plot(x, pch = 20, bty = \"n\", col = color[states]) legend(\"topright\", pch = 20, legend = c(\"state 1\", \"state 2\"),         col = color, box.lwd = 0) probs = stateprobs(delta, Gamma, allprobs) pres = pseudo_res(x, # observations                   \"norm\", # parametric distribution to use                   list(mean = mu, sd = sigma), # parameters for that distribution                   probs) # local state probabilities  # use the plotting method for LaMaResiduals plot(pres, hist = TRUE)"},{"path":[]},{"path":"https://janoleko.github.io/articles/LaMa_and_RTMB.html","id":"basic-workflow","dir":"Articles","previous_headings":"","what":"Basic workflow","title":"LaMa and RTMB","text":"workflow RTMB basically always . need define negative log-likelihood function, create automatically differentiable objective function fit model numerical minimisation latter. RTMB also provides many functions make process convenient.","code":""},{"path":"https://janoleko.github.io/articles/LaMa_and_RTMB.html","id":"simple-hmm","dir":"Articles","previous_headings":"","what":"Simple HMM","title":"LaMa and RTMB","text":"start fitting super simple stationary HMM state-dependent gamma distributions step lengths von Mises distributions turning angles. first step, define initial parameter list par dat list contains data potential hyperparameters – N, number hidden states. names par dat course arbitrary. par named list initial parameter values, accessing parameters later much convenient indexing. can also use parameter vector RTMB, using named list makes life much easier. can now define negative log-likelihood function similar fashion basic numerical ML points made : prominently, negative log-likelihood function parameters estimated data parameters passed argument stage. something get used (know), just way RTMB works. getAll() function useful use first line unpack par dat list, making elements available without $ operator. stage, nll just takes dat object global environment. Parameter transformations course still necessary, .e. parameters par unconstrained. might wonder earth RTMB can calculate gradient parameters distributions like gamma von Mises distribution. answer : can’t provides version standard distributions like dnorm(), dbinom(), etc. case dgamma2() dvm() come LaMa non-standard, hood build RTMB functions (dgamma2() actually just convenience function reparametrises gamma distribution terms mean standard deviation). Actually, standard functions (e.g. sum()), operators (e.g. %*%) methods (e.g. matrix) “overwritten” called inside MakeADFun() typically don’t notice care. REPORT() function offered RTMB really convenient quantities calculated likelihood function (written code anyway), reported, available optimisation, report statements ignored optimisation. annoying backtransformations anymore, wohoo! simple parameter transformations, ADREPORT() also great, calculates standard deviations ADREPORT()ed quantities, based delta method. Just note delta method advisable complex non-linear multivariate transformations. defined negative log-likelihood, can now create autmatically differentiable objective function fit model. needs little explanation: point, RTMB takes negative log-likelihood function generates (fast) version , including gradient. MakeADFun() now also grabs whatever saved dat global environment bakes objective function. Therefore, changes dat point effect optimisation result. set silent = TRUE suppress printing optimisation process. Let’s check obj: contains initial parameter par (now tranformed named vector), objective function fn (case just evaluates nll faster), gradient gr Hessian . now call functions without argument, get corresponding values initial parameter vector. now ready optimise objective function. optimisation routine nlminb() robust conveniently allows us provide gradient function. Alternatively, can also use optim() optimiser like allows pass gradient function. Indeed, provide Hessian nlminb() , evaluating Hessian fast RTMB, optimisation still much faster use quasi-Newton algorithm approximates current Hessian based previous gradient evaluations, compared using full Newton-Raphson. can check estimated parameter function value Note naming determined nlminb(). use different optimiser, may called differently. Much nicer however, obj (yes obj opt) automatically updated optimisation. Note calling obj$gr() optimisation now gives gradient optimum, obj$fn() still gives objective starting value obj$par updated still initial parameter vector (kind confusing). get estimated parameters natural scale, don’t backtransformation manually. can just run reporting: works REPORT() statements likelihood function. Note delta, Gamma allprobs always reported default using forward() useful e.g. state decoding viterbi(), many downstream LaMa functions take arguments inputs. Functions viterbi stateprobs family can also take reported list object input. state-dependent parameters depend specific model formulation, need reported manually user specifying negative log-likelihood. parameters, can plot decoded time series  estimated state-dependent distributions.  Moreover, can also use sdreport() function directly give us standard errors unconstrained parameters everything ADREPORT()ed.  can get overview estimated parameters ADREPORT()ed quantities well standard errors get estimated parameters standard errors list format, type get estimates standard errors ADREPORT()ed quantities list format, type Lastly, automatic reporting LaMa RTMB together makes calculating pseudo-residuals really convenient:","code":"par = list(   logmu = log(c(0.3, 1)),      # initial means for step length (log-transformed)   logsigma = log(c(0.2, 0.7)), # initial sds for step length (log-transformed)   logkappa = log(c(0.2, 0.7)), # initial concentration for turning angle (log-transformed)   eta = rep(-2, 2)             # initial t.p.m. parameters (on logit scale)   )      dat = list(   step = trex$step,   # hourly step lengths   angle = trex$angle, # hourly turning angles   N = 2   ) nll = function(par) {   getAll(par, dat) # makes everything contained available without $   Gamma = tpm(eta) # computes transition probability matrix from unconstrained eta   delta = stationary(Gamma) # computes stationary distribution   # exponentiating because all parameters strictly positive   mu = exp(logmu)   sigma = exp(logsigma)   kappa = exp(logkappa)   # reporting statements for later use   REPORT(mu); ADREPORT(mu)   REPORT(sigma); ADREPORT(sigma)   REPORT(kappa); ADREPORT(kappa)   # calculating all state-dependent densities   allprobs = matrix(1, nrow = length(step), ncol = N)   ind = which(!is.na(step) & !is.na(angle)) # only for non-NA obs.   for(j in 1:N){     allprobs[ind,j] = dgamma2(step[ind],mu[j],sigma[j])*dvm(angle[ind],0,kappa[j])   }   -forward(delta, Gamma, allprobs) # simple forward algorithm } obj = MakeADFun(nll, par, silent = TRUE) # creating the objective function names(obj) #>  [1] \"par\"          \"fn\"           \"gr\"           \"he\"           \"hessian\"      #>  [6] \"method\"       \"retape\"       \"env\"          \"report\"       \"simulate\"     #> [11] \"force.update\" obj$par #>      logmu      logmu   logsigma   logsigma   logkappa   logkappa        eta  #> -1.2039728  0.0000000 -1.6094379 -0.3566749 -1.6094379 -0.3566749 -2.0000000  #>        eta  #> -2.0000000 obj$fn() #> [1] 33293.84 obj$gr() #>          [,1]      [,2]     [,3]      [,4]     [,5]      [,6]     [,7] #> [1,] 573.7198 -2467.274 95.35893 -12045.97 55.92507 -807.9504 134.0732 #>           [,8] #> [1,] -181.2148 opt = nlminb(obj$par, obj$fn, obj$gr) # optimization opt$par #>      logmu      logmu   logsigma   logsigma   logkappa   logkappa        eta  #> -1.1916144  0.9182131 -1.5995349  0.3999258 -2.2872716  0.4019563 -1.6621910  #>        eta  #> -1.5735921 opt$objective #> [1] 27248.59 mod = obj$report() # runs the reporting from the negative log-likelihood once (delta = mod$delta) #>       S1       S2  #> 0.481525 0.518475 (Gamma = mod$Gamma) #>           S1        S2 #> S1 0.8282951 0.1717049 #> S2 0.1594681 0.8405319 (mu = mod$mu) #> [1] 0.3037305 2.5048106 (sigma = mod$sigma) #> [1] 0.2019904 1.4917139 (kappa = mod$kappa) #> [1] 0.1015431 1.4947460 # manually mod$states = viterbi(mod$delta, mod$Gamma, mod$allprobs)  # or simpler mod$states = viterbi(mod = mod)  # defining color vector color = c(\"orange\", \"deepskyblue\")  plot(trex$step[1:200], type = \"h\", xlab = \"time\", ylab = \"step length\",       col = color[mod$states[1:200]], bty = \"n\") legend(\"topright\", col = color, lwd = 1, legend = c(\"state 1\", \"state 2\"), bty = \"n\") oldpar = par(mfrow = c(1,2)) hist(trex$step, prob = TRUE, breaks = 40,       bor = \"white\", main = \"\", xlab = \"step length\") for(j in 1:2) curve(delta[j] * dgamma2(x, mu[j], sigma[j]),                      lwd = 2, add = T, col = color[j]) curve(delta[1]*dgamma2(x, mu[1], sigma[1]) + delta[2]*dgamma2(x, mu[2], sigma[2]),        lwd = 2, lty = 2, add = T) legend(\"top\", lwd = 2, col = color, legend = c(\"state 1\", \"state 2\"), bty = \"n\")  hist(trex$angle, prob = TRUE, breaks = 40,       bor = \"white\", main = \"\", xlab = \"turning angle\") for(j in 1:2) curve(delta[j] * dvm(x, 0, kappa[j]),                      lwd = 2, add = T, col = color[j]) curve(delta[1]*dvm(x, 0, kappa[1]) + delta[2]*dvm(x, 0, kappa[2]),        lwd = 2, lty = 2, add = T) par(oldpar) # resetting to default sdr = sdreport(obj) summary(sdr) #>            Estimate  Std. Error #> logmu    -1.1916144 0.011067932 #> logmu     0.9182131 0.008875692 #> logsigma -1.5995349 0.016232361 #> logsigma  0.3999258 0.013272894 #> logkappa -2.2872716 0.207126331 #> logkappa  0.4019563 0.019299344 #> eta      -1.6621910 0.041754277 #> eta      -1.5735921 0.040795512 #> mu        0.3037305 0.003361669 #> mu        2.5048106 0.022231928 #> sigma     0.2019904 0.003278782 #> sigma     1.4917139 0.019799361 #> kappa     0.1015431 0.021032256 #> kappa     1.4947460 0.028847617 # estimated parameter in list format as.list(sdr, \"Estimate\") # parameter standard errors in list format as.list(sdr, \"Std\") # adreported parameters as list as.list(sdr, \"Estimate\", report = TRUE) # their standard errors as.list(sdr, \"Std\", report = TRUE) pres_step = pseudo_res(trex$step, \"gamma2\", list(mean = mu, sd = sigma), mod = mod) plot(pres_step, hist = TRUE) pres_angle = pseudo_res(trex$angle, \"vm\", list(mu = 0, kappa = kappa), mod = mod) plot(pres_angle, hist = TRUE)"},{"path":"https://janoleko.github.io/articles/LaMa_and_RTMB.html","id":"covariate-effects","dir":"Articles","previous_headings":"","what":"Covariate effects","title":"LaMa and RTMB","text":"can now generalise previous model include covariate effects. example, might interested T-rex’s behaviour varies time day. Hence, add diel variation state process. example, can model transition probabilities function time day using trigonometric basis expansion ensure diurnal continuity. transition probabilities given  \\text{logit}(\\gamma_{ij}^{(t)}) = \\beta_0^{(ij)} + \\beta_1^{(ij)} \\sin \\bigl(\\frac{2 \\pi t}{24}\\bigr) + \\beta_2^{(ij)} \\cos \\bigl(\\frac{2 \\pi t}{24}\\bigr) + \\beta_3^{(ij)} \\sin \\bigl(\\frac{2 \\pi t}{12}\\bigr) + \\beta_4^{(ij)} \\cos \\bigl(\\frac{2 \\pi t}{12}\\bigr),  t time day. practically achieve , compute trigonometric basis design matrix Z corresponding predictor add time day dat list indexing inside likelihood function. LaMa function cosinor() conveniently. can either call directly build design matrix, use formula passed make_matrices(). latter preferable dealing complicated models. Note first option include intercept column, second . used tpm_g() matter automatically checks intercept column included. also need change parameter list par include regression parameters time day. regression parameters state process typically form N (N-1) \\times p+1 matrix, N number states p number regressors – format also expected tpm_g() computes array transition matrices based design parameter matrix. Another lovely convenience RTMB allows , parameter list, can matrices, making reshaping vectors matrices inside likelihood function unnessesary. can now define general likelihood function main difference use tpm_g() instead tpm() inclusion time day transition matrix calculation. leads us using stationary_p() instead stationary() calculate initial distribuion forward_g() instead forward() calculate log-likelihood. done , model fit essentially : can look reported results. case, simplicity get standard errors Gamma delta method , general, advisable.","code":"Z = cosinor(1:24, period = c(24, 12))  modmat = make_matrices(~ cosinor(tod, period = c(24, 12)),                         data = data.frame(tod = 1:24)) Z = modmat$Z  # only compute the 24 unique values and index later for entire time series dat$Z = Z # adding design matrix to dat dat$tod = trex$tod # adding time of day to dat for indexing par = list(logmu = log(c(0.3, 1)),             logsigma = log(c(0.2, 0.7)),            logkappa = log(c(0.2, 0.7)),            beta = matrix(c(rep(-2, 2),                             rep(0, 2*4)), nrow = 2)) # 2 times 4+1 matrix # replacing eta with regression parameter matrix, initializing slopes at zero nll2 = function(par) {   getAll(par, dat) # makes everything contained available without $   Gamma = tpm_g(Z, beta) # covariate-dependent tpms (in this case only 24 unique)   # tpm_g() automatically checks if intercept column is included   ADREPORT(Gamma) # adreporting   Delta = stationary_p(Gamma) # all periodically stationary distributions   ADREPORT(Delta)   delta = Delta[tod[1],] # initial periodically stationary distribution   # exponentiating because all parameters strictly positive   mu = exp(logmu); REPORT(mu)   sigma = exp(logsigma); REPORT(sigma)   kappa = exp(logkappa); REPORT(kappa)   # calculating all state-dependent densities   allprobs = matrix(1, nrow = length(step), ncol = N)   ind = which(!is.na(step) & !is.na(angle)) # only for non-NA obs.   for(j in 1:N){     allprobs[ind,j] = dgamma2(step[ind],mu[j],sigma[j])*dvm(angle[ind],0,kappa[j])   }   -forward_g(delta, Gamma[,,tod], allprobs) # indexing 24 unique tpms by tod in data } obj2 = MakeADFun(nll2, par, silent = TRUE) # creating the objective function opt2 = nlminb(obj2$par, obj2$fn, obj2$gr) # optimisation mod2 = obj2$report()  sdr = sdreport(obj2) Gamma = as.list(sdr, \"Estimate\", report = TRUE)$Gamma Gammasd = as.list(sdr, \"Std\", report = TRUE)$Gamma  Delta = as.list(sdr, \"Estimate\", report = TRUE)$Delta Deltasd = as.list(sdr, \"Std\", report = TRUE)$Delta  tod_seq = seq(0, 24, length = 200) # sequence for plotting Z_pred = trigBasisExp(tod_seq, degree = 2) # design matrix for prediction  Gamma_plot = tpm_g(Z_pred, mod2$beta) # interpolating transition probs  plot(tod_seq, Gamma_plot[1,2,], type = \"l\", lwd = 2, ylim = c(0,1),      xlab = \"time of day\", ylab = \"transition probability\", bty = \"n\") segments(x0 = 1:24, y0 = Gamma[1,2,]-1.96*Gammasd[1,2,],           y1 = Gamma[1,2,]+1.96*Gammasd[1,2,]) segments(x0 = 1:24, y0 = Gamma[2,1,]-1.96*Gammasd[2,1,],           y1 = Gamma[2,1,]+1.96*Gammasd[2,1,]) lines(tod_seq, Gamma_plot[2,1,], lwd = 2, lty = 3) legend(\"topleft\", lwd = 2, lty = c(1,3), bty = \"n\",        legend = c(expression(gamma[12]^(t)), expression(gamma[21]^(t)))) plot(Delta[,2], type = \"b\", lwd = 2, xlab = \"time of day\", ylab = \"Pr(active)\",       col = \"deepskyblue\", bty = \"n\", xaxt = \"n\") segments(x0 = 1:24, y0 = Delta[,2]-1.96*Deltasd[,2], lwd = 2,          y1 = Delta[,2]+1.96*Deltasd[,2], col = \"deepskyblue\") axis(1, at = seq(0,24,by=4), labels = seq(0,24,by=4))"},{"path":[]},{"path":"https://janoleko.github.io/articles/LaMa_and_RTMB.html","id":"tips","dir":"Articles","previous_headings":"RTMB tips and issues","what":"Tips","title":"LaMa and RTMB","text":"using forward algorithm, usually good idea run: changes RTMB internally represents matrix multiplications can speed forward algorithm considerably. want use non-standard probability distributions, check-R package RTMBdist provides library AD-compatible distributions can used inside likelihood functions.","code":"RTMB::TapeConfig(matmul = \"plain\")"},{"path":"https://janoleko.github.io/articles/LaMa_and_RTMB.html","id":"common-issues","dir":"Articles","previous_headings":"RTMB tips and issues","what":"Common issues","title":"LaMa and RTMB","text":"problems RTMB one keep mind. can bit annoying, opinion benefits automatic differentiation far outweigh drawbacks. list main ones encountered , please tell encounter , can added. typical issue RTMB operators might need overloaded allow automatic differentiation done default. typical model setups LaMa functions , go individualistic route get error like might overload operator . put first line likelihood function. error still prevails also add hopefully fix error. Another common problem occurs initiating objects NA values trying fill numeric values. NA logical screws automatic differentiation due mismatching types. avoid , always initiate numeric NaN values. example, don’t rather avoid error. create array fill something parameter-dependent, also : makes sure X AD object beginning classes compatible. Wrapping things AD() generally good idea fix error, introduce considerable overhead necessary. Importantly, use max/ min statements parameter differentiable. , RTMB fail probably produce helpful error message. problem results RTMB building tape (computational graph) function initial parameter value. statements, resulting gradient different one different parameter value. Often, can remedy behaviour exploiting fact abs() differentiable (code). example, can create differentiable max alternative: might able solve problems finding clever alternative. statement involve parameter, typically fine change optimisation. Furthermore, unfortunate side effects R’s ‘byte compiler’ (enabled default R). encounter error matching previous ones, try disabling byte compiler see error resolved. minor things: ’re used expm::expm() won’t work AD. Use Matrix::expm() instead. CircStats::dvm() also isn’t compatible AD. Use LaMa::dvm() instead. standard distributions available RTMB. need non-standard one, try implementing density function using plain R code. RTMB also provides AD versions many building-block functions (like Gamma Bessel function) might help . information RTMB, check documentation TMB users Google group. Continue reading Penalised splines.","code":"stop(\"Invalid argument to 'advector' (lost class attribute?)\") \"[<-\" <- ADoverload(\"[<-\") \"c\" <- ADoverload(\"c\") \"diag<-\" <- ADoverload(\"diag<-\") X = array(dim = c(1,2,3)) # which is the same as X = array(NA, dim = c(1,2,3)) X = array(NaN, dim = c(1,2,3)) # or X = array(0, dim = c(1,2,3)) X <- AD(array(...)) max2 = function(x,y){   (x + y + abs(x - y)) / 2 } compiler::enableJIT(0) #> [1] 3"},{"path":[]},{"path":"https://janoleko.github.io/articles/Longitudinal_data.html","id":"generating-data","dir":"Articles","previous_headings":"Complete pooling","what":"Generating data","title":"Longitudinal data","text":"generate K separate tracks, exact model:","code":"# loading the package library(LaMa) #> Loading required package: RTMB # parameters are shared across individuals mu = c(15, 60) # state-dependent means sigma = c(10, 40) # state-dependent standard deviations Gamma = matrix(c(0.95, 0.05, 0.15, 0.85), nrow = 2, byrow = TRUE) # t.p.m. delta = stationary(Gamma) # stationary distribution  # simulation of all tracks set.seed(123) K = 200 # number of individuals, for example different animals n = 50 # observations per animal only (but many animals)  s = x = rep(NA, n*K) for(k in 1:K){   sk = xk = rep(NA, n)   sk[1] = sample(1:2, 1, prob = delta)   xk[1] = rnorm(1, mu[sk[1]], sigma[sk[1]])   for(t in 2:n){     sk[t] = sample(1:2, 1, prob = Gamma[sk[t-1],])      xk[t] = rnorm(1, mu[sk[t]], sigma[sk[t]])   }   s[(k-1)*n + 1:n] = sk   x[(k-1)*n + 1:n] = xk }  trackID = rep(1:K, each = n)"},{"path":"https://janoleko.github.io/articles/Longitudinal_data.html","id":"writing-the-negative-log-likelihood-function","dir":"Articles","previous_headings":"Complete pooling","what":"Writing the negative log-likelihood function","title":"Longitudinal data","text":"calculate joint log-likelihood independent tracks, slightly modify standard negative log-likelihood function adding additional argument trackID. forward() now calculates sum indivual likelihood contributions, starting respective initial distribution (pool ).","code":"# fast version using trackInd in forward() nll_pool = function(par, x, trackID){   Gamma = tpm(par[1:2])   delta = stationary(Gamma)   mu = par[3:4]   sigma = exp(par[5:6])   allprobs = matrix(1, length(x), 2)   for(j in 1:2) allprobs[,j] = dnorm(x, mu[j], sigma[j])      # here we add trackInd as an argument to forward()   -forward(delta, Gamma, allprobs, trackID) }  # slow alternative looping over individuals in R nll_pool_slow = function(par, x, K){   n = length(x) / K   Gamma = tpm(par[1:2])   delta = stationary(Gamma)   mu = par[3:4]   sigma = exp(par[5:6])   allprobs = matrix(1, length(x), 2)   for(j in 1:2) allprobs[,j] = dnorm(x, mu[j], sigma[j])      # here we just loop over individuals in R   l = 0   for(k in 1:K){     l = l + forward(delta, Gamma, allprobs[(k-1)*n + 1:n,])   }   -l }"},{"path":"https://janoleko.github.io/articles/Longitudinal_data.html","id":"estimating-the-model","dir":"Articles","previous_headings":"Complete pooling","what":"Estimating the model","title":"Longitudinal data","text":"Now estimate model complete pooling. compare fast version using forward() trackID slow version also using forward() looping individuals R. example, looping individuals R already leads five times longer estimation time, can much severe complicated models.","code":"# initial parameter vector par = c(logitgamma = c(-1,-1), # off-diagonals of Gamma (on logit scale)         mu = c(15, 60), # state-dependent means         logsigma = c(log(10),log(40))) # state-dependent sds  # fast version: system.time(   mod <- nlm(nll_pool, par, x = x, trackID = trackID) ) #>    user  system elapsed  #>   0.359   0.014   0.373  # slow version system.time(   mod <- nlm(nll_pool_slow, par, x = x, K = K) ) #>    user  system elapsed  #>   2.423   0.036   2.460"},{"path":"https://janoleko.github.io/articles/Longitudinal_data.html","id":"partial-pooling","dir":"Articles","previous_headings":"","what":"Partial pooling","title":"Longitudinal data","text":"parameters model individual-specific, rest shared, speak partial pooling. demonstrate 5 individuals transition probability matrices. estimate separate transition probability matrix individual, opt parsimonious approach, transition probabilities depend external, individual-specific covariate. estimate effect covariate transition probabilities.","code":""},{"path":"https://janoleko.github.io/articles/Longitudinal_data.html","id":"generating-data-1","dir":"Articles","previous_headings":"Partial pooling","what":"Generating data","title":"Longitudinal data","text":"","code":"K = 5 # number of individuals, for example different animals  # state-dependent parameters are shared across individuals mu = c(15, 60) sigma = c(10, 40)  # but we define a tpm for each individual depending on covariates set.seed(123) z = rnorm(K) # covariate (e.g. age) beta = matrix(c(-2,-2, 1, -1), nrow = 2) # we calculate 5 tpms depending on individual-specific covariates: Gamma = tpm_g(z, beta) # each individual starts in its stationary distribution: Delta = matrix(NA, K, 2) for(k in 1:K){ Delta[k,] = stationary(Gamma[,,k]) }  # simulation of all tracks set.seed(123) n = 200 # observations per animal only (but many animals) s = x = rep(NA, n*K) for(k in 1:K){   sk = xk = rep(NA, n)   sk[1] = sample(1:2, 1, prob = Delta[k, ])   xk[1] = rnorm(1, mu[sk[1]], sigma[sk[1]])   for(t in 2:n){     sk[t] = sample(1:2, 1, prob = Gamma[sk[t-1],,k])      xk[t] = rnorm(1, mu[sk[t]], sigma[sk[t]])   }   s[(k-1)*n + 1:n] = sk   x[(k-1)*n + 1:n] = xk }"},{"path":"https://janoleko.github.io/articles/Longitudinal_data.html","id":"writing-the-negative-log-likelihood-function-1","dir":"Articles","previous_headings":"Partial pooling","what":"Writing the negative log-likelihood function","title":"Longitudinal data","text":"Now write corresponding negative log-likehood function incorporates structure. track fixed t.p.m., can assume stationarity compute stationary initial distribution track respectively.","code":"# fast version using trackInd in forward() nll_partial = function(par, x, z, trackID){   # individual-specific tpms   beta = matrix(par[1:4], nrow = 2)   Gamma = tpm_g(z, beta)   Delta = t(sapply(1:k, function(k) stationary(Gamma[,,k])))   mu = par[5:6]   sigma = exp(par[7:8])   allprobs = matrix(1, length(x), 2)   for(j in 1:2) allprobs[,j] = dnorm(x, mu[j], sigma[j])   # just handing a Delta matrix and Gamma array for all individuals to forward()   -forward(Delta, Gamma, allprobs, trackID) }"},{"path":"https://janoleko.github.io/articles/Longitudinal_data.html","id":"estimating-the-model-1","dir":"Articles","previous_headings":"Partial pooling","what":"Estimating the model","title":"Longitudinal data","text":"","code":"# again defining all the indices where a new track begins trackID = rep(1:K, each = n)  # initial parameter vector par = c(beta = c(-2, -2, 0, 0), # beta         mu = c(15, 60), # state-dependent means         log(10), log(40)) # state-dependent sds  system.time(   mod_partial <- nlm(nll_partial, par, x = x, z = z, trackID = trackID) ) #>    user  system elapsed  #>   0.406   0.008   0.414"},{"path":"https://janoleko.github.io/articles/MMMPPs.html","id":"example-1-markov-modulated-poisson-processes","dir":"Articles","previous_headings":"","what":"Example 1: Markov-modulated Poisson processes","title":"Markov-modulated (marked) Poisson processes","text":"","code":"# loading the package library(LaMa) #> Loading required package: RTMB"},{"path":"https://janoleko.github.io/articles/MMMPPs.html","id":"setting-parameters","dir":"Articles","previous_headings":"Example 1: Markov-modulated Poisson processes","what":"Setting parameters","title":"Markov-modulated (marked) Poisson processes","text":"choose considerably higher rate shorter stays underlying Markov chain state 2, .e. state 2 bursty.","code":"# state-dependent rates lambda = c(2, 15) # generator matrix of the underlying Markov chain Q = matrix(c(-0.5,0.5,2,-2), nrow = 2, byrow = TRUE)"},{"path":"https://janoleko.github.io/articles/MMMPPs.html","id":"simulating-an-mmpp","dir":"Articles","previous_headings":"Example 1: Markov-modulated Poisson processes","what":"Simulating an MMPP","title":"Markov-modulated (marked) Poisson processes","text":"Let’s visualise simulated MMPP makes MMPP special compared regular Poisson point process burstiness Markov chain second state.","code":"set.seed(123)  k = 200 # number of state switches trans_times = s = rep(NA, k) # time points where the chain transitions s[1] = sample(1:2, 1) # initial distribuion c(0.5, 0.5) # exponentially distributed waiting times trans_times[1] = rexp(1, -Q[s[1],s[1]]) # in a fixed interval, the number of arrivals is Pois(lambda * interval_length) n_arrivals = rpois(1, lambda[s[1]]*trans_times[1])  # arrival times within fixed interval are uniformly distributed arrival_times = runif(n_arrivals, 0, trans_times[1]) for(t in 2:k){   s[t] = c(1,2)[-s[t-1]] # for 2-states, always a state swith when transitioning   # exponentially distributed waiting times   trans_times[t] = trans_times[t-1] + rexp(1, -Q[s[t], s[t]])   # in a fixed interval, the number of arrivals is Pois(lambda * interval_length)   n_arrivals = rpois(1, lambda[s[t]]*(trans_times[t]-trans_times[t-1]))   # arrival times within fixed interval are uniformly distributed   arrival_times = c(arrival_times,                      runif(n_arrivals, trans_times[t-1], trans_times[t])) } arrival_times = sort(arrival_times) n = length(arrival_times) color = c(\"orange\", \"deepskyblue\") plot(arrival_times[1:100], rep(0.5,100), type = \"h\", bty = \"n\", ylim = c(0,1),       yaxt = \"n\", xlab = \"arrival times\", ylab = \"\") segments(x0 = c(0,trans_times[1:98]), x1 = trans_times[1:99],           y0 = rep(0,100), y1 = rep(0,100), col = color[s[1:99]], lwd = 4) legend(\"top\", lwd = 2, col = color, legend = c(\"state 1\", \"state 2\"), box.lwd = 0)"},{"path":"https://janoleko.github.io/articles/MMMPPs.html","id":"writing-the-negative-log-likelihood-function","dir":"Articles","previous_headings":"Example 1: Markov-modulated Poisson processes","what":"Writing the negative log-likelihood function","title":"Markov-modulated (marked) Poisson processes","text":"likelihood stationary MMPP waiting times x_1, \\dots, x_n (Meier-Hellstern (1987), Langrock, Borchers, Skaug (2013))  L(\\theta) = \\pi \\Bigl(\\prod_{=1}^n \\exp\\bigl((Q-\\Lambda)x_i\\bigr)\\Lambda \\Bigr)1,  Q generator matrix continuous-time Markov chain, \\Lambda diagonal matrix state-dependent Poisson intensities, \\pi stationary distribution continuous-time Markov chain, 1 column vector ones. details continuous-time Markov chains, see vignette continuous-time HMMs also Dobrow (2016). can easily calculate log expression using standard implementation general forward algorithm forward_g() choosing first matrix state-dependent densities identity (.e.) first row allprobs matrix one matrices state-dependent density matrices \\Lambda.","code":"nll = function(par, timediff, N){   lambda = exp(par[1:N]) # state specific rates   Q = generator(par[N+1:(N*(N-1))])   Pi = stationary_cont(Q)   Qube = tpm_cont(Q - diag(lambda), timediff) # exp((Q-Lambda) * dt)   allprobs = matrix(lambda, nrow = length(timediff + 1), ncol = N, byrow = T)   allprobs[1,] = 1   -forward_g(Pi, Qube, allprobs) }"},{"path":"https://janoleko.github.io/articles/MMMPPs.html","id":"fitting-an-mmpp-to-the-data","dir":"Articles","previous_headings":"Example 1: Markov-modulated Poisson processes","what":"Fitting an MMPP to the data","title":"Markov-modulated (marked) Poisson processes","text":"","code":"par = log(c(2, 15, # lambda             2, 0.5)) # off-diagonals of Q  timediff = diff(arrival_times)  system.time(   mod <- nlm(nll, par, timediff = timediff, N = 2, stepmax = 10) ) #>    user  system elapsed  #>   0.269   0.269   0.274 # we often need the stepmax, as the matrix exponential can be numerically unstable"},{"path":"https://janoleko.github.io/articles/MMMPPs.html","id":"results","dir":"Articles","previous_headings":"Example 1: Markov-modulated Poisson processes","what":"Results","title":"Markov-modulated (marked) Poisson processes","text":"","code":"(lambda = exp(mod$estimate[1:2])) #> [1]  1.949689 15.083121 (Q = generator(mod$estimate[3:4])) #>            S1         S2 #> S1 -0.4003955  0.4003955 #> S2  1.8998848 -1.8998848 (Pi = stationary_cont(Q)) #>        S1        S2  #> 0.8259362 0.1740638"},{"path":"https://janoleko.github.io/articles/MMMPPs.html","id":"example-2-markov-modulated-marked-poisson-processes","dir":"Articles","previous_headings":"","what":"Example 2: Markov-modulated marked Poisson processes","title":"Markov-modulated (marked) Poisson processes","text":"processes can also carry additional information, called marks, every arrival time also observe realisation different random variable depends underlying states continuous-time Markov chain. example patient arrivals hospital observe biomarker every arrival time. Information underlying health status present arrival times (sick patients visit often) biomarkers.","code":"# state-dependent rates lambda = c(1, 5, 20) # generator matrix of the underlying Markov chain Q = matrix(c(-0.5, 0.3, 0.2,              0.7, -1, 0.3,              1, 1, -2), nrow = 3, byrow = TRUE) # parmeters for distributions of state-dependent marks # (here normally distributed) mu = c(-5, 0, 5) sigma = c(2, 1, 2)  color = c(\"orange\", \"deepskyblue\", \"seagreen2\") curve(dnorm(x, 0, 1), xlim = c(-10,10), bty = \"n\", lwd = 2, col = color[2],        n = 200, ylab = \"density\", xlab = \"mark\") curve(dnorm(x, -5, 2), add = TRUE, lwd = 2, col = color[1], n = 200) curve(dnorm(x, 5, 2), add = TRUE, lwd = 2, col = color[3], n = 200)"},{"path":"https://janoleko.github.io/articles/MMMPPs.html","id":"simulating-an-mmmpp","dir":"Articles","previous_headings":"Example 2: Markov-modulated marked Poisson processes","what":"Simulating an MMMPP","title":"Markov-modulated (marked) Poisson processes","text":"now show simulate MMMPP additionally generalise two hidden states. Let’s visualise simulated MMMPP","code":"set.seed(123) k = 200 # number of state switches trans_times = s = rep(NA, k) # time points where the chain transitions s[1] = sample(1:3, 1) # initial distribuion uniformly # exponentially distributed waiting times trans_times[1] = rexp(1, -Q[s[1],s[1]]) # in a fixed interval, the number of arrivals is Pois(lambda * interval_length) n_arrivals = rpois(1, lambda[s[1]]*trans_times[1])  # arrival times within fixed interval are uniformly distributed arrival_times = runif(n_arrivals, 0, trans_times[1]) # marks are iid in interval, given underlying state marks = rnorm(n_arrivals, mu[s[1]], sigma[s[1]])  for(t in 2:k){   # off-diagonal elements of the s[t-1] row of Q divided by the diagonal element   # give the probabilites of the next state   s[t] = sample(c(1:3)[-s[t-1]], 1, prob = Q[s[t-1],-s[t-1]]/-Q[s[t-1],s[t-1]])   # exponentially distributed waiting times   trans_times[t] = trans_times[t-1] + rexp(1, -Q[s[t],s[t]])   # in a fixed interval, the number of arrivals is Pois(lambda * interval_length)   n_arrivals = rpois(1, lambda[s[t]]*(trans_times[t]-trans_times[t-1]))   # arrival times within fixed interval are uniformly distributed   arrival_times = c(arrival_times,                      runif(n_arrivals, trans_times[t-1], trans_times[t]))   # marks are iid in interval, given underlying state   marks = c(marks, rnorm(n_arrivals, mu[s[t]], sigma[s[t]])) } arrival_times = sort(arrival_times) n = length(arrival_times) plot(arrival_times[1:100], marks[1:100], pch = 16, bty = \"n\",       ylim = c(-9,9), xlab = \"arrival times\", ylab = \"marks\") segments(x0 = c(0,trans_times[1:98]), x1 = trans_times[1:99],           y0 = rep(-9,100), y1 = rep(-9,100), col = color[s[1:99]], lwd = 4) legend(\"topright\", lwd = 2, col = color,         legend = c(\"state 1\", \"state 2\", \"state 3\"), box.lwd = 0)"},{"path":"https://janoleko.github.io/articles/MMMPPs.html","id":"writing-the-negative-log-likelihood-function-1","dir":"Articles","previous_headings":"Example 2: Markov-modulated marked Poisson processes","what":"Writing the negative log-likelihood function","title":"Markov-modulated (marked) Poisson processes","text":"likelihood stationary MMMPP waiting times x_1, \\dots, x_n marks y_0, y_1, \\dotsc, y_n changes slightly MMPP likelihood, include matrix state-specific densities (Lu (2012), Mews et al. (2023)):  L(\\theta) = \\pi P(y_0) \\Bigl(\\prod_{=1}^n \\exp\\bigl((Q-\\Lambda) x_i\\bigr)\\Lambda P(y_i) \\Bigr)1,  Q, \\Lambda \\pi P(y_i) diagonal matrix state-dependent densites observation time t_i. can easily calculate log expression using standard implementation general forward algorithm forward_g() first calculating allprobs matrix state-dependent densities marks (usual HMMs) multiplying row except first one element-wise state-dependent rates.","code":"nllMark = function(par, y, timediff, N){   lambda = exp(par[1:N]) # state specific rates   mu = par[N+1:N]   sigma = exp(par[2*N+1:N])   Q = generator(par[3*N+1:(N*(N-1))])   Pi = stationary_cont(Q)   Qube = tpm_cont(Q-diag(lambda), timediff) # exp((Q-Lambda)*deltat)   allprobs = matrix(1, length(y), N)   for(j in 1:N) allprobs[,j] = dnorm(y, mu[j], sigma[j])   allprobs[-1,] = allprobs[-1,] * matrix(lambda, length(y) - 1, N, byrow = T)   -forward_g(Pi, Qube, allprobs) }"},{"path":"https://janoleko.github.io/articles/MMMPPs.html","id":"fitting-an-mmmpp-to-the-data","dir":"Articles","previous_headings":"Example 2: Markov-modulated marked Poisson processes","what":"Fitting an MMMPP to the data","title":"Markov-modulated (marked) Poisson processes","text":"","code":"par = c(loglambda = log(c(1, 5, 20)), # lambda         mu = c(-5, 0, 5), # mu         logsigma = log(c(2, 1, 2)), # sigma         qs = log(c(0.7, 1, 0.3, 1, 0.2, 0.3))) # Q timediff = diff(arrival_times)  system.time(   mod2 <- nlm(nllMark, par, y = marks, timediff = timediff, N = 3, stepmax = 5) ) #>    user  system elapsed  #>   2.385   3.392   1.934"},{"path":"https://janoleko.github.io/articles/MMMPPs.html","id":"results-1","dir":"Articles","previous_headings":"Example 2: Markov-modulated marked Poisson processes","what":"Results","title":"Markov-modulated (marked) Poisson processes","text":"","code":"N = 3 (lambda = exp(mod2$estimate[1:N])) #> [1]  0.9646715  4.8640550 19.5008965 (mu = mod2$estimate[N+1:N]) #> [1] -5.18540508 -0.09097055  4.80538783 (sigma = exp(mod2$estimate[2*N+1:N])) #> [1] 1.7931062 0.9644485 2.0093266 (Q = generator(mod2$estimate[3*N+1:(N*(N-1))])) #>            S1         S2         S3 #> S1 -0.5909290  0.2788642  0.3120648 #> S2  0.9258939 -1.1798377  0.2539439 #> S3  1.1933693  1.2097188 -2.4030882 (Pi = stationary_cont(Q)) #>        S1        S2        S3  #> 0.6296990 0.2609524 0.1093485"},{"path":[]},{"path":"https://janoleko.github.io/articles/Penalised_splines.html","id":"smooth-transition-probabilites","dir":"Articles","previous_headings":"","what":"Smooth transition probabilites","title":"Penalised splines","text":"start investigating 2-state HMM trex data set, containing hourly step lengths turning angles Tyrannosaurus rex living 66 million years ago. transition probabilities modelled smooth functions time day using cyclic P-Splines. relationship can summarised \\text{logit}(\\gamma_{ij}^{(t)}) = \\beta_0^{(ij)} + s_{ij}(t),  s_{ij}(t) smooth periodic function time day. model T-rex’s step lengths turning angles using state-dependent gamma von Mises distributions. ease model specification, LaMa provides function make_matrices() creates design penalty matrices regression settings based R package mgcv. user needs specify right side formula using mgcv syntax provide data. , use s(tod, = \"cp\") create matrices cyclic P-splines (cp). results cubic B-Spline basis, wrapped boundary support (0 24). append resulting matrices dat list. can now specify penalised negative log-likelihood function. transition probability matrix can computed regular way using tpm_g(). last line need add curvature penalty based S, can conveniently using penalty(). also append lambda vector dat list initial penalty strength parameter vector. case length two coefficient matrix two rows. wondering lambda added par list, penalised likelihood estimation, hyperparameter, hence true parameter sense parameters par. One , point, just use penalised likelihood function penalised ML fixed penalty strength lambda. model fit automatic smoothness selection can conducted using qreml() function contained LaMa. quasi restricted maximum likelihood algorithm finds good penalty strength parameter lambda treating spline coefficients random effects. hood, qreml() also constructs AD function RTMB uses qREML algorithm (Koslik 2024) fit model. tell qreml() function parameters spline coefficients providing name corresponding list element par. rules follow using qreml(): likelihood function needs RTMB-compatible, .e. structure likelihood functions vignette LaMa RTMB. importantly, function parameter list . penalty strength vector lambda needs length correspond total number spline coefficient vectors used. case, number rows betaSpline, additionally different spline coefficient (different name) parameter list, possibly different length different penalty matrix, needed elements lambda. penalty() function can called likelihood. several spline coefficients penalised, penalty() expects list coefficient matrices vectors list penalty matrices. shown third example vignette. default, qreml() assumes penalisation hyperparameter dat object called lambda. can use different name dat (course changing pnll well), want use different name penalisation hyperparameter, specify character string qreml() call using psname argument. mod object now list contains everything reported likelihood function, also RTMB object created process. fitting model, can use predict() modmat object created earlier build new interpolating design matrix using exact basis expansion specified . allows us plot estimated transition probabilities smooth function time day.","code":"library(LaMa) #> Loading required package: RTMB  head(trex) #>   tod      step     angle state #> 1   9 0.3252437        NA     1 #> 2  10 0.2458265  2.234562     1 #> 3  11 0.2173252 -2.262418     1 #> 4  12 0.5114665 -2.958732     1 #> 5  13 0.3828494  1.811840     1 #> 6  14 0.4220099  1.834668     1 modmat = make_matrices(~ s(tod, bs = \"cp\"), # formula                        data = data.frame(tod = 1:24), # data                        knots = list(tod = c(0, 24))) # where to wrap the cyclic basis Z = modmat$Z # spline design matrix S = modmat$S # penalty matrix pnll = function(par) {   getAll(par, dat)   # cbinding intercept and spline coefs, because intercept is not penalised   Gamma = tpm_g(Z, cbind(beta0, betaSpline))   # computing all periodically stationary distributions for easy access later   Delta = stationary_p(Gamma); REPORT(Delta)   # parameter transformations   mu = exp(logmu); REPORT(mu)   sigma = exp(logsigma); REPORT(sigma)   kappa = exp(logkappa); REPORT(kappa)   # calculating all state-dependent densities   allprobs = matrix(1, nrow = length(step), ncol = N)   ind = which(!is.na(step) & !is.na(angle)) # only for non-NA obs.   for(j in 1:N){     allprobs[ind,j] = dgamma2(step[ind],mu[j],sigma[j]) * dvm(angle[ind],0,kappa[j])   }   -forward_g(Delta[tod[1],], Gamma[,,tod], allprobs) + # regular forward algorithm     penalty(betaSpline, S, lambda) # this does all the penalisation work } par = list(logmu = log(c(0.3, 2.5)), # state-dependent mean step            logsigma = log(c(0.2, 1.5)), # state-dependent sd step            logkappa = log(c(0.2, 1.5)), # state-dependent concentration angle            beta0 = c(-2, 2), # state process intercepts            betaSpline = matrix(rep(0, 2*(ncol(Z)-1)), nrow = 2)) # spline coefs  dat = list(step = trex$step, # observed steps            angle = trex$angle, # observed angle            N = 2, # number of states            tod = trex$tod, # time of day (used for indexing)            Z = Z, # spline design matrix            S = S, # penalty matrix            lambda = rep(100, 2)) # initial penalty strength system.time(   mod1 <- qreml(pnll, par, dat, random = \"betaSpline\") ) #> Creating AD function #> Initialising with lambda: 100 100  #> outer 1 - lambda: 32.051 31.828  #> outer 2 - lambda: 10.555 10.748  #> outer 3 - lambda: 3.659 3.977  #> outer 4 - lambda: 1.41 1.589  #> outer 5 - lambda: 0.669 0.693  #> outer 6 - lambda: 0.426 0.347  #> outer 7 - lambda: 0.346 0.21  #> outer 8 - lambda: 0.32 0.153  #> outer 9 - lambda: 0.312 0.129  #> outer 10 - lambda: 0.309 0.119  #> outer 11 - lambda: 0.308 0.114  #> outer 12 - lambda: 0.308 0.112  #> outer 13 - lambda: 0.308 0.112  #> Converged #> Final model fit with lambda: 0.308 0.112 #>    user  system elapsed  #>   9.044   3.805   8.576 Delta = mod1$Delta  tod_seq = seq(0, 24, length = 100) Z_p = predict(modmat, data.frame(tod = tod_seq))  Gamma_plot = tpm_g(Z_p, mod1$beta) # interpolating transition probs  plot(tod_seq, Gamma_plot[1,2,], type = \"l\", lwd = 2, ylim = c(0,1),      xlab = \"time of day\", ylab = \"transition probability\", bty = \"n\") lines(tod_seq, Gamma_plot[2,1,], lwd = 2, lty = 3) legend(\"topleft\", lwd = 2, lty = c(1,3), bty = \"n\",        legend = c(expression(gamma[12]^(t)), expression(gamma[21]^(t)))) plot(Delta[,2], type = \"b\", lwd = 2, pch = 16, xlab = \"time of day\", ylab = \"Pr(active)\",       col = \"deepskyblue\", bty = \"n\", xaxt = \"n\") axis(1, at = seq(0,24,by=4), labels = seq(0,24,by=4))"},{"path":"https://janoleko.github.io/articles/Penalised_splines.html","id":"smooth-density-estimation","dir":"Articles","previous_headings":"","what":"Smooth density estimation","title":"Penalised splines","text":"demonstrate nonparametric estimation state-dependent densities, consider nessi data set. contains acceleration data Loch Ness Monster, specifically overall dynamic body acceleration (ODBA). ODBA strictily positive extreme values, making direct analysis difficult. Hence, analysis consider logarithm ODBA observed process.  Clearly, least three behavioural states data, start fitting simple 3-state Gaussian HMM likelihood function: fit model explained vignette LaMa RTMB.  see clear lack--fit due inflexibility Gaussian state-dependent densities. Thus, now fit model state-dependent densities based P-Splines. first step, requires us prepare design penalty matrices needed using smooth_dens_construct(). function can take multiple data streams set initial parameters (specifying initial means standard deviations) data stream. builds P-Spline design penalty matrices data stream well matrix initial spline coefficients based provided parameters. basis functions standardised integrate one, needed density estimation. , can specify penalised negative log-likelihood function. six lines middle needed P-Spline-based density estimation. coefficient matrix beta provided buildSmoothDens() one column less number basis functions, also printed calling buildSmoothDens(). last column, .e. last coefficient state, needs fixed zero identifiability using cbind(beta, 0). , transform unconstrained parameter matrix non-negative weights sum one (called alpha) state using inverse multinomial logistic link (softmax). columnns allprobs matrix computed linear combinations columns Z weights alpha. Lastly, penalise unconstrained coefficients beta (constrained alpha’s) using penalty() function. Now specify initial parameter data list fit model. case, actually don’t need add observations dat list anymore, information contained design matrix Z. fitting model, can easily visualise smooth densities using prepared prediction objects. already access reported quanitites qreml() automatically runs reporting model fitting.  P-Spline model results good fit empirical distribution. beause first state skewed distribution, second state high kurtosis third state funny right tail. P-Spline model can capture features parametric model failed .","code":"head(nessi) #>         ODBA   logODBA state #> 1 0.03775025 -3.276763     2 #> 2 0.05417830 -2.915475     2 #> 3 0.03625247 -3.317248     2 #> 4 0.01310802 -4.334531     1 #> 5 0.05402441 -2.918319     3 #> 6 0.06133794 -2.791357     3 hist(nessi$logODBA, prob = TRUE, breaks = 50, bor = \"white\",       main = \"\", xlab = \"log(ODBA)\") nll = function(par){     getAll(par, dat)     sigma = exp(logsigma) # exp because strictly positive     REPORT(mu); REPORT(sigma)     Gamma = tpm(eta) # multinomial logit link     delta = stationary(Gamma) # stationary dist of the homogeneous Markov chain     allprobs = matrix(1, length(logODBA), N)     ind = which(!is.na(logODBA))     for(j in 1:N) allprobs[ind,j] = dnorm(logODBA[ind], mu[j], sigma[j])     -forward(delta, Gamma, allprobs) } # initial parameter list par = list(mu = c(-4.5, -3.5, -2.5),            logsigma = log(rep(0.5, 3)),            eta = rep(-2, 6))  # data and hyperparameters dat = list(logODBA = nessi$logODBA, N = 3)  # creating automatically differentiable objective function obj = MakeADFun(nll, par, silent = TRUE)  # fitting the model opt = nlminb(obj$par, obj$fn, obj$gr)  # reporting to get calculated quantities mod = obj$report()  # visualising the results color = c(\"orange\", \"deepskyblue\", \"seagreen3\") hist(nessi$logODBA, prob = TRUE, breaks = 50, bor = \"white\",      main = \"\", xlab = \"log(ODBA)\") for(j in 1:3) curve(mod$delta[j] * dnorm(x, mod$mu[j], mod$sigma[j]),                      add = TRUE, col = color[j], lwd = 2, n = 500) # providing initial means and sds to initialise spline coefficients par0 = list(logODBA = list(mean = c(-4, -3.3, -2.8), sd = c(0.3, 0.2, 0.5)))  # construct the smooth density objects modmat = smooth_dens_construct(nessi[\"logODBA\"], # only one data stream here                                par = par0) #> logODBA  #> Leaving out last column of the penalty matrix, fix the last spline coefficient at zero for identifiability! #> Parameter matrix excludes the last column. Add a (fixed) zero column using 'cbind(coef, 0)' in your loss function!  # par is nested named list: top layer: each data stream # for each data stream: initial means and standard deviations for each state  # objects for model fitting Z = modmat$Z$logODBA # spline design matrix for logODBA S = modmat$S$logODBA # penalty matrix for logODBA beta = modmat$coef$logODBA # initial spline coefficients  # objects for prediction Z_p = modmat$Z_predict$logODBA # prediction design matrix xseq = modmat$xseq$logODBA # prediction sequence of logODBA values pnll = function(par){   getAll(par, dat)   # regular stationary HMM stuff   Gamma = tpm(eta)   delta = stationary(Gamma)   # smooth state-dependent densities   alpha = exp(cbind(beta, 0))   alpha = alpha / rowSums(alpha) # multinomial logit link   REPORT(alpha)   allprobs = matrix(1, nrow(Z), N)   ind = which(!is.na(Z[,1])) # only for non-NA obs.   allprobs[ind,] = Z[ind,] %*% t(alpha)   # forward algorithm + penalty   -forward(delta, Gamma, allprobs) +      penalty(beta, S, lambda) } par = list(beta = beta, # spline coefficients prepared by smooth_dens_construct()            eta = rep(-2, 6)) # initial transition matrix on logit scale  dat = list(N = 3, # number of states            Z = Z, # spline design matrix            S = S, # spline penalty matrix            lambda = rep(10, 3)) # initial penalty strength vector  # fitting the model using qREML system.time(   mod2 <- qreml(pnll, par, dat, random = \"beta\") ) #> Creating AD function #> Initialising with lambda: 10 10 10  #> outer 1 - lambda: 4.213 3.833 4.836  #> outer 2 - lambda: 2.309 1.937 3.045  #> outer 3 - lambda: 1.604 1.332 2.338  #> outer 4 - lambda: 1.305 1.127 2.028  #> outer 5 - lambda: 1.166 1.053 1.883  #> outer 6 - lambda: 1.099 1.026 1.812  #> outer 7 - lambda: 1.065 1.016 1.777  #> outer 8 - lambda: 1.048 1.012 1.76  #> outer 9 - lambda: 1.04 1.01 1.75  #> outer 10 - lambda: 1.035 1.01 1.747  #> outer 11 - lambda: 1.034 1.01 1.745  #> outer 12 - lambda: 1.033 1.01 1.745  #> outer 13 - lambda: 1.033 1.01 1.744  #> Converged #> Final model fit with lambda: 1.033 1.01 1.744 #>    user  system elapsed  #>  16.105   4.458  15.439 sDens = Z_p %*% t(mod2$alpha) # all three state-dependent densities on a grid  hist(nessi$logODBA, prob = TRUE, breaks = 50, bor = \"white\", main = \"\", xlab = \"log(ODBA)\") for(j in 1:3) lines(xseq, mod2$delta[j] * sDens[,j], col = color[j], lwd = 2) lines(xseq, colSums(mod2$delta * t(sDens)), col = \"black\", lwd = 2, lty = 2)"},{"path":"https://janoleko.github.io/articles/Penalised_splines.html","id":"markov-switching-gamlss","dir":"Articles","previous_headings":"","what":"Markov-switching GAMLSS","title":"Penalised splines","text":"Lastly, want demonstrate one can easily fit Markov-switching regression models state-dependent means potentially parameters depend covariates via smooth functions. , consider energy data set contained R package MSwM. comprises 1784 daily observations energy prices (Cents per kWh) Spain want explain using daily oil prices (Euros per barrel) also provided data. Specifically, consider 2-state MS-GAMLSS defined  \\text{price}_t \\mid \\{ S_t = \\} \\sim N \\bigl(\\mu_t^{()}, (\\sigma_t^{()})^2 \\bigr),   \\mu_t^{()} = \\beta_{0,\\mu}^{()} + s_{\\mu}^{()}(\\text{oil}_t), \\quad \\text{log}(\\sigma_t^{()}) = \\beta_{0, \\sigma}^{()} + s_{\\sigma}^{()}(\\text{oil}_t), \\quad = 1,2,  covering potential explanatory covariates sake simplicity. Similar first example, can prepare model matrices using make_matrices(): , specify penalised negative log-likelihood function. differs first example state-dependent distributions, opposed state process parameters, depend covariate. Additionally, now two completely separated spline-coefficient matrices/ random effects called betaSpline alphaSpline state-dependent means standard deviations respectively. Thus, need pass list penalty() function. also pass penalty matrix list S provided make_matrices(). potentially list length two two spline coefficient matrices penalised differently (e.g. us using different spline basis). case, however, pass list length one. matter penalty() pass list length one just one matrix. point , model fit now basically identical previous two examples. specify initial parameters include inital penalty strength parameter dat list. fitted model, can visualise results. first decode probable state sequence plot estimated state-dependent densities function oil price, well decoded time series. former, create fine grid oil price values use predict() build associated interpolating design matrix.","code":"data(energy, package = \"MSwM\") head(energy) #>      Price      Oil      Gas     Coal   EurDol Ibex35   Demand #> 1 3.188083 22.43277 14.40099 38.35157 1.134687 8.3976 477.3856 #> 2 4.953667 22.27263 19.02747 38.35157 1.106439 8.3771 609.1261 #> 3 4.730917 22.65383 18.48417 38.35157 1.106684 8.5547 650.3715 #> 4 4.531000 23.67657 18.30143 38.35157 1.116819 8.4631 647.0499 #> 5 5.141875 23.67209 14.55602 38.35157 1.122965 8.1773 627.9698 #> 6 6.322083 23.60534 15.22485 38.35157 1.122460 8.1866 693.2467 modmat = make_matrices(~ s(Oil, k = 12, bs = \"ps\"), energy) Z = modmat$Z # design matrix S = modmat$S # penalty matrix (list) pnll = function(par) {   getAll(par, dat)   Gamma = tpm(eta) # computing the tpm   delta = stationary(Gamma) # stationary distribution    # regression parameters for mean and sd   beta = cbind(beta0, betaSpline); REPORT(beta) # mean parameter matrix   alpha = cbind(alpha0, alphaSpline); REPORT(alpha) # sd parameter matrix    # calculating all covariate-dependent means and sds   Mu = Z %*% t(beta) # mean   Sigma = exp(Z %*% t(alpha)) # sd    allprobs = cbind(dnorm(price, Mu[,1], Sigma[,1]),                    dnorm(price, Mu[,2], Sigma[,2])) # state-dependent densities      - forward(delta, Gamma, allprobs) +     penalty(list(betaSpline, alphaSpline), S, lambda) } # initial parameter list par = list(eta = rep(-4, 2), # state process intercepts            beta0 = c(2, 5), # state-dependent mean intercepts            betaSpline = matrix(0, nrow = 2, ncol = 11), # mean spline coef            alpha0 = c(0, 0), # state-dependent sd intercepts            alphaSpline = matrix(0, nrow = 2, ncol = 11)) # sd spline coef  # data, model matrices and initial penalty strength dat = list(price = energy$Price,             Z = Z,             S = S,             lambda = rep(1e3, 4))  # model fit system.time(   mod3 <- qreml(pnll, par, dat, random = c(\"betaSpline\", \"alphaSpline\")) ) #> Creating AD function #> Initialising with lambda: 1000 1000 1000 1000  #> outer 1 - lambda: 466.896 374.247 432.358 329.654  #> outer 2 - lambda: 250.283 143.698 200.372 113.051  #> outer 3 - lambda: 126.064 57.828 99.173 42.157  #> outer 4 - lambda: 72.846 26.191 56.901 18.27  #> outer 5 - lambda: 48.019 14.491 35.924 9.766  #> outer 6 - lambda: 35.991 10.081 24.159 6.518  #> outer 7 - lambda: 29.871 8.365 17.317 5.192  #> outer 8 - lambda: 26.631 7.684 13.359 4.626  #> outer 9 - lambda: 24.863 7.41 11.104 4.375  #> outer 10 - lambda: 23.88 7.297 9.836 4.263  #> outer 11 - lambda: 23.325 7.25 9.13 4.213  #> outer 12 - lambda: 23.007 7.23 8.74 4.189  #> outer 13 - lambda: 22.822 7.22 8.525 4.178  #> outer 14 - lambda: 22.719 7.216 8.406 4.173  #> outer 15 - lambda: 22.655 7.214 8.342 4.171  #> outer 16 - lambda: 22.618 7.213 8.305 4.17  #> outer 17 - lambda: 22.598 7.213 8.286 4.169  #> outer 18 - lambda: 22.589 7.212 8.279 4.169  #> outer 19 - lambda: 22.588 7.212 8.277 4.169  #> Converged #> Final model fit with lambda: 22.588 7.212 8.277 4.169 #>    user  system elapsed  #>  15.481   5.681  14.589 xseq = seq(min(energy$Oil), max(energy$Oil), length = 200) # sequence for prediction Z_p = predict(modmat, newdata = data.frame(Oil = xseq)) # prediction design matrix  energy$states = viterbi(mod = mod3) # decoding most probable state sequence  Mu_plot = Z_p %*% t(mod3$beta) Sigma_plot = exp(Z_p %*% t(mod3$alpha))  library(scales) # to make colors semi-transparent  par(mfrow = c(1,2))  # state-dependent distribution as a function of oil price plot(energy$Oil, energy$Price, pch = 20, bty = \"n\", col = alpha(color[energy$states], 0.1),      xlab = \"oil price\", ylab = \"energy price\") for(j in 1:2) lines(xseq, Mu_plot[,j], col = color[j], lwd = 3) # means qseq = qnorm(seq(0.5, 0.95, length = 4)) # sequence of quantiles for(i in qseq){ for(j in 1:2){   lines(xseq, Mu_plot[,j] + i * Sigma_plot[,j], col = alpha(color[j], 0.7), lty = 2)   lines(xseq, Mu_plot[,j] - i * Sigma_plot[,j], col = alpha(color[j], 0.7), lty = 2) }} legend(\"topright\", bty = \"n\", legend = paste(\"state\", 1:2), col = color, lwd = 3)  # decoded time series plot(NA, xlim = c(0, nrow(energy)), ylim = c(1,10), bty = \"n\",      xlab = \"time\", ylab = \"energy price\") segments(x0 = 1:(nrow(energy)-1), x1 = 2:nrow(energy),          y0 = energy$Price[-nrow(energy)], y1 = energy$Price[-1],           col = color[energy$states[-1]], lwd = 0.5)"},{"path":[]},{"path":"https://janoleko.github.io/articles/Periodic_HMMs.html","id":"setting-parameters-for-simulation","dir":"Articles","previous_headings":"","what":"Setting parameters for simulation","title":"Periodic HMMs","text":"simulate 2-state HMM Gaussian state-dependent distributions. periodic inhomogeneity, choose bimodal activity pattern. L transition probability matrices can conveniently calculated using tpm_p(). hood, performs basis expansion using trigBasisExp() sine cosine terms uses linear predictos form  \\eta^{(t)}_{ij} = \\beta_0^{(ij)} + \\sum_{k=1}^K \\bigl( \\beta_{1k}^{(ij)} \\sin(\\frac{2 \\pi k t}{L}) + \\beta_{2k}^{(ij)} \\cos(\\frac{2 \\pi k t}{L}) \\bigr)  -diagonal entries transition probability matrix. special case periodically inhomogeneous Markov chains also allows derivation -called periodically stationary distribution (Koslik et al. 2023) can compute distribution using stationary_p().","code":"# parameters mu = c(4, 14)   # state-dependent means sigma = c(3, 5) # state-dependent standard deviations  L = 48 # half-hourly data: 48 observations per day beta = matrix(c(-1, 1, -1, -1, 1,                 -2, -1, 2, 2, -2), nrow = 2, byrow = TRUE) Gamma = tpm_p(seq(1, 48, by = 1), L, beta, degree = 2) Delta = stationary_p(Gamma)  # having a look at the periodically stationary distribution color = c(\"orange\", \"deepskyblue\") plot(Delta[,1], type = \"b\", lwd = 2, pch = 16, col = color[1], bty = \"n\",       xlab = \"time of day\", ylab = \"Pr(state 1)\") # only plotting one state, as the other probability is just 1-delta"},{"path":"https://janoleko.github.io/articles/Periodic_HMMs.html","id":"simulating-data","dir":"Articles","previous_headings":"","what":"Simulating data","title":"Periodic HMMs","text":"","code":"# simulation tod = rep(1:48, 50) # time of day variable, 50 days n = length(tod) set.seed(123) s = rep(NA, n) s[1] = sample(1:2, 1, prob = Delta[tod[1],]) # initial state from stationary dist for(t in 2:n){   # sampling next state conditional on previous one and the periodic t.p.m.   s[t] = sample(1:2, 1, prob = Gamma[s[t-1],,tod[t]]) } # sampling observations conditional on the states x = rnorm(n, mu[s], sigma[s])  oldpar = par(mfrow = c(1,2)) plot(x[1:400], bty = \"n\", pch = 20, ylab = \"x\",       col = color[s[1:400]]) boxplot(x ~ tod, xlab = \"time of day\") # we see a periodic pattern in the data par(oldpar)"},{"path":[]},{"path":"https://janoleko.github.io/articles/Periodic_HMMs.html","id":"writing-the-negative-log-likelihood-function","dir":"Articles","previous_headings":"Trigonometric modeling of the transition probalities","what":"Writing the negative log-likelihood function","title":"Periodic HMMs","text":"specify likelihood function pretend know degree trigonometric link , practice, never case. use tpm_p() compute periodically stationary start using stationary_p() additional argument specifies time point compute.","code":"nll = function(par, x, tod){   beta = matrix(par[1:10], nrow = 2) # matrix of coefficients   Gamma = tpm_p(tod = 1:48, L = 48, beta = beta, degree = 2) # calculating all L tpms   delta = stationary_p(Gamma, t = tod[1]) # periodically stationary start   mu = par[11:12]   sigma = exp(par[13:14])   # calculate all state-dependent probabilities   allprobs = matrix(1, length(x), 2)   for(j in 1:2) allprobs[,j] = dnorm(x, mu[j], sigma[j])   # return negative for minimization   -forward_p(delta, Gamma, allprobs, tod) }"},{"path":"https://janoleko.github.io/articles/Periodic_HMMs.html","id":"fitting-an-hmm-to-the-data","dir":"Articles","previous_headings":"Trigonometric modeling of the transition probalities","what":"Fitting an HMM to the data","title":"Periodic HMMs","text":"","code":"par = c(beta = c(-1,-2, rep(0, 8)), # starting values state process         mu = c(4, 14), # initial state-dependent means         logsigma = c(log(3),log(5))) # initial state-dependent sds system.time(   mod <- nlm(nll, par, x = x, tod = tod) ) #>    user  system elapsed  #>   0.904   0.022   0.926"},{"path":"https://janoleko.github.io/articles/Periodic_HMMs.html","id":"visualising-results","dir":"Articles","previous_headings":"Trigonometric modeling of the transition probalities","what":"Visualising results","title":"Periodic HMMs","text":", use tpm_p() stationary_p() tranform parameters.","code":"# transform parameters to working beta_hat = matrix(mod$estimate[1:10], nrow = 2) Gamma_hat = tpm_p(tod = 1:48, L = 48, beta = beta_hat, degree = 2) Delta_hat = stationary_p(Gamma_hat) mu_hat = mod$estimate[11:12] sigma_hat = exp(mod$estimate[13:14])  delta_hat = apply(Delta_hat, 2, mean)  oldpar = par(mfrow = c(1,2)) hist(x, prob = TRUE, bor = \"white\", breaks = 40, main = \"\") curve(delta_hat[1]*dnorm(x, mu_hat[1], sigma_hat[1]), add = TRUE, lwd = 2,        col = color[1], n=500) curve(delta_hat[2]*dnorm(x, mu_hat[2], sigma_hat[2]), add = TRUE, lwd = 2,        col = color[2], n=500) curve(delta_hat[1]*dnorm(x, mu_hat[1], sigma_hat[1])+         delta_hat[2]*dnorm(x, mu[2], sigma_hat[2]),       add = TRUE, lwd = 2, lty = \"dashed\", n = 500) legend(\"topright\", col = c(color[1], color[2], \"black\"), lwd = 2, bty = \"n\",        lty = c(1,1,2), legend = c(\"state 1\", \"state 2\", \"marginal\"))  plot(Delta_hat[,1], type = \"b\", lwd = 2, pch = 16, col = color[1], bty = \"n\",       xlab = \"time of day\", ylab = \"Pr(state 1)\") par(oldpar)"},{"path":"https://janoleko.github.io/articles/Periodic_HMMs.html","id":"efficieny-and-convenience","dir":"Articles","previous_headings":"","what":"Efficieny and convenience","title":"Periodic HMMs","text":"convenient use tpm_p(), performs basis expansion sine cosine terms time evaluated. wasteful model estimation terms stay fixed. better alternative first build corresponding design matrix. can done conveniently using cosinor() function, either formula passed make_matrices(). First let’s call cosinor() : cosinor function excepts period argument specifies period trigonometric functions. can see, period can vector, leading larger basis expansion, .e. flexibility. model involves covariates time day, say temperature (temp), might convenient use make_matrices() formula: cases, transition probability matrix can calculated using tpm_g() tpm_p(): Continue reading LaMa RTMB Penalised splines.","code":"tod = 1:24 # cyclic time of day variable Z = cosinor(tod, period = c(24, 12)) # design matrix Z = cbind(intercept = 1, Z) head(Z, 2) #>      intercept sin(2*pi*tod/24) cos(2*pi*tod/24) sin(2*pi*tod/12) #> [1,]         1         0.258819        0.9659258        0.5000000 #> [2,]         1         0.500000        0.8660254        0.8660254 #>      cos(2*pi*tod/12) #> [1,]        0.8660254 #> [2,]        0.5000000 data = data.frame(tod = rep(1:24, 2),                    temp = rnorm(48, 20, 5)) modmat = make_matrices(~ temp * cosinor(tod, 24), data) Z = modmat$Z head(Z, 2) #>      (Intercept)     temp sin(2 * pi * tod/24) cos(2 * pi * tod/24) #> [1,]           1 18.93188             0.258819            0.9659258 #> [2,]           1 25.98938             0.500000            0.8660254 #>      temp:sin(2 * pi * tod/24) temp:cos(2 * pi * tod/24) #> [1,]                  4.899932                  18.28680 #> [2,]                 12.994690                  22.50746 # coefficient matrix (beta = matrix(c(-2,-2, runif(2*(ncol(Z)-1))), nrow = 2)) #>      [,1]      [,2]      [,3]       [,4]      [,5]      [,6] #> [1,]   -2 0.5438832 0.3935516 0.75556189 0.8233689 0.7234530 #> [2,]   -2 0.2698139 0.3127479 0.05147858 0.9122313 0.1442263 # constructing t.p.m.s Gamma = tpm_p(Z = Z, beta = beta) # not first arguments in tpm_p Gamma = tpm_g(Z, beta) # but first arguments in tpm_g"},{"path":[]},{"path":"https://janoleko.github.io/articles/State_space_models.html","id":"simulating-data-from-the-stochastic-volatility-model","dir":"Articles","previous_headings":"","what":"Simulating data from the stochastic volatility model","title":"State-space models","text":"start simulating data specified model:","code":"# loading the package library(LaMa) #> Loading required package: RTMB beta = 2 # baseline standard deviation phi = 0.95 # AR parameter of the log-volatility process sigma = 0.5 # variability of the log-volatility process  n = 1000 set.seed(123) g = rep(NA, n) g[1] = rnorm(1, 0, sigma / sqrt(1-phi^2)) # stationary distribution of AR(1) process for(t in 2:n){   # sampling next state based on previous state and AR(1) equation   g[t] = rnorm(1, phi*g[t-1], sigma) } # sampling zero-mean observations with standard deviation given by latent process y = rnorm(n, 0, beta * exp(g/2))   # share returns oldpar = par(mar = c(5,4,3,4.5)+0.1) plot(y, type = \"l\", bty = \"n\", ylim = c(-40,20), yaxt = \"n\") # true underlying standard deviation lines(beta*exp(g)/7 - 40, col = \"deepskyblue\", lwd = 2) axis(side=2, at = seq(-20,20,by=5), labels = seq(-20,20,by=5)) axis(side=4, at = seq(0,150,by=75)/7-40, labels = seq(0,150,by=75)) mtext(\"standard deviation\", side=4, line=3, at = -30) par(oldpar)"},{"path":"https://janoleko.github.io/articles/State_space_models.html","id":"writing-the-negative-log-likelihood-function","dir":"Articles","previous_headings":"","what":"Writing the negative log-likelihood function","title":"State-space models","text":"calculate likelihood, need integrate state space. approximate high-dimensional integral using midpoint quadrature ultimately results fine discretisation continuous state space intervals b width h midpoints bstar (Langrock 2011). Thus, likelihood corresponds basic HMM likelihood large number states.","code":"nll = function(par, y, bm, m){   phi = plogis(par[1])   sigma = exp(par[2])   beta = exp(par[3])   b = seq(-bm, bm, length = m+1) # intervals for midpoint quadrature   h = b[2] - b[1] # interval width   bstar = (b[-1] + b[-(m+1)]) / 2 # interval midpoints   # approximating t.p.m. resulting from midpoint quadrature   Gamma = sapply(bstar, dnorm, mean = phi * bstar, sd = sigma) * h   delta = h * dnorm(bstar, 0, sigma / sqrt(1-phi^2)) # stationary distribution   # approximating state-dependent density based on midpoints   allprobs = t(sapply(y, dnorm, mean = 0, sd = beta * exp(bstar/2)))   # forward algorithm   -forward(delta, Gamma, allprobs) }"},{"path":"https://janoleko.github.io/articles/State_space_models.html","id":"fitting-an-ssm-to-the-data","dir":"Articles","previous_headings":"","what":"Fitting an SSM to the data","title":"State-space models","text":"","code":"par = c(qlogis(0.95), log(0.3), log(1)) bm = 5 # relevant range of underlying volatility (-5,5) m = 100 # number of approximating states  system.time(   mod <- nlm(nll, par, y = y, bm = bm, m = m) ) #>    user  system elapsed  #>   1.383   2.424   0.975"},{"path":"https://janoleko.github.io/articles/State_space_models.html","id":"results","dir":"Articles","previous_headings":"","what":"Results","title":"State-space models","text":"","code":"## parameter estimates (phi = plogis(mod$estimate[1])) #> [1] 0.9516567 (sigma = exp(mod$estimate[2])) #> [1] 0.4436876 (beta = exp(mod$estimate[3])) #> [1] 2.184006  ## decoding states b = seq(-bm, bm, length = m+1) # intervals for midpoint quadrature h = b[2]-b[1] # interval width bstar = (b[-1] + b[-(m+1)])/2 # interval midpoints Gamma = sapply(bstar, dnorm, mean = phi*bstar, sd = sigma) * h delta = h * dnorm(bstar, 0, sigma/sqrt(1-phi^2)) # stationary distribution # approximating state-dependent density based on midpoints allprobs = t(sapply(y, dnorm, mean = 0, sd = beta * exp(bstar/2)))  # actual decoding probs = stateprobs(delta, Gamma, allprobs) # local/ soft decoding states = viterbi(delta, Gamma, allprobs) # global/ hard decoding  oldpar = par(mar = c(5,4,3,4.5)+0.1) plot(y, type = \"l\", bty = \"n\", ylim = c(-50,20), yaxt = \"n\") # when there are so many states it is not too sensable to only plot the most probable state, # as its probability might still be very small. Generally, we are approximating continuous  # distributions, thus it makes sense to plot the entire conditional distribution. maxprobs = apply(probs, 1, max) for(t in 1:nrow(probs)){   colend = round((probs[t,]/(maxprobs[t]*5))*100)   colend[which(colend<10)] = paste0(\"0\", colend[which(colend<10)])   points(rep(t, m), bstar*4-35, col = paste0(\"#FFA200\",colend), pch = 20) } # we can add the viterbi decoded volatility levels as a \"mean\" lines(bstar[states]*4-35)  axis(side=2, at = seq(-20,20,by=5), labels = seq(-20,20,by=5)) axis(side=4, at = seq(-5,5, by = 5)*4-35, labels = seq(-5,5, by = 5)) mtext(\"g\", side=4, line=3, at = -30) par(oldpar)"},{"path":[]},{"path":"https://janoleko.github.io/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Jan-Ole Koslik. Author, maintainer.","code":""},{"path":"https://janoleko.github.io/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Koslik J (2025). LaMa: Fast Numerical Maximum Likelihood Estimation Latent Markov Models. R package version 2.0.6, https://janoleko.github.io/LaMa/.","code":"@Manual{,   title = {LaMa: Fast Numerical Maximum Likelihood Estimation for Latent Markov Models},   author = {Jan-Ole Koslik},   year = {2025},   note = {R package version 2.0.6},   url = {https://janoleko.github.io/LaMa/}, }"},{"path":"https://janoleko.github.io/index.html","id":"lama---latent-markov-model-toolbox-️-","dir":"","previous_headings":"","what":"Fast Numerical Maximum Likelihood Estimation for Latent Markov Models","title":"Fast Numerical Maximum Likelihood Estimation for Latent Markov Models","text":"variety latent Markov models (Mews, Koslik, Langrock 2025), including hidden Markov models (HMMs), hidden semi-Markov models (HSMMs), state-space models (SSMs) continuous-time variants can formulated estimated within framework via directly maximising likelihood function using -called forward algorithm (Zucchini, MacDonald, Langrock 2016). Applied researchers often need custom models standard software easily support. Writing tailored R code offers flexibility suffers slow estimation speeds. R package solves issues providing easy--use functions (written C++ speed) common tasks like forward algorithm. functions can combined custom models Lego-type approach, offering 10-20 times faster estimation via standard numerical optimisers. recent iteration, LaMa allows automatic differentiation RTMB package drastically increases speed accuracy even . important families functions forward family calculates log-likelihood various different models, tpm family calculating transition probability matrices, stationary family compute stationary periodically stationary distributions well stateprobs viterbi families local global decoding.","code":""},{"path":"https://janoleko.github.io/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Fast Numerical Maximum Likelihood Estimation for Latent Markov Models","text":"can install released package version CRAN : development version Github:","code":"install.packages(\"LaMa\") remotes::install_github(\"janoleko/LaMa\")"},{"path":"https://janoleko.github.io/index.html","id":"package-documentation","dir":"","previous_headings":"","what":"Package documentation","title":"Fast Numerical Maximum Likelihood Estimation for Latent Markov Models","text":"aid building fully custom likelihood functions, package contains several vignettes demonstrate simulate data estimate wide range models using functions included package. HMMs, simple complex: Introduction LaMa Inhomogeneous HMMs covariate effects Longitudinal data Periodic HMMs LaMa RTMB Penalised splines latent Markov model classes: State-space models Continuous-time HMMs Hidden semi-Markov models Markov-modulated (marked) Poisson processes","code":""},{"path":"https://janoleko.github.io/index.html","id":"introductory-example-homogeneous-hmm","dir":"","previous_headings":"","what":"Introductory example: Homogeneous HMM","title":"Fast Numerical Maximum Likelihood Estimation for Latent Markov Models","text":"analyse trex data set contained package. contains hourly step lengths Tyrannosaurus rex, living 66 million years ago. data, fit simple 2-state HMM state-dependent gamma distributions step lengths. start defining negative log-likelihood function. made really convenient functions tpm() computes transition probability matrix via multinomial logit link, stationary() computes stationary distribution Markov chain forward() calculates log-likelihood via forward algorithm. fit model, define intial parameter vector numerically optimise function using nlm(): Really fast 10.000 data points! tranforming working (unconstrained) parameters natural parameters using tpm() stationary(), can visualise results:","code":"library(LaMa) #> Loading required package: RTMB  head(trex, 3) #>   tod      step     angle state #> 1   9 0.3252437        NA     1 #> 2  10 0.2458265  2.234562     1 #> 3  11 0.2173252 -2.262418     1 nll = function(par, step){   # parameter transformations for unconstrained optimisation   Gamma = tpm(par[1:2]) # rowwise softmax   delta = stationary(Gamma) # stationary distribution   mu = exp(par[3:4]) # state-dependent means   sigma = exp(par[5:6]) # state-dependent sds   # calculating all state-dependent probabilities   allprobs = matrix(1, length(step), 2)   ind = which(!is.na(step))   for(j in 1:2) allprobs[ind,j] = dgamma2(step[ind], mu[j], sigma[j])   # simple forward algorithm to calculate log-likelihood   -forward(delta, Gamma, allprobs) } par = c(-2,-2,             # initial tpm params (logit-scale)         log(c(0.3, 2.5)),  # initial means for step length (log-transformed)         log(c(0.2, 1.5)))  # initial sds for step length (log-transformed)  system.time(   mod <- nlm(nll, par, step = trex$step) ) #>    user  system elapsed  #>   0.364   0.012   0.379 # transform parameters to working (Gamma = tpm(mod$estimate[1:2])) #>           S1        S2 #> S1 0.8269546 0.1730454 #> S2 0.1608470 0.8391530 (delta = stationary(Gamma)) # stationary HMM #>       S1       S2  #> 0.481733 0.518267 (mu = exp(mod$estimate[3:4])) #> [1] 0.3034926 2.5057053 (sigma = exp(mod$estimate[5:6])) #> [1] 0.2015258 1.4908153  hist(trex$step, prob = TRUE, bor = \"white\", breaks = 40, main = \"\", xlab = \"step length\") curve(delta[1] * dgamma2(x, mu[1], sigma[1]), add = TRUE, lwd = 2, col = \"orange\", n=500) curve(delta[2] * dgamma2(x, mu[2], sigma[2]), add = TRUE, lwd = 2, col = \"deepskyblue\", n=500) legend(\"topright\", col = c(\"orange\", \"deepskyblue\"), lwd = 2, bty = \"n\", legend = c(\"state 1\", \"state 2\"))"},{"path":"https://janoleko.github.io/reference/LaMa-package.html","id":null,"dir":"Reference","previous_headings":"","what":"LaMa: Fast Numerical Maximum Likelihood Estimation for Latent Markov Models — LaMa-package","title":"LaMa: Fast Numerical Maximum Likelihood Estimation for Latent Markov Models — LaMa-package","text":"variety latent Markov models, including hidden Markov models, hidden semi-Markov models, state-space models continuous-time variants can formulated estimated within framework via directly maximising likelihood function using -called forward algorithm. Applied researchers often need custom models standard software easily support. Writing tailored 'R' code offers flexibility suffers slow estimation speeds. address issues providing easy--use functions (written 'C++' speed) common tasks like forward algorithm. functions can combined custom models Lego-type approach, offering 10-20 times faster estimation via standard numerical optimisers. aid building fully custom likelihood functions, several vignettes included show simulate data estimate model classes.","code":""},{"path":[]},{"path":"https://janoleko.github.io/reference/LaMa-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"LaMa: Fast Numerical Maximum Likelihood Estimation for Latent Markov Models — LaMa-package","text":"Maintainer: Jan-Ole Koslik jan-ole.koslik@uni-bielefeld.de (ORCID)","code":""},{"path":"https://janoleko.github.io/reference/calc_trackInd.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the index of the first observation of each track based on an ID variable — calc_trackInd","title":"Calculate the index of the first observation of each track based on an ID variable — calc_trackInd","text":"Function conveniently calculate trackInd variable needed internally fitting model longitudinal data multiple tracks.","code":""},{"path":"https://janoleko.github.io/reference/calc_trackInd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the index of the first observation of each track based on an ID variable — calc_trackInd","text":"","code":"calc_trackInd(ID)"},{"path":"https://janoleko.github.io/reference/calc_trackInd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the index of the first observation of each track based on an ID variable — calc_trackInd","text":"ID ID variable track IDs length data analysed","code":""},{"path":"https://janoleko.github.io/reference/calc_trackInd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the index of the first observation of each track based on an ID variable — calc_trackInd","text":"vector indices first observation track can passed forward forward_g sum likelihood contributions track","code":""},{"path":"https://janoleko.github.io/reference/calc_trackInd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate the index of the first observation of each track based on an ID variable — calc_trackInd","text":"","code":"uniqueID = c(\"Animal1\", \"Animal2\", \"Animal3\") ID = rep(uniqueID, c(100, 200, 300)) trackInd = calc_trackInd(ID)"},{"path":"https://janoleko.github.io/reference/cosinor.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate trigonometric basis expansion — cosinor","title":"Evaluate trigonometric basis expansion — cosinor","text":"function can used evaluate trigonometric basis expansion given periodic variable period. can also used formulas passed make_matrices.","code":""},{"path":"https://janoleko.github.io/reference/cosinor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate trigonometric basis expansion — cosinor","text":"","code":"cosinor(x = 1:24, period = 24, eval = TRUE)"},{"path":"https://janoleko.github.io/reference/cosinor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate trigonometric basis expansion — cosinor","text":"x vector periodic variable values period vector period length. example time day period = 24, period = c(24,12) flexibility. eval logical, changed. TRUE function returns evaluated cosinor terms, FALSE function returns terms strings used internally form formula evaluation.","code":""},{"path":"https://janoleko.github.io/reference/cosinor.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate trigonometric basis expansion — cosinor","text":"either desing matrix evaluated cosinor terms (eval = TRUE) character vector terms strings (eval = FALSE).","code":""},{"path":"https://janoleko.github.io/reference/cosinor.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate trigonometric basis expansion — cosinor","text":"returned basis can used linear predictors form $$  \\eta^{(t)} = \\beta_0 + \\sum_{k} \\bigl( \\beta_{1k} \\sin(\\frac{2 \\pi t}{period_k}) + \\beta_{2k} \\cos(\\frac{2 \\pi t}{period_k}) \\bigr). $$ relevant modeling e.g. diurnal variation flexibility can increased adding smaller frequencies (.e. increasing length period).","code":""},{"path":"https://janoleko.github.io/reference/cosinor.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Evaluate trigonometric basis expansion — cosinor","text":"","code":"## Evaluate cosinor terms # builds design matrix X = cosinor(1:24, period = 24) X = cosinor(1:24, period = c(24, 12, 6))  ## Usage in model formulas # e.g. frequencies of 24 and 12 hours + interaction with temperature form = ~ x + temp * cosinor(hour, c(24, 12))  data = data.frame(x = runif(24), temp = rnorm(24,20), hour = 1:24) modmat = make_matrices(form, data = data)"},{"path":"https://janoleko.github.io/reference/ddwell.html","id":null,"dir":"Reference","previous_headings":"","what":"State dwell-time distributions of periodically inhomogeneous Markov chains — ddwell","title":"State dwell-time distributions of periodically inhomogeneous Markov chains — ddwell","text":"Computes dwell-time distribution periodically inhomogeneous Markov chain given transition probability matrix.","code":""},{"path":"https://janoleko.github.io/reference/ddwell.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"State dwell-time distributions of periodically inhomogeneous Markov chains — ddwell","text":"","code":"ddwell(x, Gamma, time = NULL, state = NULL)"},{"path":"https://janoleko.github.io/reference/ddwell.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"State dwell-time distributions of periodically inhomogeneous Markov chains — ddwell","text":"x vector (non-negative) dwell times compute dwell-time distribution Gamma array L unique transition probability matrices periodically inhomogeneous Markov chain, dimensions c(N,N,L), N number states L cycle length time integer vector time points 1:L compute dwell-time distribution. NULL, overall dwell-time distribution computed. state integer vector state indices compute dwell-time distribution. NULL, dwell-time distributions states returned named list.","code":""},{"path":"https://janoleko.github.io/reference/ddwell.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"State dwell-time distributions of periodically inhomogeneous Markov chains — ddwell","text":"either time-varying dwell-time distribution(s) time specified, overall dwell-time distribution time NULL. one state specified, named list states returned.","code":""},{"path":"https://janoleko.github.io/reference/ddwell.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"State dwell-time distributions of periodically inhomogeneous Markov chains — ddwell","text":"Markov chains whose transition probabilities vary periodically, achieved example expressing transition probability matrix periodic function time day using tpm_p cosinor, probability distribution time spent state can computed analytically. function computes said distribution, either specific time point (conditioning transitioning state time point) overall distribution (conditioning transitioning state time point).","code":""},{"path":"https://janoleko.github.io/reference/ddwell.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"State dwell-time distributions of periodically inhomogeneous Markov chains — ddwell","text":"Koslik, J. O., Feldmann, C. C., Mews, S., Michels, R., & Langrock, R. (2023). Inference state process periodically inhomogeneous hidden Markov models animal behavior. arXiv preprint arXiv:2312.14583.","code":""},{"path":"https://janoleko.github.io/reference/ddwell.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"State dwell-time distributions of periodically inhomogeneous Markov chains — ddwell","text":"","code":"# setting parameters for trigonometric link beta = matrix(c(-1, 2, -1, -2, 1, -1), nrow = 2, byrow = TRUE) Gamma = tpm_p(beta = beta, degree = 1)  # at specific times and for specific state ddwell(1:20, Gamma, time = 1:4, state = 1) #>             1          2         3         4         5          6          7 #> t1 0.06255530 0.08043312 0.1021583 0.1232574 0.1360227 0.13328015 0.11424672 #> t2 0.08580039 0.10897526 0.1314824 0.1450994 0.1421739 0.12187035 0.09171239 #> t3 0.11920292 0.14382237 0.1587175 0.1555173 0.1333083 0.10031987 0.06762680 #> t4 0.16328661 0.18019753 0.1765643 0.1513496 0.1138967 0.07677909 0.04780658 #>             8          9          10          11          12          13 #> t1 0.08597529 0.05795695 0.036086957 0.021451897 0.012526000 0.007332955 #> t2 0.06182440 0.03849502 0.022883373 0.013361855 0.007822280 0.004653506 #> t3 0.04210790 0.02503105 0.014615906 0.008556424 0.005090252 0.003109226 #> t4 0.02841863 0.01659395 0.009714411 0.005779143 0.003530014 0.002237972 #>             14          15           16           17           18           19 #> t1 0.004362405 0.002664643 0.0016893407 0.0011259864 0.0008002580 0.0006147365 #> t2 0.002842453 0.001802070 0.0012011230 0.0008536589 0.0006557576 0.0005503568 #> t3 0.001971199 0.001313852 0.0009337773 0.0007173024 0.0006020094 0.0005554132 #> t4 0.001491663 0.001060150 0.0008143787 0.0006834825 0.0006305802 0.0006396266 #>              20 #> t1 0.0005159290 #> t2 0.0005077585 #> t3 0.0005633812 #> t4 0.0007085138 # results in 4x20 matrix  # or overall distribution for all states ddwell(1:20, Gamma) #> $`state 1` #>          1          2          3          4          5          6          7  #> 0.23876652 0.16830698 0.11852833 0.08374960 0.05952926 0.04274237 0.03127267  #>          8          9         10         11         12         13         14  #> 0.02366237 0.01886914 0.01613048 0.01488364 0.01470017 0.01522215 0.01610698  #>         15         16         17         18         19         20  #> 0.01699858 0.01754221 0.01744454 0.01655301 0.01490724 0.01272368  #>  #> $`state 2` #>            1            2            3            4            5            6  #> 0.5304997868 0.1712799650 0.0662901569 0.0324558381 0.0202817977 0.0156571047  #>            7            8            9           10           11           12  #> 0.0141716305 0.0142623506 0.0152462653 0.0166678924 0.0180415973 0.0187787681  #>           13           14           15           16           17           18  #> 0.0182904359 0.0162522851 0.0128784300 0.0089320207 0.0053514586 0.0027523266  #>           19           20  #> 0.0012168037 0.0004667301  #>  # results in list of length 2, each element is a vector of length 20"},{"path":"https://janoleko.github.io/reference/dgmrf2.html","id":null,"dir":"Reference","previous_headings":"","what":"Reparametrised multivariate Gaussian distribution — dgmrf2","title":"Reparametrised multivariate Gaussian distribution — dgmrf2","text":"Density function multivariate Gaussian distribution reparametrised terms precision matrix (inverse variance). implementation particularly useful defining joint log-likelihood penalised splines ..d. random effects multivariate Gaussian distribution fixed precision/ penalty matrix \\(\\lambda S\\). \\(S\\) fixed scaled \\(\\lambda\\), efficient precompute determinant \\(S\\) (normalisation constant) scale quadratic form \\(\\lambda\\) multiple spline parameters/ random effects different \\(\\lambda\\)'s penalty matrix \\(S\\) evaluated.","code":""},{"path":"https://janoleko.github.io/reference/dgmrf2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reparametrised multivariate Gaussian distribution — dgmrf2","text":"","code":"dgmrf2(x, mu = 0, S, lambda, logdetS = NULL, log = FALSE)"},{"path":"https://janoleko.github.io/reference/dgmrf2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reparametrised multivariate Gaussian distribution — dgmrf2","text":"x density evaluation point, either vector matrix mu mean parameter. Either scalar vector S unscaled precision matrix lambda precision scaling parameter Can vector x matrix. row x evaluated corresponding lambda. benefitial efficiency perspective determinant S computed . logdetS Optional precomputed log determinant precision matrix S. precision matrix depend parameters, can precomputed passed function. log logical; TRUE, densities returned log scale.","code":""},{"path":"https://janoleko.github.io/reference/dgmrf2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reparametrised multivariate Gaussian distribution — dgmrf2","text":"vector density values","code":""},{"path":"https://janoleko.github.io/reference/dgmrf2.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Reparametrised multivariate Gaussian distribution — dgmrf2","text":"implementation allows automatic differentiation RTMB.","code":""},{"path":"https://janoleko.github.io/reference/dgmrf2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reparametrised multivariate Gaussian distribution — dgmrf2","text":"","code":"x = matrix(runif(30), nrow = 3)  # iid random effects S = diag(10) sigma = c(1, 2, 3) # random effect standard deviations lambda = 1 / sigma^2 d = dgmrf2(x, 0, S, lambda)  # P-splines L = diff(diag(10), diff = 2) # second-order difference matrix S = t(L) %*% L lambda = c(1,2,3) d = dgmrf2(x, 0, S, lambda, log = TRUE)"},{"path":"https://janoleko.github.io/reference/forward.html","id":null,"dir":"Reference","previous_headings":"","what":"Forward algorithm with homogeneous transition probability matrix — forward","title":"Forward algorithm with homogeneous transition probability matrix — forward","text":"Calculates log-likelihood sequence observations homogeneous hidden Markov model using forward algorithm.","code":""},{"path":"https://janoleko.github.io/reference/forward.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Forward algorithm with homogeneous transition probability matrix — forward","text":"","code":"forward(   delta,   Gamma,   allprobs,   trackID = NULL,   ad = NULL,   report = TRUE,   logspace = FALSE )"},{"path":"https://janoleko.github.io/reference/forward.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Forward algorithm with homogeneous transition probability matrix — forward","text":"delta initial stationary distribution length N, matrix dimension c(k,N) k independent tracks, trackID provided Gamma transition probability matrix dimension c(N,N), array k transition probability matrices dimension c(N,N,k), trackID provided allprobs matrix state-dependent probabilities/ density values dimension c(n, N) trackID optional vector length n containing IDs provided, total log-likelihood sum track's likelihood contribution. case, Gamma can matrix, leading transition probabilities track, array dimension c(N,N,k), one (homogeneous) transition probability matrix track. Furthermore, instead single vector delta corresponding initial distribution, delta matrix initial distributions, dimension c(k,N), can provided, track starts initial distribution. ad optional logical, indicating whether automatic differentiation RTMB used. default, function determines . report logical, indicating whether delta, Gamma, allprobs, potentially trackID reported fitted model. Defaults TRUE, works ad = TRUE, uses RTMB package. Caution: multiple tracks, compatibility downstream functions like viterbi, stateprobs pseudo_res, forward called trackID argument. logspace logical, indicating whether probabilities/ densities allprobs matrix log-scale. , internal computations also done log-scale numerically robust entries small.","code":""},{"path":"https://janoleko.github.io/reference/forward.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Forward algorithm with homogeneous transition probability matrix — forward","text":"log-likelihood given data parameters","code":""},{"path":[]},{"path":"https://janoleko.github.io/reference/forward.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Forward algorithm with homogeneous transition probability matrix — forward","text":"","code":"## negative log likelihood function nll = function(par, step) {  # parameter transformations for unconstrained optimisation  Gamma = tpm(par[1:2]) # multinomial logit link  delta = stationary(Gamma) # stationary HMM  mu = exp(par[3:4])  sigma = exp(par[5:6])  # calculate all state-dependent probabilities  allprobs = matrix(1, length(step), 2)  ind = which(!is.na(step))  for(j in 1:2) allprobs[ind,j] = dgamma2(step[ind], mu[j], sigma[j])  # simple forward algorithm to calculate log-likelihood  -forward(delta, Gamma, allprobs) }  ## fitting an HMM to the trex data par = c(-2,-2,            # initial tpm params (logit-scale)         log(c(0.3, 2.5)), # initial means for step length (log-transformed)         log(c(0.2, 1.5))) # initial sds for step length (log-transformed) mod = nlm(nll, par, step = trex$step[1:1000])"},{"path":"https://janoleko.github.io/reference/forward_g.html","id":null,"dir":"Reference","previous_headings":"","what":"General forward algorithm with time-varying transition probability matrix — forward_g","title":"General forward algorithm with time-varying transition probability matrix — forward_g","text":"Calculates log-likelihood sequence observations hidden Markov model time-varying transition probabilities using forward algorithm.","code":""},{"path":"https://janoleko.github.io/reference/forward_g.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"General forward algorithm with time-varying transition probability matrix — forward_g","text":"","code":"forward_g(   delta,   Gamma,   allprobs,   trackID = NULL,   ad = NULL,   report = TRUE,   logspace = FALSE )"},{"path":"https://janoleko.github.io/reference/forward_g.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"General forward algorithm with time-varying transition probability matrix — forward_g","text":"delta initial stationary distribution length N, matrix dimension c(k,N) k independent tracks, trackID provided Gamma array transition probability matrices dimension c(N,N,n-1), time series length n, n-1 transitions. array dimension c(N,N,n) single track provided, first slice ignored. elements \\(\\Gamma^{(t)}\\) depend covariate values t covariates t+1 choice calculation array, prior using function. conducting calculation using tpm_g(), choice comes including covariate matrix Z[-1,] oder Z[-n,]. trackID provided, Gamma needs array dimension c(N,N,n), matching number rows allprobs. track, transition matrix beginning ignored. parameters Gamma pooled across tracks , depends calculation Gamma. pooled, can use tpm_g(Z, beta) calculate entire array transition matrices Z dimension c(n,p). function can also used fit continuous-time HMMs, array entry Markov semigroup \\(\\Gamma(\\Delta t) = \\exp(Q \\Delta t)\\) \\(Q\\) generator continuous-time Markov chain. allprobs matrix state-dependent probabilities/ density values dimension c(n, N) trackID optional vector length n containing IDs provided, total log-likelihood sum track's likelihood contribution. case, Gamma needs array dimension c(N,N,n), matching number rows allprobs. track, transition matrix beginning track ignored (transition tracks). Furthermore, instead single vector delta corresponding initial distribution, delta matrix initial distributions, dimension c(k,N), can provided, track starts initial distribution. ad optional logical, indicating whether automatic differentiation RTMB used. default, function determines . report logical, indicating whether delta, Gamma, allprobs, potentially trackID reported fitted model. Defaults TRUE, works ad = TRUE, uses RTMB package. Caution: multiple tracks, compatibility downstream functions like viterbi_g, stateprobs_g pseudo_res, forward_g called trackID argument. logspace logical, indicating whether probabilities/ densities allprobs matrix log-scale. , internal computations also done log-scale numerically robust entries small.","code":""},{"path":"https://janoleko.github.io/reference/forward_g.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"General forward algorithm with time-varying transition probability matrix — forward_g","text":"log-likelihood given data parameters","code":""},{"path":[]},{"path":"https://janoleko.github.io/reference/forward_g.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"General forward algorithm with time-varying transition probability matrix — forward_g","text":"","code":"## Simple usage Gamma = array(c(0.9, 0.2, 0.1, 0.8), dim = c(2,2,10)) delta = c(0.5, 0.5) allprobs = matrix(0.5, 10, 2) forward_g(delta, Gamma, allprobs) #> [1] -6.931472  # \\donttest{ ## Full model fitting example ## negative log likelihood function nll = function(par, step, Z) {  # parameter transformations for unconstrained optimisation  beta = matrix(par[1:6], nrow = 2)  Gamma = tpm_g(Z, beta) # multinomial logit link for each time point  delta = stationary(Gamma[,,1]) # stationary HMM  mu = exp(par[7:8])  sigma = exp(par[9:10])  # calculate all state-dependent probabilities  allprobs = matrix(1, length(step), 2)  ind = which(!is.na(step))  for(j in 1:2) allprobs[ind,j] = dgamma2(step[ind], mu[j], sigma[j])  # simple forward algorithm to calculate log-likelihood  -forward_g(delta, Gamma, allprobs) }  ## fitting an HMM to the trex data par = c(-1.5,-1.5,        # initial tpm intercepts (logit-scale)         rep(0, 4),        # initial tpm slopes         log(c(0.3, 2.5)), # initial means for step length (log-transformed)         log(c(0.2, 1.5))) # initial sds for step length (log-transformed) mod = nlm(nll, par, step = trex$step[1:500], Z = trigBasisExp(trex$tod[1:500])) #> Warning: NA/NaN replaced by maximum positive value # }"},{"path":"https://janoleko.github.io/reference/forward_hsmm.html","id":null,"dir":"Reference","previous_headings":"","what":"Forward algorithm for homogeneous hidden semi-Markov models — forward_hsmm","title":"Forward algorithm for homogeneous hidden semi-Markov models — forward_hsmm","text":"Calculates (approximate) log-likelihood sequence observations homogeneous hidden semi-Markov model using modified forward algorithm.","code":""},{"path":"https://janoleko.github.io/reference/forward_hsmm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Forward algorithm for homogeneous hidden semi-Markov models — forward_hsmm","text":"","code":"forward_hsmm(   dm,   omega,   allprobs,   trackID = NULL,   delta = NULL,   eps = 1e-10,   report = TRUE )"},{"path":"https://janoleko.github.io/reference/forward_hsmm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Forward algorithm for homogeneous hidden semi-Markov models — forward_hsmm","text":"dm list length N containing vectors dwell-time probability mass functions (PMFs) state. vector lengths correspond approximating state aggregate sizes, hence little probablity mass covered . omega matrix dimension c(N,N) conditional transition probabilites, also called embedded transition probability matrix. Contains transition probabilities given current state left. Hence, diagonal elements need zero rows need sum one. Can constructed using tpm_emb. allprobs matrix state-dependent probabilities/ density values dimension c(n, N) automatically converted appropriate dimension. trackID optional vector length n containing IDs provided, total log-likelihood sum track's likelihood contribution. case, dm can nested list, top layer contains k dm lists described . omega can also array dimension c(N,N,k) one conditional transition probability matrix track. Furthermore, instead single vector delta corresponding initial distribution, delta matrix initial distributions, dimension c(k,N), can provided, track starts initial distribution. delta optional vector initial state probabilities length N default, stationary distribution computed (typically recommended). eps small value avoid numerical issues approximating transition matrix construction. Usually, changed. report logical, indicating whether initial distribution, approximating transition probability matrix allprobs matrix reported fitted model. Defaults TRUE.","code":""},{"path":"https://janoleko.github.io/reference/forward_hsmm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Forward algorithm for homogeneous hidden semi-Markov models — forward_hsmm","text":"log-likelihood given data parameters","code":""},{"path":"https://janoleko.github.io/reference/forward_hsmm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Forward algorithm for homogeneous hidden semi-Markov models — forward_hsmm","text":"Hidden semi-Markov models (HSMMs) flexible extension HMMs, state duration distribution explicitly modelled distribution positive integers. direct numerical maximum likelhood estimation, HSMMs can represented HMMs enlarged state space (size \\(M\\)) structured transition probabilities. function designed used automatic differentiation based R package RTMB. slow without !","code":""},{"path":"https://janoleko.github.io/reference/forward_hsmm.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Forward algorithm for homogeneous hidden semi-Markov models — forward_hsmm","text":"Langrock, R., & Zucchini, W. (2011). Hidden Markov models arbitrary state dwell-time distributions. Computational Statistics & Data Analysis, 55(1), 715-724. Koslik, J. O. (2025). Hidden semi-Markov models inhomogeneous state dwell-time distributions. Computational Statistics & Data Analysis, 209, 108171.","code":""},{"path":[]},{"path":"https://janoleko.github.io/reference/forward_hsmm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Forward algorithm for homogeneous hidden semi-Markov models — forward_hsmm","text":"","code":"# currently no examples"},{"path":"https://janoleko.github.io/reference/forward_ihsmm.html","id":null,"dir":"Reference","previous_headings":"","what":"Forward algorithm for hidden semi-Markov models with inhomogeneous state durations and/ or conditional transition probabilities — forward_ihsmm","title":"Forward algorithm for hidden semi-Markov models with inhomogeneous state durations and/ or conditional transition probabilities — forward_ihsmm","text":"Calculates (approximate) log-likelihood sequence observations inhomogeneous hidden semi-Markov model using modified forward algorithm.","code":""},{"path":"https://janoleko.github.io/reference/forward_ihsmm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Forward algorithm for hidden semi-Markov models with inhomogeneous state durations and/ or conditional transition probabilities — forward_ihsmm","text":"","code":"forward_ihsmm(   dm,   omega,   allprobs,   trackID = NULL,   delta = NULL,   startInd = NULL,   eps = 1e-10,   report = TRUE )"},{"path":"https://janoleko.github.io/reference/forward_ihsmm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Forward algorithm for hidden semi-Markov models with inhomogeneous state durations and/ or conditional transition probabilities — forward_ihsmm","text":"dm list length N containing matrices (vectors) dwell-time probability mass functions (PMFs) state. dwell-time PMFs constant, vectors PMF dwell-time distribution fixed time. vector lengths correspond approximating state aggregate sizes, hence little probablity mass covered . dwell-time PMFs inhomogeneous, matrices need n rows, n number observations. number columns correponds size approximating state aggregates. latter case, first max(sapply(dm, ncol)) - 1 observations used first approximating transition probability matrix needs computed based first max(sapply(dm, ncol)) covariate values (represented dm). omega matrix dimension c(N,N) array dimension c(N,N,n) conditional transition probabilites, also called embedded transition probability matrix. contains transition probabilities given current state left. Hence, diagonal elements need zero rows need sum one. matrix can constructed using tpm_emb array using tpm_emb_g. allprobs matrix state-dependent probabilities/ density values dimension c(n, N) trackID trackID optional vector length n containing IDs provided, total log-likelihood sum track's likelihood contribution. Instead single vector delta corresponding initial distribution, delta matrix initial distributions, dimension c(k,N), can provided, track starts initial distribution. delta optional vector initial state probabilities length N default, instead , stationary distribution computed corresponding first approximating transition probability matrix track computed. Contrary homogeneous case, theoretically motivated just convenience. startInd optional integer index forward algorithm starts. approximating inhomogeneous HSMMs inhomogeneous HMMs, first transition probability matrix can constructed time max(sapply(dm, ncol)) (depends previous covariate values). Hence, provided, startInd chosen max(sapply(dm, ncol)). Fixing startInd value larger max(aggregate sizes) useful models different aggregate sizes fitted data supposed compared. case important models use number observations. eps small value avoid numerical issues approximating transition matrix construction. Usually, changed. report logical, indicating whether initial distribution, approximating transition probability matrix allprobs matrix reported fitted model. Defaults TRUE.","code":""},{"path":"https://janoleko.github.io/reference/forward_ihsmm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Forward algorithm for hidden semi-Markov models with inhomogeneous state durations and/ or conditional transition probabilities — forward_ihsmm","text":"log-likelihood given data parameters","code":""},{"path":"https://janoleko.github.io/reference/forward_ihsmm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Forward algorithm for hidden semi-Markov models with inhomogeneous state durations and/ or conditional transition probabilities — forward_ihsmm","text":"Hidden semi-Markov models (HSMMs) flexible extension HMMs, state duration distribution explicitly modelled distribution positive integers. function can used fit HSMMs state-duration distribution / conditional transition probabilities vary covariates. direct numerical maximum likelhood estimation, HSMMs can represented HMMs enlarged state space (size \\(M\\)) structured transition probabilities. function designed used automatic differentiation based R package RTMB. slow without !","code":""},{"path":"https://janoleko.github.io/reference/forward_ihsmm.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Forward algorithm for hidden semi-Markov models with inhomogeneous state durations and/ or conditional transition probabilities — forward_ihsmm","text":"Koslik, J. O. (2025). Hidden semi-Markov models inhomogeneous state dwell-time distributions. Computational Statistics & Data Analysis, 209, 108171.","code":""},{"path":[]},{"path":"https://janoleko.github.io/reference/forward_ihsmm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Forward algorithm for hidden semi-Markov models with inhomogeneous state durations and/ or conditional transition probabilities — forward_ihsmm","text":"","code":"# currently no examples"},{"path":"https://janoleko.github.io/reference/forward_p.html","id":null,"dir":"Reference","previous_headings":"","what":"Forward algorithm with for periodically varying transition probability matrices — forward_p","title":"Forward algorithm with for periodically varying transition probability matrices — forward_p","text":"Calculates log-likelihood sequence observations hidden Markov model periodically varying transition probabilities using forward algorithm.","code":""},{"path":"https://janoleko.github.io/reference/forward_p.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Forward algorithm with for periodically varying transition probability matrices — forward_p","text":"","code":"forward_p(   delta,   Gamma,   allprobs,   tod,   trackID = NULL,   ad = NULL,   report = TRUE,   logspace = FALSE )"},{"path":"https://janoleko.github.io/reference/forward_p.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Forward algorithm with for periodically varying transition probability matrices — forward_p","text":"delta initial stationary distribution length N, matrix dimension c(k,N) k independent tracks, trackID provided Gamma array transition probability matrices dimension c(N,N,L). use definition \\(\\Pr(S_t=j \\mid S_{t-1}=) = \\gamma_{ij}^{(t)}\\) transition probabilities time point \\(t-1\\) \\(t\\) element \\(\\Gamma^{(t)}\\). allprobs matrix state-dependent probabilities/ density values dimension c(n, N) tod (Integer valued) variable cycle indexing 1, ..., L, mapping data index generalised time day (length n) half-hourly data L = 48. , however, also day year daily data L = 365. trackID optional vector length n containing IDs provided, total log-likelihood sum track's likelihood contribution. Instead single vector delta corresponding initial distribution, delta matrix initial distributions dimension c(k,N), can provided, track starts initial distribution. ad optional logical, indicating whether automatic differentiation RTMB used. default, function determines . report logical, indicating whether delta, Gamma, allprobs, potentially trackID reported fitted model. Defaults TRUE, works ad = TRUE, uses RTMB package. Caution: multiple tracks, compatibility downstream functions like viterbi_p, stateprobs_p pseudo_res, forward_p called trackID argument. logspace logical, indicating whether probabilities/ densities allprobs matrix log-scale. , internal computations also done log-scale numerically robust entries small.","code":""},{"path":"https://janoleko.github.io/reference/forward_p.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Forward algorithm with for periodically varying transition probability matrices — forward_p","text":"log-likelihood given data parameters","code":""},{"path":"https://janoleko.github.io/reference/forward_p.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Forward algorithm with for periodically varying transition probability matrices — forward_p","text":"transition probability matrix varies periodically (e.g. function time day), \\(L\\) unique matrices \\(L\\) period length (e.g. \\(L=24\\) hourly data time--day variation). Thus, much efficient calculate \\(L\\) matrices index time variable (e.g. time day day year) instead calculating matrix index data set (redundant). function allows expecting transition probability matrix time point period integer valued (\\(1, \\dots, L\\)) time variable maps data index according time.","code":""},{"path":[]},{"path":"https://janoleko.github.io/reference/forward_p.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Forward algorithm with for periodically varying transition probability matrices — forward_p","text":"","code":"## negative log likelihood function nll = function(par, step, tod) {  # parameter transformations for unconstrained optimisation  beta = matrix(par[1:6], nrow = 2)  Gamma = tpm_p(1:24, beta = beta) # multinomial logit link for each time point  delta = stationary_p(Gamma, tod[1]) # stationary HMM  mu = exp(par[7:8])  sigma = exp(par[9:10])  # calculate all state-dependent probabilities  allprobs = matrix(1, length(step), 2)  ind = which(!is.na(step))  for(j in 1:2) allprobs[ind,j] = dgamma2(step[ind], mu[j], sigma[j])  # simple forward algorithm to calculate log-likelihood  -forward_p(delta, Gamma, allprobs, tod) }  ## fitting an HMM to the nessi data par = c(-2,-2,            # initial tpm intercepts (logit-scale)         rep(0, 4),        # initial tpm slopes         log(c(0.3, 2.5)), # initial means for step length (log-transformed)         log(c(0.2, 1.5))) # initial sds for step length (log-transformed) mod = nlm(nll, par, step = trex$step[1:500], tod = trex$tod[1:500])"},{"path":"https://janoleko.github.io/reference/forward_phsmm.html","id":null,"dir":"Reference","previous_headings":"","what":"Forward algorithm for hidden semi-Markov models with periodically inhomogeneous state durations and/ or conditional transition probabilities — forward_phsmm","title":"Forward algorithm for hidden semi-Markov models with periodically inhomogeneous state durations and/ or conditional transition probabilities — forward_phsmm","text":"Hidden semi-Markov models (HSMMs) flexible extension HMMs, state duration distribution explicitly modelled distribution positive integers. function can used fit HSMMs state-duration distribution / conditional transition probabilities vary covariates. direct numerical maximum likelhood estimation, HSMMs can represented HMMs enlarged state space (size \\(M\\)) structured transition probabilities. function can used fit HSMMs state-duration distribution / conditional transition probabilities vary periodically. special case periodic variation (compared arbitrary covariate influence), version preferred forward_ihsmm computes correct periodically stationary distribution observations lost approximation. function designed used automatic differentiation based R package RTMB. slow without !","code":""},{"path":"https://janoleko.github.io/reference/forward_phsmm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Forward algorithm for hidden semi-Markov models with periodically inhomogeneous state durations and/ or conditional transition probabilities — forward_phsmm","text":"","code":"forward_phsmm(   dm,   omega,   allprobs,   tod,   trackID = NULL,   delta = NULL,   eps = 1e-10,   report = TRUE )"},{"path":"https://janoleko.github.io/reference/forward_phsmm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Forward algorithm for hidden semi-Markov models with periodically inhomogeneous state durations and/ or conditional transition probabilities — forward_phsmm","text":"dm list length N containing matrices (vectors) dwell-time probability mass functions (PMFs) state. dwell-time PMFs constant, vectors PMF dwell-time distribution fixed time. vector lengths correspond approximating state aggregate sizes, hence little probablity mass covered . dwell-time PMFs inhomogeneous, matrices need L rows, L cycle length. number columns correpond size approximating state aggregates. omega matrix dimension c(N,N) array dimension c(N,N,L) conditional transition probabilites, also called embedded transition probability matrix contains transition probabilities given current state left. Hence, diagonal elements need zero rows need sum one. matrix can constructed using tpm_emb array using tpm_emb_g. allprobs matrix state-dependent probabilities/ density values dimension c(n, N) tod (Integer valued) variable cycle indexing 1, ..., L, mapping data index generalised time day (length n). half-hourly data L = 48. , however, also day year daily data L = 365. trackID optional vector length n containing IDs provided, total log-likelihood sum track's likelihood contribution. Instead single vector delta corresponding initial distribution, delta matrix initial distributions, dimension c(k,N), can provided, track starts initial distribution. delta Optional vector initial state probabilities length N. default, instead , stationary distribution computed corresponding first approximating t.p.m. track computed. Contrary homogeneous case, theoretically motivated just convenience. eps small value avoid numerical issues approximating transition matrix construction. Usually, changed. report logical, indicating whether initial distribution, approximating transition probability matrix allprobs matrix reported fitted model. Defaults TRUE.","code":""},{"path":"https://janoleko.github.io/reference/forward_phsmm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Forward algorithm for hidden semi-Markov models with periodically inhomogeneous state durations and/ or conditional transition probabilities — forward_phsmm","text":"log-likelihood given data parameters","code":""},{"path":"https://janoleko.github.io/reference/forward_phsmm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Forward algorithm for hidden semi-Markov models with periodically inhomogeneous state durations and/ or conditional transition probabilities — forward_phsmm","text":"Calculates (approximate) log-likelihood sequence observations periodically inhomogeneous hidden semi-Markov model using modified forward algorithm.","code":""},{"path":"https://janoleko.github.io/reference/forward_phsmm.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Forward algorithm for hidden semi-Markov models with periodically inhomogeneous state durations and/ or conditional transition probabilities — forward_phsmm","text":"Koslik, J. O. (2025). Hidden semi-Markov models inhomogeneous state dwell-time distributions. Computational Statistics & Data Analysis, 209, 108171.","code":""},{"path":[]},{"path":"https://janoleko.github.io/reference/forward_phsmm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Forward algorithm for hidden semi-Markov models with periodically inhomogeneous state durations and/ or conditional transition probabilities — forward_phsmm","text":"","code":"# currently no examples"},{"path":"https://janoleko.github.io/reference/forward_s.html","id":null,"dir":"Reference","previous_headings":"","what":"Forward algorithm for hidden semi-Markov models with homogeneous transition probability matrix — forward_s","title":"Forward algorithm for hidden semi-Markov models with homogeneous transition probability matrix — forward_s","text":"Hidden semi-Markov models (HSMMs) flexible extension HMMs can approximated HMMs enlarged state space (size \\(M\\)) structured transition probabilities.","code":""},{"path":"https://janoleko.github.io/reference/forward_s.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Forward algorithm for hidden semi-Markov models with homogeneous transition probability matrix — forward_s","text":"","code":"forward_s(delta, Gamma, allprobs, sizes)"},{"path":"https://janoleko.github.io/reference/forward_s.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Forward algorithm for hidden semi-Markov models with homogeneous transition probability matrix — forward_s","text":"delta initial stationary distribution length N, matrix dimension c(k,N) k independent tracks, trackID provided Gamma transition probability matrix dimension c(M,M) allprobs matrix state-dependent probabilities/ density values dimension c(n, N) automatically converted appropriate dimension. sizes state aggregate sizes used approximation semi-Markov chain.","code":""},{"path":"https://janoleko.github.io/reference/forward_s.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Forward algorithm for hidden semi-Markov models with homogeneous transition probability matrix — forward_s","text":"log-likelihood given data parameters","code":""},{"path":"https://janoleko.github.io/reference/forward_s.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Forward algorithm for hidden semi-Markov models with homogeneous transition probability matrix — forward_s","text":"","code":"## generating data from homogeneous 2-state HSMM mu = c(0, 6) lambda = c(6, 12) omega = matrix(c(0,1,1,0), nrow = 2, byrow = TRUE) # simulation # for a 2-state HSMM the embedded chain always alternates between 1 and 2 s = rep(1:2, 100) C = x = numeric(0) for(t in 1:100){   dt = rpois(1, lambda[s[t]])+1 # shifted Poisson   C = c(C, rep(s[t], dt))   x = c(x, rnorm(dt, mu[s[t]], 1.5)) # fixed sd 2 for both states }  ## negative log likelihood function mllk = function(theta.star, x, sizes){   # parameter transformations for unconstraint optimization   omega = matrix(c(0,1,1,0), nrow = 2, byrow = TRUE) # omega fixed (2-states)   lambda = exp(theta.star[1:2]) # dwell time means   dm = list(dpois(1:sizes[1]-1, lambda[1]), dpois(1:sizes[2]-1, lambda[2]))   Gamma = tpm_hsmm2(omega, dm)   delta = stationary(Gamma) # stationary   mu = theta.star[3:4]   sigma = exp(theta.star[5:6])   # calculate all state-dependent probabilities   allprobs = matrix(1, length(x), 2)   for(j in 1:2){ allprobs[,j] = dnorm(x, mu[j], sigma[j]) }   # return negative for minimization   -forward_s(delta, Gamma, allprobs, sizes) }  ## fitting an HSMM to the data theta.star = c(log(5), log(10), 1, 4, log(2), log(2)) mod = nlm(mllk, theta.star, x = x, sizes = c(20, 30), stepmax = 5)"},{"path":"https://janoleko.github.io/reference/forward_sp.html","id":null,"dir":"Reference","previous_headings":"","what":"Forward algorithm for hidden semi-Markov models with periodically varying transition probability matrices — forward_sp","title":"Forward algorithm for hidden semi-Markov models with periodically varying transition probability matrices — forward_sp","text":"Hidden semi-Markov models (HSMMs) flexible extension HMMs can approximated HMMs enlarged state space (size \\(M\\)) structured transition probabilities. Recently, inference procedure generalised allow either dwell-time distributions conditional transition probabilities depend external covariates time day. special case implemented . function allows , expecting transition probability matrix time point period, integer valued (\\(1, \\dots, L\\)) time variable maps data index according time.","code":""},{"path":"https://janoleko.github.io/reference/forward_sp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Forward algorithm for hidden semi-Markov models with periodically varying transition probability matrices — forward_sp","text":"","code":"forward_sp(delta, Gamma, allprobs, sizes, tod)"},{"path":"https://janoleko.github.io/reference/forward_sp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Forward algorithm for hidden semi-Markov models with periodically varying transition probability matrices — forward_sp","text":"delta initial stationary distribution length N, matrix dimension c(k,N) k independent tracks, trackID provided Gamma array transition probability matrices dimension c(M,M,L). use definition \\(\\Pr(S_t=j \\mid S_{t-1}=) = \\gamma_{ij}^{(t)}\\) transition probabilities time point \\(t-1\\) \\(t\\) element \\(\\Gamma^{(t)}\\). allprobs matrix state-dependent probabilities/ density values dimension c(n, N) automatically converted appropriate dimension. sizes state aggregate sizes used approximation semi-Markov chain. tod (Integer valued) variable cycle indexing 1, ..., L, mapping data index generalised time day (length n). half-hourly data L = 48. , however, also day year daily data L = 365.","code":""},{"path":"https://janoleko.github.io/reference/forward_sp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Forward algorithm for hidden semi-Markov models with periodically varying transition probability matrices — forward_sp","text":"log-likelihood given data parameters","code":""},{"path":"https://janoleko.github.io/reference/forward_sp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Forward algorithm for hidden semi-Markov models with periodically varying transition probability matrices — forward_sp","text":"","code":"## generating data from homogeneous 2-state HSMM mu = c(0, 6) beta = matrix(c(log(4),log(6),-0.2,0.2,-0.1,0.4), nrow=2) # time varying mean dwell time Lambda = exp(cbind(1, trigBasisExp(1:24, 24, 1))%*%t(beta)) omega = matrix(c(0,1,1,0), nrow = 2, byrow = TRUE) # simulation # for a 2-state HSMM the embedded chain always alternates between 1 and 2 s = rep(1:2, 100) C = x = numeric(0) tod = rep(1:24, 50) # time of day variable time = 1 for(t in 1:100){   dt = rpois(1, Lambda[tod[time], s[t]])+1 # dwell time depending on time of day   time = time + dt   C = c(C, rep(s[t], dt))   x = c(x, rnorm(dt, mu[s[t]], 1.5)) # fixed sd 2 for both states } tod = tod[1:length(x)]  ## negative log likelihood function mllk = function(theta.star, x, sizes, tod){   # parameter transformations for unconstraint optimization   omega = matrix(c(0,1,1,0), nrow = 2, byrow = TRUE) # omega fixed (2-states)   mu = theta.star[1:2]   sigma = exp(theta.star[3:4])   beta = matrix(theta.star[5:10], nrow=2)   # time varying mean dwell time   Lambda = exp(cbind(1, trigBasisExp(1:24, 24, 1))%*%t(beta))   dm = list()   for(j in 1:2){     dm[[j]] = sapply(1:sizes[j]-1, dpois, lambda = Lambda[,j])   }   Gamma = tpm_phsmm2(omega, dm)   delta = stationary_p(Gamma, tod[1])   # calculate all state-dependent probabilities   allprobs = matrix(1, length(x), 2)   for(j in 1:2){ allprobs[,j] = dnorm(x, mu[j], sigma[j]) }   # return negative for minimization   -forward_sp(delta, Gamma, allprobs, sizes, tod) }  ## fitting an HSMM to the data theta.star = c(1, 4, log(2), log(2), # state-dependent parameters                  log(4), log(6), rep(0,4)) # state process parameters dm # mod = nlm(mllk, theta.star, x = x, sizes = c(10, 15), tod = tod, stepmax = 5)"},{"path":"https://janoleko.github.io/reference/gamma2.html","id":null,"dir":"Reference","previous_headings":"","what":"Reparametrised gamma distribution — gamma2","title":"Reparametrised gamma distribution — gamma2","text":"Density, distribution function, quantile function random generation gamma distribution reparametrised terms mean standard deviation.","code":""},{"path":"https://janoleko.github.io/reference/gamma2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reparametrised gamma distribution — gamma2","text":"","code":"dgamma2(x, mean = 1, sd = 1, log = FALSE)  pgamma2(q, mean = 1, sd = 1, lower.tail = TRUE, log.p = FALSE)  qgamma2(p, mean = 1, sd = 1, lower.tail = TRUE, log.p = FALSE)  rgamma2(n, mean = 1, sd = 1)"},{"path":"https://janoleko.github.io/reference/gamma2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reparametrised gamma distribution — gamma2","text":"x, q vector quantiles mean mean parameter, must positive scalar. sd standard deviation parameter, must positive scalar. log, log.p logical; TRUE, probabilities/ densities \\(p\\) returned \\(\\log(p)\\). lower.tail logical; TRUE, probabilities \\(P[X <= x]\\), otherwise, \\(P[X > x]\\). p vector probabilities n number observations. length(n) > 1, length taken number required.","code":""},{"path":"https://janoleko.github.io/reference/gamma2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reparametrised gamma distribution — gamma2","text":"dgamma2 gives density, pgamma2 gives distribution function, qgamma2 gives quantile function, rgamma2 generates random deviates.","code":""},{"path":"https://janoleko.github.io/reference/gamma2.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Reparametrised gamma distribution — gamma2","text":"implementation allows automatic differentiation RTMB.","code":""},{"path":"https://janoleko.github.io/reference/gamma2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reparametrised gamma distribution — gamma2","text":"","code":"x = rgamma2(1) d = dgamma2(x) p = pgamma2(x) q = qgamma2(p)"},{"path":"https://janoleko.github.io/reference/gdeterminant.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes generalised determinant — gdeterminant","title":"Computes generalised determinant — gdeterminant","text":"Computes generalised determinant","code":""},{"path":"https://janoleko.github.io/reference/gdeterminant.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes generalised determinant — gdeterminant","text":"","code":"gdeterminant(x, eps = NULL, log = TRUE)"},{"path":"https://janoleko.github.io/reference/gdeterminant.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes generalised determinant — gdeterminant","text":"x symmetric matrix eps eigenvalues smaller treated zero log logical. TRUE, log-determinant returned. FALSE, determinant returned.","code":""},{"path":"https://janoleko.github.io/reference/gdeterminant.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes generalised determinant — gdeterminant","text":"generalised log-determinant x","code":""},{"path":"https://janoleko.github.io/reference/generator.html","id":null,"dir":"Reference","previous_headings":"","what":"Build the generator matrix of a continuous-time Markov chain — generator","title":"Build the generator matrix of a continuous-time Markov chain — generator","text":"function builds infinitesimal generator matrix continuous-time Markov chain unconstrained parameter vector.","code":""},{"path":"https://janoleko.github.io/reference/generator.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build the generator matrix of a continuous-time Markov chain — generator","text":"","code":"generator(param, byrow = FALSE, report = TRUE)"},{"path":"https://janoleko.github.io/reference/generator.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build the generator matrix of a continuous-time Markov chain — generator","text":"param unconstrained parameter vector length N*(N-1) N number states Markov chain byrow logical indicating transition probability matrix filled row report logical, indicating whether generator matrix Q reported fitted model. Defaults TRUE, works automatic differentiation RTMB used.","code":""},{"path":"https://janoleko.github.io/reference/generator.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build the generator matrix of a continuous-time Markov chain — generator","text":"infinitesimal generator matrix dimension c(N,N)","code":""},{"path":[]},{"path":"https://janoleko.github.io/reference/generator.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Build the generator matrix of a continuous-time Markov chain — generator","text":"","code":"# 2 states: 2 free off-diagonal elements generator(rep(-1, 2)) #>            S1         S2 #> S1 -0.3678794  0.3678794 #> S2  0.3678794 -0.3678794 # 3 states: 6 free off-diagonal elements generator(rep(-2, 6)) #>            S1         S2         S3 #> S1 -0.2706706  0.1353353  0.1353353 #> S2  0.1353353 -0.2706706  0.1353353 #> S3  0.1353353  0.1353353 -0.2706706"},{"path":"https://janoleko.github.io/reference/grapes-sp-grapes.html","id":null,"dir":"Reference","previous_headings":"","what":"Sparsity-retaining matrix multiplication — %sp%","title":"Sparsity-retaining matrix multiplication — %sp%","text":"Standard matrix multiplication destroys automatic sparsity detection RTMB essential models high-dimensional random effects. can mitigated changing \"plain\" TapeConfig, can make AD tape construction slow. , provide different version retains sparsity. may slightly slower standard method constructing AD tape.","code":""},{"path":"https://janoleko.github.io/reference/grapes-sp-grapes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sparsity-retaining matrix multiplication — %sp%","text":"","code":"A %sp% B"},{"path":"https://janoleko.github.io/reference/grapes-sp-grapes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sparsity-retaining matrix multiplication — %sp%","text":"matrix dimension n x p B matrix dimension p x m","code":""},{"path":"https://janoleko.github.io/reference/grapes-sp-grapes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sparsity-retaining matrix multiplication — %sp%","text":"matrix product B, dimension n x m","code":""},{"path":"https://janoleko.github.io/reference/grapes-sp-grapes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sparsity-retaining matrix multiplication — %sp%","text":"","code":"A <- matrix(1:6, nrow = 2, ncol = 3) B <- matrix(7:12, nrow = 3, ncol = 2) A %sp% B #>      [,1] [,2] #> [1,]   76  103 #> [2,]  100  136"},{"path":"https://janoleko.github.io/reference/logLik.qremlModel.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract log-likelihood from qremlModel object — logLik.qremlModel","title":"Extract log-likelihood from qremlModel object — logLik.qremlModel","text":"Extract log-likelihood qremlModel object","code":""},{"path":"https://janoleko.github.io/reference/logLik.qremlModel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract log-likelihood from qremlModel object — logLik.qremlModel","text":"","code":"# S3 method for class 'qremlModel' logLik(object, ...)"},{"path":"https://janoleko.github.io/reference/logLik.qremlModel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract log-likelihood from qremlModel object — logLik.qremlModel","text":"object fitted model class \"qremlModel\" ... Additional arguments (used)","code":""},{"path":"https://janoleko.github.io/reference/logLik.qremlModel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract log-likelihood from qremlModel object — logLik.qremlModel","text":"object class \"logLik\"","code":""},{"path":"https://janoleko.github.io/reference/make_matrices.html","id":null,"dir":"Reference","previous_headings":"","what":"Build the design and the penalty matrix for models involving penalised splines based on a formula and a data set — make_matrices","title":"Build the design and the penalty matrix for models involving penalised splines based on a formula and a data set — make_matrices","text":"Build design penalty matrix models involving penalised splines based formula data set","code":""},{"path":"https://janoleko.github.io/reference/make_matrices.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build the design and the penalty matrix for models involving penalised splines based on a formula and a data set — make_matrices","text":"","code":"make_matrices(formula, data, knots = NULL)"},{"path":"https://janoleko.github.io/reference/make_matrices.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build the design and the penalty matrix for models involving penalised splines based on a formula and a data set — make_matrices","text":"formula formula used mgcv. Formulas can right-side , contain response variable, just extracted naming. Can also list formulas, processed separately. case, named list right-side formulas list formulas response variables can provided. data data frame containing variables right side formula(s) knots optional list containing user specified knot values covariate used basis construction. bases user simply supplies knots used, must match k value supplied (note number knots always just k). See mgcv documentation details. formula list, needs named (based response variables) list lists.","code":""},{"path":"https://janoleko.github.io/reference/make_matrices.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build the design and the penalty matrix for models involving penalised splines based on a formula and a data set — make_matrices","text":"list class LaMa_matrices containing: Z design matrix (list matrices formula list)) S list penalty matrices (names based response terms formulas well smooth terms covariates). tensorproduct smooths, corresponding entries lists, containing \\(d\\) marginal penalty matrices \\(d\\) dimension tensor product) pardim list parameter dimensions (fixed penalised separately) formula, ease setting initial parameters coef list coefficient vectors filled zeros correct length formula, ease setting initial parameters data data frame used model(s) gam unfitted mgcv::gam object used construction Z S (list objects formula list) gam0 fitted mgcv::gam used internally create prediction design matrices (list objects formula list) knots knot list used basis construction (named list lists formula list","code":""},{"path":[]},{"path":"https://janoleko.github.io/reference/make_matrices.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Build the design and the penalty matrix for models involving penalised splines based on a formula and a data set — make_matrices","text":"","code":"data = data.frame(x = runif(100),                    y = runif(100),                   g = factor(rep(1:10, each = 10)))  # unvariate thin plate regression spline modmat = make_matrices(~ s(x), data) # univariate P-spline modmat = make_matrices(~ s(x, bs = \"ps\"), data) # adding random intercept modmat = make_matrices(~ s(g, bs = \"re\") + s(x, bs = \"ps\"), data) # tensorproduct of x and y modmat = make_matrices(~ s(x) + s(y) + ti(x,y), data) # multiple formulas at once modmat = make_matrices(list(mu ~ s(x) + y, sigma ~ s(g, bs = \"re\")), data = data)"},{"path":"https://janoleko.github.io/reference/make_matrices_dens.html","id":null,"dir":"Reference","previous_headings":"","what":"Build a standardised P-Spline design matrix and the associated P-Spline penalty matrix — make_matrices_dens","title":"Build a standardised P-Spline design matrix and the associated P-Spline penalty matrix — make_matrices_dens","text":"function builds B-spline design matrix given data vector. Importantly, B-spline basis functions normalised integral basis function 1, hence basis can used spline-based density estimation, basis functions weighted non-negative weights summing one.","code":""},{"path":"https://janoleko.github.io/reference/make_matrices_dens.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build a standardised P-Spline design matrix and the associated P-Spline penalty matrix — make_matrices_dens","text":"","code":"make_matrices_dens(   x,   k,   type = \"real\",   degree = 3,   knots = NULL,   diff_order = 2,   pow = 0.5,   npoints = 10000 )"},{"path":"https://janoleko.github.io/reference/make_matrices_dens.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build a standardised P-Spline design matrix and the associated P-Spline penalty matrix — make_matrices_dens","text":"x data vector k number basis functions type type data, either \"real\" data reals, \"positive\" data positive reals \"circular\" circular data like angles. degree degree B-spline basis functions, defaults cubic B-splines knots optional vector knots (including boundary knots) used basis construction. provided, knots placed equidistantly \"real\" \"circular\" using polynomial spacing \"positive\". \"real\" \"positive\" k - degree + 1 knots needed, \"circular\" k + 1 knots needed. # @param quantile logical, TRUE use quantile-based knot spacing (instead equidistant polynomial) diff_order order differencing used P-Spline penalty matrix data stream. Defaults second-order differences. pow power polynomial knot spacing npoints number points used numerical integration normalizing B-spline basis functions non-equidistant knot spacing used type = \"positive\".","code":""},{"path":"https://janoleko.github.io/reference/make_matrices_dens.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build a standardised P-Spline design matrix and the associated P-Spline penalty matrix — make_matrices_dens","text":"list containing design matrix Z, penalty matrix S, prediction design matrix Z_predict, prediction grid xseq, details basis expansion.","code":""},{"path":"https://janoleko.github.io/reference/make_matrices_dens.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Build a standardised P-Spline design matrix and the associated P-Spline penalty matrix — make_matrices_dens","text":"","code":"set.seed(1) # real-valued x <- rnorm(100) modmat <- make_matrices_dens(x, k = 20) #> Leaving out last column of the penalty matrix, fix the last spline coefficient at zero for identifiability! # positive-continuouos x <- rgamma2(100, mean = 5, sd = 2) modmat <- make_matrices_dens(x, k = 20, type = \"positive\") #> Leaving out last column of the penalty matrix, fix the last spline coefficient at zero for identifiability! # circular x <- rvm(100, mu = 0, kappa = 2) modmat <- make_matrices_dens(x, k = 20, type = \"circular\") #> Leaving out last column of the penalty matrix, fix the last spline coefficient at zero for identifiability! # bounded in an interval x <- rbeta(100, 1, 2) modmat <- make_matrices_dens(x, k = 20) #> Leaving out last column of the penalty matrix, fix the last spline coefficient at zero for identifiability!"},{"path":"https://janoleko.github.io/reference/make_matrices_old.html","id":null,"dir":"Reference","previous_headings":"","what":"Build the design and the penalty matrix for models involving penalised splines based on a formula and a data set — make_matrices_old","title":"Build the design and the penalty matrix for models involving penalised splines based on a formula and a data set — make_matrices_old","text":"Build design penalty matrix models involving penalised splines based formula data set","code":""},{"path":"https://janoleko.github.io/reference/make_matrices_old.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build the design and the penalty matrix for models involving penalised splines based on a formula and a data set — make_matrices_old","text":"","code":"make_matrices_old(formula, data, knots = NULL)"},{"path":"https://janoleko.github.io/reference/make_matrices_old.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build the design and the penalty matrix for models involving penalised splines based on a formula and a data set — make_matrices_old","text":"formula right side formula used mgcv data data frame containing variables formula knots optional list containing user specified knot values used basis construction bases user simply supplies knots used, must match k value supplied (note number knots always just k). See mgcv documentation details.","code":""},{"path":"https://janoleko.github.io/reference/make_matrices_old.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build the design and the penalty matrix for models involving penalised splines based on a formula and a data set — make_matrices_old","text":"list containing design matrix Z, (potentially nested) list penalty matrices S, formula, data, knots, original mod object returned mgcv. Note tensorproduct smooths, corresponding list entry list, containing d marginal penalty matrices d dimension tensor product.","code":""},{"path":"https://janoleko.github.io/reference/make_matrices_old.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Build the design and the penalty matrix for models involving penalised splines based on a formula and a data set — make_matrices_old","text":"","code":"data = data.frame(x = runif(100),                    y = runif(100),                   g = factor(rep(1:10, each = 10)))  # unvariate thin plate regression spline modmat = make_matrices(~ s(x), data) # univariate P-spline modmat = make_matrices(~ s(x, bs = \"ps\"), data) # adding random intercept modmat = make_matrices(~ s(g, bs = \"re\") + s(x, bs = \"ps\"), data) # tensorproduct of x and y modmat = make_matrices(~ s(x) + s(y) + ti(x,y), data)"},{"path":"https://janoleko.github.io/reference/minmax.html","id":null,"dir":"Reference","previous_headings":"","what":"AD-compatible minimum and maximum functions — minmax","title":"AD-compatible minimum and maximum functions — minmax","text":"functions compute parallel minimum/ maximum two vector-valued inputs compatible automatic differentiation using RTMB.","code":""},{"path":"https://janoleko.github.io/reference/minmax.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"AD-compatible minimum and maximum functions — minmax","text":"","code":"min2(x, y)  max2(x, y)"},{"path":"https://janoleko.github.io/reference/minmax.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"AD-compatible minimum and maximum functions — minmax","text":"x first vector y second vector","code":""},{"path":"https://janoleko.github.io/reference/minmax.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"AD-compatible minimum and maximum functions — minmax","text":"min2 returns parallel minimum max2 parallel maximum x y","code":""},{"path":"https://janoleko.github.io/reference/minmax.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"AD-compatible minimum and maximum functions — minmax","text":"","code":"x <- c(1, 4, 8, 2) y <- c(2, 5, 3, 7) min2(x, y) #> [1] 1 4 3 2 max2(x, y) #> [1] 2 5 8 7"},{"path":"https://janoleko.github.io/reference/minmax0_smooth.html","id":null,"dir":"Reference","previous_headings":"","what":"Smooth approximations to max(x, 0) and min(x, 0) — minmax0_smooth","title":"Smooth approximations to max(x, 0) and min(x, 0) — minmax0_smooth","text":"Smooth approximations max(x, 0) min(x, 0)","code":""},{"path":"https://janoleko.github.io/reference/minmax0_smooth.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Smooth approximations to max(x, 0) and min(x, 0) — minmax0_smooth","text":"","code":"max0_smooth(x, rho = 20)  min0_smooth(x, rho = 20)"},{"path":"https://janoleko.github.io/reference/minmax0_smooth.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Smooth approximations to max(x, 0) and min(x, 0) — minmax0_smooth","text":"x vector values rho smoothing parameter, larger values lead closer approximation","code":""},{"path":"https://janoleko.github.io/reference/minmax0_smooth.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Smooth approximations to max(x, 0) and min(x, 0) — minmax0_smooth","text":"approximate maximum minimum x 0","code":""},{"path":"https://janoleko.github.io/reference/minmax0_smooth.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Smooth approximations to max(x, 0) and min(x, 0) — minmax0_smooth","text":"","code":"x <- seq(-1, 1, by = 0.1) min0_smooth(x) #>  [1] -1.000000e+00 -9.000000e-01 -8.000000e-01 -7.000000e-01 -6.000003e-01 #>  [6] -5.000023e-01 -4.000168e-01 -3.001238e-01 -2.009075e-01 -1.063464e-01 #> [11] -3.465736e-02 -6.346401e-03 -9.074964e-04 -1.237843e-04 -1.677032e-05 #> [16] -2.269945e-06 -3.072097e-07 -4.157642e-08 -5.626758e-09 -7.614990e-10 #> [21] -1.030577e-10 max0_smooth(x) #>  [1] 1.030577e-10 7.614990e-10 5.626758e-09 4.157642e-08 3.072097e-07 #>  [6] 2.269945e-06 1.677032e-05 1.237843e-04 9.074964e-04 6.346401e-03 #> [11] 3.465736e-02 1.063464e-01 2.009075e-01 3.001238e-01 4.000168e-01 #> [16] 5.000023e-01 6.000003e-01 7.000000e-01 8.000000e-01 9.000000e-01 #> [21] 1.000000e+00"},{"path":"https://janoleko.github.io/reference/nessi.html","id":null,"dir":"Reference","previous_headings":"","what":"Loch Ness Monster Acceleration Data — nessi","title":"Loch Ness Monster Acceleration Data — nessi","text":"small group researchers managed put accelerometer Loch Ness Monster collected data days. Now data set overall dynamic body acceleration (ODBA) creature.","code":""},{"path":"https://janoleko.github.io/reference/nessi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Loch Ness Monster Acceleration Data — nessi","text":"","code":"nessi"},{"path":"https://janoleko.github.io/reference/nessi.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Loch Ness Monster Acceleration Data — nessi","text":"data frame 5.000 rows 3 variables: ODBA overall dynamci body acceleration logODBA logarithm overall dynamic body acceleration state hidden state variable","code":""},{"path":"https://janoleko.github.io/reference/nessi.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Loch Ness Monster Acceleration Data — nessi","text":"Generated example purposes.","code":""},{"path":"https://janoleko.github.io/reference/penalty.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes penalty based on quadratic form — penalty","title":"Computes penalty based on quadratic form — penalty","text":"function computes quadratic penalties form $$0.5 \\sum_{} \\lambda_i b_i^T S_i b_i,$$ smoothing parameters \\(\\lambda_i\\), coefficient vectors \\(b_i\\), fixed penalty matrices \\(S_i\\). intended used inside penalised negative log-likelihood function fitting models penalised splines simple random effects via quasi restricted maximum likelihood (qREML) qreml function. qreml work, likelihood function needs compatible RTMB R package enable automatic differentiation.","code":""},{"path":"https://janoleko.github.io/reference/penalty.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes penalty based on quadratic form — penalty","text":"","code":"penalty(re_coef, S, lambda)"},{"path":"https://janoleko.github.io/reference/penalty.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes penalty based on quadratic form — penalty","text":"re_coef coefficient vector/ matrix list coefficient vectors/ matrices list entry corresponds different smooth/ random effect associated penalty matrix S. several smooths/ random effects kind present, convenient pass matrix, row corresponds one smooth/ random effect. way rows can use penalty matrix. S fixed penalty matrix list penalty matrices matching structure re_coef also dimension individuals smooths/ random effects lambda penalty strength parameter vector length corresponding total number random effects/ spline coefficients re_coef E.g. re_coef contains one vector one matrix 4 rows, lambda needs length 5.","code":""},{"path":"https://janoleko.github.io/reference/penalty.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes penalty based on quadratic form — penalty","text":"returns penalty value reports qreml.","code":""},{"path":"https://janoleko.github.io/reference/penalty.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Computes penalty based on quadratic form — penalty","text":"Caution: formatting re_coef needs match structure parameter list penalised negative log-likelihood function, .e. two random effect vectors different names (different list elements parameter list), combine matrix inside likelihood pass matrix penalty. seperate random effects, name, need passed list penalty. Moreover, ordering re_coef needs match character vector random specified qreml.","code":""},{"path":"https://janoleko.github.io/reference/penalty.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Computes penalty based on quadratic form — penalty","text":"Koslik, J. O. (2024). Efficient smoothness selection nonparametric Markov-switching models via quasi restricted maximum likelihood. arXiv preprint arXiv:2411.11498.","code":""},{"path":[]},{"path":"https://janoleko.github.io/reference/penalty.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes penalty based on quadratic form — penalty","text":"","code":"# Example with a single random effect re = rep(0, 5) S = diag(5) lambda = 1 penalty(re, S, lambda) #> [1] 0  # Example with two random effects,  # where one element contains two random effects of similar structure re = list(matrix(0, 2, 5), rep(0, 4)) S = list(diag(5), diag(4)) lambda = c(1,1,2) # length = total number of random effects penalty(re, S, lambda) #> [1] 0  # Full model-fitting example data = trex[1:1000,] # subset  # initial parameter list par = list(logmu = log(c(0.3, 1)), # step mean            logsigma = log(c(0.2, 0.7)), # step sd            beta0 = c(-2,-2), # state process intercept            betaspline = matrix(rep(0, 18), nrow = 2)) # state process spline coefs            # data object with initial penalty strength lambda dat = list(step = data$step, # step length            tod = data$tod, # time of day covariate            N = 2, # number of states            lambda = rep(10,2)) # initial penalty strength  # building model matrices modmat = make_matrices(~ s(tod, bs = \"cp\"),                         data = data.frame(tod = 1:24),                         knots = list(tod = c(0,24))) # wrapping points dat$Z = modmat$Z # spline design matrix dat$S = modmat$S # penalty matrix  # penalised negative log-likelihood function pnll = function(par) {   getAll(par, dat) # makes everything contained available without $   Gamma = tpm_g(Z, cbind(beta0, betaspline)) # transition probabilities   delta = stationary_p(Gamma, t = 1) # initial distribution   mu = exp(logmu) # step mean   sigma = exp(logsigma) # step sd   # calculating all state-dependent densities   allprobs = matrix(1, nrow = length(step), ncol = N)   ind = which(!is.na(step)) # only for non-NA obs.   for(j in 1:N) allprobs[ind,j] = dgamma2(step[ind],mu[j],sigma[j])   -forward_g(delta, Gamma[,,tod], allprobs) +       penalty(betaspline, S, lambda) # this does all the penalization work }  # model fitting mod = qreml(pnll, par, dat, random = \"betaspline\") #> Creating AD function #> Performance tip: Consider running `TapeConfig(matmul = 'plain')` before `MakeADFun()` to speed up the forward algorithm. #> Initialising with lambda: 10 10  #> outer 1 - lambda: 5.545 5.001  #> outer 2 - lambda: 3.289 3.001  #> outer 3 - lambda: 2.081 2.091  #> outer 4 - lambda: 1.406 1.599  #> outer 5 - lambda: 1.018 1.293  #> outer 6 - lambda: 0.79 1.08  #> outer 7 - lambda: 0.654 0.92  #> outer 8 - lambda: 0.573 0.794  #> outer 9 - lambda: 0.525 0.69  #> outer 10 - lambda: 0.497 0.602  #> outer 11 - lambda: 0.48 0.526  #> outer 12 - lambda: 0.471 0.46  #> outer 13 - lambda: 0.467 0.403  #> outer 14 - lambda: 0.465 0.353  #> outer 15 - lambda: 0.465 0.31  #> outer 16 - lambda: 0.466 0.272  #> outer 17 - lambda: 0.467 0.24  #> outer 18 - lambda: 0.469 0.214  #> outer 19 - lambda: 0.472 0.191  #> outer 20 - lambda: 0.474 0.172  #> outer 21 - lambda: 0.476 0.157  #> outer 22 - lambda: 0.478 0.144  #> outer 23 - lambda: 0.48 0.134  #> outer 24 - lambda: 0.481 0.126  #> outer 25 - lambda: 0.483 0.119  #> outer 26 - lambda: 0.484 0.114  #> outer 27 - lambda: 0.485 0.109  #> outer 28 - lambda: 0.486 0.106  #> outer 29 - lambda: 0.487 0.103  #> outer 30 - lambda: 0.488 0.101  #> outer 31 - lambda: 0.488 0.099  #> outer 32 - lambda: 0.489 0.097  #> outer 33 - lambda: 0.489 0.096  #> outer 34 - lambda: 0.489 0.095  #> outer 35 - lambda: 0.49 0.094  #> outer 36 - lambda: 0.49 0.094  #> outer 37 - lambda: 0.49 0.093  #> outer 38 - lambda: 0.49 0.093  #> Converged #> Final model fit with lambda: 0.49 0.093"},{"path":"https://janoleko.github.io/reference/penalty2.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes generalised quadratic-form penalties — penalty2","title":"Computes generalised quadratic-form penalties — penalty2","text":"function computes quadratic penalty form $$0.5 \\sum_{} \\lambda_i b^T S_i b,$$ smoothing parameters \\(\\lambda_i\\), coefficient vector \\(b\\), fixed penalty matrices \\(S_i\\). generalises penalty allowing subsets coefficient vector  \\(b\\) penalised multiple times different smoothing parameters, necessary tensor products, functional random effects adaptive smoothing. intended used inside penalised negative log-likelihood function fitting models penalised splines simple random effects via quasi restricted maximum likelihood (qREML) qreml function. qreml work, likelihood function needs compatible RTMB R package enable automatic differentiation.","code":""},{"path":"https://janoleko.github.io/reference/penalty2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes generalised quadratic-form penalties — penalty2","text":"","code":"penalty2(re_coef, S, lambda)"},{"path":"https://janoleko.github.io/reference/penalty2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes generalised quadratic-form penalties — penalty2","text":"re_coef list coefficient vectors/ matrices list entry corresponds different smooth/ random effect associated penalty matrix penalty-matrix list S. several smooths/ random effects kind present, convenient pass matrix, row corresponds one smooth/ random effect. way rows can use penalty matrix. S list fixed penalty matrices matching structure re_coef. means re_coef length 3, S needs list length 3. entry needs either penalty matrix, matching dimension corresponding entry re_coef, list multiple penalty matrices tensor products. lambda penalty strength parameter vector length corresponding provided re_coef S. Specifically, entries one penalty matrix, nrow(re_coef[[]]) parameters needed. entries k penalty matrices, k * nrow(re_coef[[]]) parameters needed. E.g. re_coef[[1]] vector re_coef[[2]] matrix 4 rows, S[[1]] list length 2 S[[2]] matrix, lambda needs length 1 * 2 + 4 = 6.","code":""},{"path":"https://janoleko.github.io/reference/penalty2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes generalised quadratic-form penalties — penalty2","text":"returns penalty value reports qreml.","code":""},{"path":"https://janoleko.github.io/reference/penalty2.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Computes generalised quadratic-form penalties — penalty2","text":"Caution: formatting re_coef needs match structure parameter list penalised negative log-likelihood function, .e. two random effect vectors different names (different list elements parameter list), combine matrix inside likelihood pass matrix penalty. seperate random effects, name, need passed list penalty. Moreover, ordering re_coef needs match character vector random specified qreml.","code":""},{"path":[]},{"path":"https://janoleko.github.io/reference/penalty2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes generalised quadratic-form penalties — penalty2","text":"","code":"# Example with a single random effect re = rep(0, 5) S = diag(5) lambda = 1 penalty(re, S, lambda) #> [1] 0  # Example with two random effects,  # where one element contains two random effects of similar structure re = list(matrix(0, 2, 5), rep(0, 4)) S = list(diag(5), diag(4)) lambda = c(1,1,2) # length = total number of random effects penalty(re, S, lambda) #> [1] 0  # Full model-fitting example data = trex[1:1000,] # subset  # initial parameter list par = list(logmu = log(c(0.3, 1)), # step mean            logsigma = log(c(0.2, 0.7)), # step sd            beta0 = c(-2,-2), # state process intercept            betaspline = matrix(rep(0, 18), nrow = 2)) # state process spline coefs            # data object with initial penalty strength lambda dat = list(step = data$step, # step length            tod = data$tod, # time of day covariate            N = 2, # number of states            lambda = rep(10,2)) # initial penalty strength  # building model matrices modmat = make_matrices(~ s(tod, bs = \"cp\"),                         data = data.frame(tod = 1:24),                         knots = list(tod = c(0,24))) # wrapping points dat$Z = modmat$Z # spline design matrix dat$S = modmat$S # penalty matrix  # penalised negative log-likelihood function pnll = function(par) {   getAll(par, dat) # makes everything contained available without $   Gamma = tpm_g(Z, cbind(beta0, betaspline)) # transition probabilities   delta = stationary_p(Gamma, t = 1) # initial distribution   mu = exp(logmu) # step mean   sigma = exp(logsigma) # step sd   # calculating all state-dependent densities   allprobs = matrix(1, nrow = length(step), ncol = N)   ind = which(!is.na(step)) # only for non-NA obs.   for(j in 1:N) allprobs[ind,j] = dgamma2(step[ind],mu[j],sigma[j])   -forward_g(delta, Gamma[,,tod], allprobs) +       penalty(betaspline, S, lambda) # this does all the penalization work }  # model fitting mod = qreml(pnll, par, dat, random = \"betaspline\") #> Creating AD function #> Performance tip: Consider running `TapeConfig(matmul = 'plain')` before `MakeADFun()` to speed up the forward algorithm. #> Initialising with lambda: 10 10  #> outer 1 - lambda: 5.545 5.001  #> outer 2 - lambda: 3.289 3.001  #> outer 3 - lambda: 2.081 2.091  #> outer 4 - lambda: 1.406 1.599  #> outer 5 - lambda: 1.018 1.293  #> outer 6 - lambda: 0.79 1.08  #> outer 7 - lambda: 0.654 0.92  #> outer 8 - lambda: 0.573 0.794  #> outer 9 - lambda: 0.525 0.69  #> outer 10 - lambda: 0.497 0.602  #> outer 11 - lambda: 0.48 0.526  #> outer 12 - lambda: 0.471 0.46  #> outer 13 - lambda: 0.467 0.403  #> outer 14 - lambda: 0.465 0.353  #> outer 15 - lambda: 0.465 0.31  #> outer 16 - lambda: 0.466 0.272  #> outer 17 - lambda: 0.467 0.24  #> outer 18 - lambda: 0.469 0.214  #> outer 19 - lambda: 0.472 0.191  #> outer 20 - lambda: 0.474 0.172  #> outer 21 - lambda: 0.476 0.157  #> outer 22 - lambda: 0.478 0.144  #> outer 23 - lambda: 0.48 0.134  #> outer 24 - lambda: 0.481 0.126  #> outer 25 - lambda: 0.483 0.119  #> outer 26 - lambda: 0.484 0.114  #> outer 27 - lambda: 0.485 0.109  #> outer 28 - lambda: 0.486 0.106  #> outer 29 - lambda: 0.487 0.103  #> outer 30 - lambda: 0.488 0.101  #> outer 31 - lambda: 0.488 0.099  #> outer 32 - lambda: 0.489 0.097  #> outer 33 - lambda: 0.489 0.096  #> outer 34 - lambda: 0.489 0.095  #> outer 35 - lambda: 0.49 0.094  #> outer 36 - lambda: 0.49 0.094  #> outer 37 - lambda: 0.49 0.093  #> outer 38 - lambda: 0.49 0.093  #> Converged #> Final model fit with lambda: 0.49 0.093"},{"path":"https://janoleko.github.io/reference/penalty_uni.html","id":null,"dir":"Reference","previous_headings":"","what":"Penalty approximation of unimodality constraints for univariates smooths — penalty_uni","title":"Penalty approximation of unimodality constraints for univariates smooths — penalty_uni","text":"Penalty approximation unimodality constraints univariates smooths","code":""},{"path":"https://janoleko.github.io/reference/penalty_uni.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Penalty approximation of unimodality constraints for univariates smooths — penalty_uni","text":"","code":"penalty_uni(coef, m, kappa = 1000, concave = TRUE, rho = 20)"},{"path":"https://janoleko.github.io/reference/penalty_uni.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Penalty approximation of unimodality constraints for univariates smooths — penalty_uni","text":"coef coefficient vector matrix apply unimodality penalty m vector indices position coefficient mode. coef vector, must length 1. Otherwise, must length equal nrow(coef) kappa global scaling factor penalty concave logical; TRUE (default), penalty enforces increasing mode decreasing. coefficients decrease mode, increase, set concave = FALSE. rho control parameter smooth approximation min(x, 0) used internally. large values, gets closer true minimum function less stable.","code":""},{"path":"https://janoleko.github.io/reference/penalty_uni.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Penalty approximation of unimodality constraints for univariates smooths — penalty_uni","text":"numeric value penalty given coefficients","code":""},{"path":"https://janoleko.github.io/reference/penalty_uni.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Penalty approximation of unimodality constraints for univariates smooths — penalty_uni","text":"","code":"## coefficient vector coef <- c(1, 2, 3, 2, 1) # mode at position 3 penalty_uni(coef, m = 3) # basically zero #> [1] 5.152884e-07 #' # mode at position 2 penalty_uni(coef, m = 2) # large positive penalty #> [1] 1000  ## coefficient matrix coef <- rbind(coef, coef) m <- c(1, 4) penalty_uni(coef, m) #> [1] 3000"},{"path":"https://janoleko.github.io/reference/plot.LaMaResiduals.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot pseudo-residuals — plot.LaMaResiduals","title":"Plot pseudo-residuals — plot.LaMaResiduals","text":"Plot pseudo-residuals computed pseudo_res.","code":""},{"path":"https://janoleko.github.io/reference/plot.LaMaResiduals.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot pseudo-residuals — plot.LaMaResiduals","text":"","code":"# S3 method for class 'LaMaResiduals' plot(x, hist = TRUE, col = \"darkblue\", lwd = 1.5, main = NULL, ...)"},{"path":"https://janoleko.github.io/reference/plot.LaMaResiduals.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot pseudo-residuals — plot.LaMaResiduals","text":"x pseudo-residuals returned pseudo_res hist logical, TRUE, adds histogram pseudo-residuals col character, color QQ-line (density curve histogram = TRUE) lwd numeric, line width QQ-line (density curve histogram = TRUE) main optional character vector main titles plots length 2 (3 histogram = TRUE) ... currently ignored. method consistency","code":""},{"path":"https://janoleko.github.io/reference/plot.LaMaResiduals.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot pseudo-residuals — plot.LaMaResiduals","text":"NULL, plots pseudo-residuals 2- 3-panel layout","code":""},{"path":"https://janoleko.github.io/reference/plot.LaMaResiduals.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot pseudo-residuals — plot.LaMaResiduals","text":"","code":"## pseudo-residuals for the trex data step = trex$step[1:200]  nll = function(par){   getAll(par)   Gamma = tpm(logitGamma)   delta = stationary(Gamma)   mu = exp(logMu); REPORT(mu)   sigma = exp(logSigma); REPORT(sigma)   allprobs = matrix(1, length(step), 2)   ind = which(!is.na(step))   for(j in 1:2) allprobs[ind,j] = dgamma2(step[ind], mu[j], sigma[j])   -forward(delta, Gamma, allprobs) }  par = list(logitGamma = c(-2,-2),             logMu = log(c(0.3, 2.5)),             logSigma = log(c(0.3, 0.5)))             obj = MakeADFun(nll, par) #> Performance tip: Consider running `TapeConfig(matmul = 'plain')` before `MakeADFun()` to speed up the forward algorithm. opt = nlminb(obj$par, obj$fn, obj$gr) #> outer mgc:  336.5166  #> outer mgc:  20.97319  #> outer mgc:  34.15246  #> outer mgc:  19.14836  #> outer mgc:  22.89668  #> outer mgc:  14.22144  #> outer mgc:  16.43229  #> outer mgc:  8.153913  #> outer mgc:  6.812466  #> outer mgc:  9.6369  #> outer mgc:  12.03652  #> outer mgc:  3.217212  #> outer mgc:  3.933861  #> outer mgc:  3.111364  #> outer mgc:  2.511187  #> outer mgc:  3.259669  #> outer mgc:  1.203184  #> outer mgc:  0.9612578  #> outer mgc:  1.247134  #> outer mgc:  1.783606  #> outer mgc:  1.46798  #> outer mgc:  0.7872239  #> outer mgc:  0.06505949  #> outer mgc:  0.1913509  #> outer mgc:  0.06904775  #> outer mgc:  0.1037367  #> outer mgc:  0.01007877  #> outer mgc:  0.002057907  #> outer mgc:  0.0002424967   mod = obj$report()  pres = pseudo_res(step, \"gamma2\", list(mean = mod$mu, sd = mod$sigma),                   mod = mod)                    plot(pres)  plot(pres, hist = TRUE)"},{"path":"https://janoleko.github.io/reference/pred_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Build the prediction design matrix based on new data and model_matrices object created by make_matrices — pred_matrix","title":"Build the prediction design matrix based on new data and model_matrices object created by make_matrices — pred_matrix","text":"Build prediction design matrix based new data model_matrices object created make_matrices","code":""},{"path":"https://janoleko.github.io/reference/pred_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build the prediction design matrix based on new data and model_matrices object created by make_matrices — pred_matrix","text":"","code":"pred_matrix(model_matrices, newdata, what = NULL, exclude = NULL)"},{"path":"https://janoleko.github.io/reference/pred_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build the prediction design matrix based on new data and model_matrices object created by make_matrices — pred_matrix","text":"model_matrices model_matrices object returned make_matrices newdata data frame containing variables formula new data evaluate basis optional character string specifying formula use prediction, object contains multiple formulas. NULL, first formula used. exclude optional vector terms set zero predicted design matrix. Useful predicting main effects e.g. sd(..., bs = \"re\") terms present. See mgcv::predict.gam details.","code":""},{"path":"https://janoleko.github.io/reference/pred_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build the prediction design matrix based on new data and model_matrices object created by make_matrices — pred_matrix","text":"prediction design matrix newdata basis used model_matrices","code":""},{"path":"https://janoleko.github.io/reference/pred_matrix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Build the prediction design matrix based on new data and model_matrices object created by make_matrices — pred_matrix","text":"","code":"# single formula modmat = make_matrices(~ s(x), data.frame(x = 1:10)) Z_p = pred_matrix(modmat, data.frame(x = 1:10 - 0.5)) # with multiple formulas modmat = make_matrices(list(mu ~ s(x), sigma ~ s(x, bs = \"ps\")), data = data.frame(x = 1:10)) Z_p = pred_matrix(modmat, data.frame(x = 1:10 - 0.5), what = \"mu\") # nested formula list form = list(stream1 = list(mu ~ s(x), sigma ~ s(x, bs = \"ps\"))) modmat = make_matrices(form, data = data.frame(x = 1:10)) Z_p = pred_matrix(modmat, data.frame(x = 1:10 - 0.5), what = c(\"stream1\", \"mu\"))"},{"path":"https://janoleko.github.io/reference/predict.LaMa_matrices.html","id":null,"dir":"Reference","previous_headings":"","what":"Build the prediction design matrix based on new data and model_matrices object created by make_matrices — predict.LaMa_matrices","title":"Build the prediction design matrix based on new data and model_matrices object created by make_matrices — predict.LaMa_matrices","text":"Build prediction design matrix based new data model_matrices object created make_matrices","code":""},{"path":"https://janoleko.github.io/reference/predict.LaMa_matrices.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build the prediction design matrix based on new data and model_matrices object created by make_matrices — predict.LaMa_matrices","text":"","code":"# S3 method for class 'LaMa_matrices' predict(object, newdata, what = NULL, ...)"},{"path":"https://janoleko.github.io/reference/predict.LaMa_matrices.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build the prediction design matrix based on new data and model_matrices object created by make_matrices — predict.LaMa_matrices","text":"object model matrices object returned make_matrices newdata data frame containing variables formula new data evaluate basis optional character string specifying formula use prediction, object contains multiple formulas. NULL, first formula used. ... needs newdata data frame containing variables formula new data evaluate basis","code":""},{"path":"https://janoleko.github.io/reference/predict.LaMa_matrices.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build the prediction design matrix based on new data and model_matrices object created by make_matrices — predict.LaMa_matrices","text":"prediction design matrix newdata basis used model_matrices","code":""},{"path":[]},{"path":"https://janoleko.github.io/reference/predict.LaMa_matrices.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Build the prediction design matrix based on new data and model_matrices object created by make_matrices — predict.LaMa_matrices","text":"","code":"# single formula modmat = make_matrices(~ s(x), data.frame(x = 1:10)) Z_p = predict(modmat, data.frame(x = 1:10 - 0.5)) # with multiple formulas modmat = make_matrices(list(mu ~ s(x), sigma ~ s(x, bs = \"ps\")), data = data.frame(x = 1:10)) Z_p = predict(modmat, data.frame(x = 1:10 - 0.5), what = \"mu\") # nested formula list form = list(stream1 = list(mu ~ s(x), sigma ~ s(x, bs = \"ps\"))) modmat = make_matrices(form, data = data.frame(x = 1:10)) Z_p = predict(modmat, data.frame(x = 1:10 - 0.5), what = c(\"stream1\", \"mu\"))"},{"path":"https://janoleko.github.io/reference/process_hid_formulas.html","id":null,"dir":"Reference","previous_headings":"","what":"Process and standardise formulas for the state process of hidden Markov models — process_hid_formulas","title":"Process and standardise formulas for the state process of hidden Markov models — process_hid_formulas","text":"Process standardise formulas state process hidden Markov models","code":""},{"path":"https://janoleko.github.io/reference/process_hid_formulas.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process and standardise formulas for the state process of hidden Markov models — process_hid_formulas","text":"","code":"process_hid_formulas(formulas, nStates, ref = NULL)"},{"path":"https://janoleko.github.io/reference/process_hid_formulas.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process and standardise formulas for the state process of hidden Markov models — process_hid_formulas","text":"formulas formulas transition process hidden Markov model, either single formula, list formulas, matrix. nStates number states Markov chain ref optional vector reference categories state, defaults 1:nStates. provided, must length nStates contain valid state indices. formula matrix provided, specified reference categries specified one \".\" entry row.","code":""},{"path":"https://janoleko.github.io/reference/process_hid_formulas.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process and standardise formulas for the state process of hidden Markov models — process_hid_formulas","text":"named list formulas length nStates * (nStates - 1), formula corresponds transition state \\(\\) state \\(j\\), excluding transitions ref[].","code":""},{"path":"https://janoleko.github.io/reference/process_hid_formulas.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process and standardise formulas for the state process of hidden Markov models — process_hid_formulas","text":"","code":"# single formula for all non-reference category elements formulas = process_hid_formulas(~ s(x), nStates = 3) # now a list of length 6 with names tr.ij, not including reference categories  # different reference categories formulas = process_hid_formulas(~ s(x), nStates = 3, ref = c(1,1,1))  # different formulas for different entries (and only for 2 of 6) formulas = list(tr.12 ~ s(x), tr.23 ~ s(y)) formulas = process_hid_formulas(formulas, nStates = 3, ref = c(1,1,1)) # also a list of length 6, remaining entries filled with tr.ij ~ 1  # matrix input with reference categories formulas = matrix(c(\".\", \"~ s(x)\", \"~ s(y)\",                     \"~ g\", \".\", \"~ I(x^2)\",                     \"~ y\", \"~ 1\", \".\"),                      nrow = 3, byrow = TRUE) # dots define reference categories formulas = process_hid_formulas(formulas, nStates = 3)"},{"path":"https://janoleko.github.io/reference/pseudo_res.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate pseudo-residuals — pseudo_res","title":"Calculate pseudo-residuals — pseudo_res","text":"HMMs, pseudo-residuals used assess goodness--fit model. based cumulative distribution function (CDF) $$F_{X_t}(x_t) = F(x_t \\mid x_1, \\dots, x_{t-1}, x_{t+1}, \\dots, x_T)$$ can used quantify whether observation extreme relative model-implied distribution. function calculates residuals via probability integral transform, based local state probabilities obtained stateprobs stateprobs_g respective parametric family.","code":""},{"path":"https://janoleko.github.io/reference/pseudo_res.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate pseudo-residuals — pseudo_res","text":"","code":"pseudo_res(   obs,   dist,   par,   stateprobs = NULL,   mod = NULL,   normal = TRUE,   discrete = NULL,   randomise = TRUE,   seed = NULL )"},{"path":"https://janoleko.github.io/reference/pseudo_res.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate pseudo-residuals — pseudo_res","text":"obs vector continuous-valued observations (length n) dist character string specifying parametric CDF use (e.g., \"norm\" normal \"pois\" Poisson) CDF function evaluate directly. discrete CDF passed, discrete argument needs set TRUE determined automatically. par named parameter list parametric CDF Names need correspond parameter names specified distribution (e.g. list(mean = c(1,2), sd = c(1,1)) normal distribution 2 states). argument flexible parametric distribution allows. example can matrix parameters one row observation one column state. stateprobs matrix local state probabilities observation (dimension c(n,N), N number states) computed stateprobs, stateprobs_g stateprobs_p mod optional model object containing initial distribution delta, transition probability matrix Gamma, matrix state-dependent probabilities allprobs, potentially trackID variable using automatic differentiation either RTMB::MakeADFun qreml include forward, forward_g forward_p likelihood function, objects needed state decoding automatically reported model fitting. Hence, can pass model object obtained running RTMB::report() qreml directly function avoid calculating local state proabilities manually. case, call look like pseudo_res(obs, \"norm\", par, mod = mod). normal logical, TRUE, returns Gaussian pseudo residuals approximately standard normally distributed model correct. discrete logical, TRUE, computes discrete pseudo residuals (slightly differ definition) default, determined using dist argument, works standard discrete distributions. used special discrete distribution, set TRUE manually. See pseudo_res_discrete details. randomise discrete pseudo residuals . Logical, TRUE, return randomised pseudo residuals. Recommended discrete observations. seed discrete pseudo residuals . Integer, seed random number generation","code":""},{"path":"https://janoleko.github.io/reference/pseudo_res.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate pseudo-residuals — pseudo_res","text":"vector pseudo residuals","code":""},{"path":"https://janoleko.github.io/reference/pseudo_res.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate pseudo-residuals — pseudo_res","text":"used discrete pseudo-residuals, function just wrapper pseudo_res_discrete.","code":""},{"path":[]},{"path":"https://janoleko.github.io/reference/pseudo_res.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate pseudo-residuals — pseudo_res","text":"","code":"## continuous-valued observations obs = rnorm(100) stateprobs = matrix(0.5, nrow = 100, ncol = 2) par = list(mean = c(1,2), sd = c(1,1)) pres = pseudo_res(obs, \"norm\", par, stateprobs)  ## discrete-valued observations obs = rpois(100, lambda = 1) par = list(lambda = c(1,2)) pres = pseudo_res(obs, \"pois\", par, stateprobs) #> Calculating discrete pseudo-residuals #> Randomised between lower and upper  ## custom CDF function obs = rnbinom(100, size = 1, prob = 0.5) par = list(size = c(0.5, 2), prob = c(0.4, 0.6)) pres = pseudo_res(obs, pnbinom, par, stateprobs,                    discrete = TRUE) #> Calculating discrete pseudo-residuals #> Randomised between lower and upper # if discrete CDF function is passed, 'discrete' needs to be set to TRUE  ## no CDF available, only density (artificial example) obs = rnorm(100) par = list(mean = c(1,2), sd = c(1,1)) cdf = function(x, mean, sd) integrate(dnorm, -Inf, x, mean = mean, sd = sd)$value pres = pseudo_res(obs, cdf, par, stateprobs) #> Assuming 'dist' evaluates a continuous CDF. If discrete, please set 'discrete = TRUE'.  ## full example with model object step = trex$step[1:200]  nll = function(par){   getAll(par)   Gamma = tpm(logitGamma)   delta = stationary(Gamma)   mu = exp(logMu); REPORT(mu)   sigma = exp(logSigma); REPORT(sigma)   allprobs = matrix(1, length(step), 2)   ind = which(!is.na(step))   for(j in 1:2) allprobs[ind,j] = dgamma2(step[ind], mu[j], sigma[j])   -forward(delta, Gamma, allprobs) }  par = list(logitGamma = c(-2,-2),             logMu = log(c(0.3, 2.5)),             logSigma = log(c(0.3, 0.5)))             obj = MakeADFun(nll, par) #> Performance tip: Consider running `TapeConfig(matmul = 'plain')` before `MakeADFun()` to speed up the forward algorithm. opt = nlminb(obj$par, obj$fn, obj$gr) #> outer mgc:  336.5166  #> outer mgc:  20.97319  #> outer mgc:  34.15246  #> outer mgc:  19.14836  #> outer mgc:  22.89668  #> outer mgc:  14.22144  #> outer mgc:  16.43229  #> outer mgc:  8.153913  #> outer mgc:  6.812466  #> outer mgc:  9.6369  #> outer mgc:  12.03652  #> outer mgc:  3.217212  #> outer mgc:  3.933861  #> outer mgc:  3.111364  #> outer mgc:  2.511187  #> outer mgc:  3.259669  #> outer mgc:  1.203184  #> outer mgc:  0.9612578  #> outer mgc:  1.247134  #> outer mgc:  1.783606  #> outer mgc:  1.46798  #> outer mgc:  0.7872239  #> outer mgc:  0.06505949  #> outer mgc:  0.1913509  #> outer mgc:  0.06904775  #> outer mgc:  0.1037367  #> outer mgc:  0.01007877  #> outer mgc:  0.002057907  #> outer mgc:  0.0002424967   mod = obj$report()  pres = pseudo_res(step, \"gamma2\", list(mean = mod$mu, sd = mod$sigma),                   mod = mod)  plot(pres)"},{"path":"https://janoleko.github.io/reference/pseudo_res_discrete.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate pseudo-residuals for discrete-valued observations — pseudo_res_discrete","title":"Calculate pseudo-residuals for discrete-valued observations — pseudo_res_discrete","text":"HMMs, pseudo-residuals used assess goodness--fit model. based cumulative distribution function (CDF) $$F_{X_t}(x_t) = F(x_t \\mid x_1, \\dots, x_{t-1}, x_{t+1}, \\dots, x_T)$$ can used quantify whether observation extreme relative model-implied distribution. function calculates residuals discrete-valued observations, based local state probabilities obtained stateprobs stateprobs_g respective parametric family.","code":""},{"path":"https://janoleko.github.io/reference/pseudo_res_discrete.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate pseudo-residuals for discrete-valued observations — pseudo_res_discrete","text":"","code":"pseudo_res_discrete(   obs,   dist,   par,   stateprobs,   normal = TRUE,   randomise = TRUE,   seed = NULL )"},{"path":"https://janoleko.github.io/reference/pseudo_res_discrete.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate pseudo-residuals for discrete-valued observations — pseudo_res_discrete","text":"obs vector discrete-valued observations (length n) dist character string specifying parametric CDF use (e.g., \"norm\" normal \"pois\" Poisson) CDF function evaluate directly. par named parameter list parametric CDF Names need correspond parameter names specified distribution (e.g. list(mean = c(1,2), sd = c(1,1)) normal distribution 2 states). argument flexible parametric distribution allows. example can matrix parameters one row observation one column state. stateprobs matrix local state probabilities observation (dimension c(n,N), N number states) normal logical, TRUE, returns Gaussian pseudo residuals approximately standard normally distributed model correct. randomise logical, TRUE, return randomised pseudo residuals. Recommended discrete observations. seed integer, seed random number generation","code":""},{"path":"https://janoleko.github.io/reference/pseudo_res_discrete.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate pseudo-residuals for discrete-valued observations — pseudo_res_discrete","text":"vector pseudo residuals","code":""},{"path":"https://janoleko.github.io/reference/pseudo_res_discrete.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate pseudo-residuals for discrete-valued observations — pseudo_res_discrete","text":"discrete observations, calculating pseudo residuals slightly involved, CDF step function. Therefore, one can calculate lower upper CDF values observation. default, function exactly randomly samples interval give approximately Gaussian psuedo-residuals. randomise set FALSE, lower, upper mean pseudo-residuasl returned.","code":""},{"path":"https://janoleko.github.io/reference/pseudo_res_discrete.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate pseudo-residuals for discrete-valued observations — pseudo_res_discrete","text":"","code":"obs = rpois(100, lambda = 1) stateprobs = matrix(0.5, nrow = 100, ncol = 2) par = list(lambda = c(1,2)) pres = pseudo_res_discrete(obs, \"pois\", par, stateprobs) #> Randomised between lower and upper"},{"path":"https://janoleko.github.io/reference/qreml.html","id":null,"dir":"Reference","previous_headings":"","what":"Quasi restricted maximum likelihood (qREML) algorithm for models with penalised splines or simple i.i.d. random effects — qreml","title":"Quasi restricted maximum likelihood (qREML) algorithm for models with penalised splines or simple i.i.d. random effects — qreml","text":"algorithm can used flexibly fit statistical models involve penalised splines simple ..d. random effects, .e. penalties form $$0.5 \\sum_{} \\lambda_i b_i^T S_i b_i,$$ smoothing parameters \\(\\lambda_i\\), coefficient vectors \\(b_i\\), fixed penalty matrices \\(S_i\\). qREML algorithm typically much faster REML marginal ML using full Laplace approximation method, may slightly less accurate regarding estimation penalty strength parameters. hood, qreml uses R package RTMB automatic differentiation inner optimisation. user specify penalised negative log-likelihood function pnll structured dictated RTMB use penalty function compute quadratic-form penalty inside likelihood.","code":""},{"path":"https://janoleko.github.io/reference/qreml.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Quasi restricted maximum likelihood (qREML) algorithm for models with penalised splines or simple i.i.d. random effects — qreml","text":"","code":"qreml(   pnll,   par,   dat,   random,   map = NULL,   silent = 1,   psname = \"lambda\",   alpha = 0.3,   smoothing = 1,   maxiter = 100,   tol = 1e-04,   method = \"BFGS\",   control = list(),   conv_crit = \"relchange\",   spHess = FALSE,   joint_unc = FALSE,   saveall = FALSE )"},{"path":"https://janoleko.github.io/reference/qreml.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Quasi restricted maximum likelihood (qREML) algorithm for models with penalised splines or simple i.i.d. random effects — qreml","text":"pnll penalised negative log-likelihood function structured dictated RTMB uses penalty function LaMa compute penalty Needs function named list initial parameters par . par named list initial parameters random effects/ spline coefficients can vectors matrices, latter summarising several random effects structure, one row matrix. dat initial data list contains data used likelihood function, hyperparameters, initial penalty strength vector initial penalty strength vector called lambda, name dat needs specified using psname argument . length needs match total number random effects. random vector names random effects/ penalised parameters par Caution: ordering random needs match order random effects passed penalty inside likelihood function. map optional map argument, containing factor vectors indicate parameter sharing fixing. Needs named list subset fixed effect parameters penalty strength parameters. example, model four penalty strength parameters, map[[psname]] factor(c(NA, 1, 1, 2)) fix first penalty strength parameter, estimate second third jointly, estimate fourth separately. silent integer silencing level: 0 corresponds full printing inner outer iterations, 1 printing outer iterations , 2 printing. psname optional name given penalty strength parameter dat. Defaults \"lambda\". alpha optional hyperparamater exponential smoothing penalty strengths. larger values smoother convergence expected algorithm may need iterations. smoothing optional scaling factor final penalty strength parameters Increasing beyond one lead smoother final model. Can integer vector length equal length penalty strength parameter. maxiter maximum number iterations outer optimisation penalty strength parameters. tol Convergence tolerance penalty strength parameters. method optimisation method used optim. Defaults \"BFGS\", might changed \"L-BFGS-B\" high-dimensional settings. control list control parameters optim use inner optimisation. , optim uses BFGS method changed. advise changing default values reltol maxit can decrease accuracy Laplace approximation. conv_crit character, convergence criterion penalty strength parameters. Can \"relchange\" (default) \"gradient\". spHess logical, TRUE, sparse AD Hessian used outer iteration. Hessian large sparse (many cross derivatives 0), speed computations lot. Hessian dense, slow computations slightly might require significantly memory. joint_unc logical, TRUE, joint RTMB object returned allowing joint uncertainty quantification saveall logical, TRUE, model objects iteration saved final model object.","code":""},{"path":"https://janoleko.github.io/reference/qreml.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Quasi restricted maximum likelihood (qREML) algorithm for models with penalised splines or simple i.i.d. random effects — qreml","text":"model object class 'qremlModel'. list containing: ... everything reported inside pnll using RTMB::REPORT(). using forward, tpm_g, etc., may involve automatically reported objects. obj RTMB AD object containing final conditional model fit psname final penalty strength parameter vector all_psname list penalty strength parameter vectors iterations par named estimated parameter list structure initial par. Note name par fixed depends original name par list. relist_par function convert estimated parameter vector estimated parameter list. useful uncertainty quantification based sampling multivariate normal distribution. par_vec estimated parameter vector llk unpenalised log-likelihood optimum n_fixpar number fixed, .e. unpenalised, parameters edf overall effective number parameters all_edf list effective number parameters smooth Hessian_condtional final Hessian conditional penalised fit obj_joint joint_unc = TRUE, joint RTMB object joint uncertainty quantification model penalty parameters.","code":""},{"path":"https://janoleko.github.io/reference/qreml.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Quasi restricted maximum likelihood (qREML) algorithm for models with penalised splines or simple i.i.d. random effects — qreml","text":"Koslik, J. O. (2024). Efficient smoothness selection nonparametric Markov-switching models via quasi restricted maximum likelihood. arXiv preprint arXiv:2411.11498.","code":""},{"path":[]},{"path":"https://janoleko.github.io/reference/qreml.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Quasi restricted maximum likelihood (qREML) algorithm for models with penalised splines or simple i.i.d. random effects — qreml","text":"","code":"data = trex[1:1000,] # subset  # initial parameter list par = list(logmu = log(c(0.3, 1)), # step mean            logsigma = log(c(0.2, 0.7)), # step sd            beta0 = c(-2,-2), # state process intercept            betaspline = matrix(rep(0, 18), nrow = 2)) # state process spline coefs            # data object with initial penalty strength lambda dat = list(step = data$step, # step length            tod = data$tod, # time of day covariate            N = 2, # number of states            lambda = rep(10,2)) # initial penalty strength  # building model matrices modmat = make_matrices(~ s(tod, bs = \"cp\"),                         data = data.frame(tod = 1:24),                         knots = list(tod = c(0,24))) # wrapping points dat$Z = modmat$Z # spline design matrix dat$S = modmat$S # penalty matrix  # penalised negative log-likelihood function pnll = function(par) {   getAll(par, dat) # makes everything contained available without $   Gamma = tpm_g(Z, cbind(beta0, betaspline), ad = TRUE) # transition probabilities   delta = stationary_p(Gamma, t = 1, ad = TRUE) # initial distribution   mu = exp(logmu) # step mean   sigma = exp(logsigma) # step sd   # calculating all state-dependent densities   allprobs = matrix(1, nrow = length(step), ncol = N)   ind = which(!is.na(step)) # only for non-NA obs.   for(j in 1:N) allprobs[ind,j] = dgamma2(step[ind],mu[j],sigma[j])   -forward_g(delta, Gamma[,,tod], allprobs) +       penalty(betaspline, S, lambda) # this does all the penalization work }  # model fitting mod = qreml(pnll, par, dat, random = \"betaspline\") #> Creating AD function #> Performance tip: Consider running `TapeConfig(matmul = 'plain')` before `MakeADFun()` to speed up the forward algorithm. #> Initialising with lambda: 10 10  #> outer 1 - lambda: 5.545 5.001  #> outer 2 - lambda: 3.289 3.001  #> outer 3 - lambda: 2.081 2.091  #> outer 4 - lambda: 1.406 1.599  #> outer 5 - lambda: 1.018 1.293  #> outer 6 - lambda: 0.79 1.08  #> outer 7 - lambda: 0.654 0.92  #> outer 8 - lambda: 0.573 0.794  #> outer 9 - lambda: 0.525 0.69  #> outer 10 - lambda: 0.497 0.602  #> outer 11 - lambda: 0.48 0.526  #> outer 12 - lambda: 0.471 0.46  #> outer 13 - lambda: 0.467 0.403  #> outer 14 - lambda: 0.465 0.353  #> outer 15 - lambda: 0.465 0.31  #> outer 16 - lambda: 0.466 0.272  #> outer 17 - lambda: 0.467 0.24  #> outer 18 - lambda: 0.469 0.214  #> outer 19 - lambda: 0.472 0.191  #> outer 20 - lambda: 0.474 0.172  #> outer 21 - lambda: 0.476 0.157  #> outer 22 - lambda: 0.478 0.144  #> outer 23 - lambda: 0.48 0.134  #> outer 24 - lambda: 0.481 0.126  #> outer 25 - lambda: 0.483 0.119  #> outer 26 - lambda: 0.484 0.114  #> outer 27 - lambda: 0.485 0.109  #> outer 28 - lambda: 0.486 0.106  #> outer 29 - lambda: 0.487 0.103  #> outer 30 - lambda: 0.488 0.101  #> outer 31 - lambda: 0.488 0.099  #> outer 32 - lambda: 0.489 0.097  #> outer 33 - lambda: 0.489 0.096  #> outer 34 - lambda: 0.489 0.095  #> outer 35 - lambda: 0.49 0.094  #> outer 36 - lambda: 0.49 0.094  #> outer 37 - lambda: 0.49 0.093  #> outer 38 - lambda: 0.49 0.093  #> Converged #> Final model fit with lambda: 0.49 0.093"},{"path":"https://janoleko.github.io/reference/qreml_old.html","id":null,"dir":"Reference","previous_headings":"","what":"Quasi restricted maximum likelihood (qREML) algorithm for models with penalised splines or simple i.i.d. random effects — qreml_old","title":"Quasi restricted maximum likelihood (qREML) algorithm for models with penalised splines or simple i.i.d. random effects — qreml_old","text":"algorithm can used flexibly fit statistical models involve penalised splines simple ..d. random effects, .e. penalties form $$0.5 \\sum_{} \\lambda_i b_i^T S_i b_i,$$ smoothing parameters \\(\\lambda_i\\), coefficient vectors \\(b_i\\), fixed penalty matrices \\(S_i\\). qREML algorithm typically much faster REML marginal ML using full Laplace approximation method, may slightly less accurate regarding estimation penalty strength parameters. hood, qreml uses R package RTMB automatic differentiation inner optimisation. user specify penalised negative log-likelihood function pnll structured dictated RTMB use penalty function compute quadratic-form penalty inside likelihood.","code":""},{"path":"https://janoleko.github.io/reference/qreml_old.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Quasi restricted maximum likelihood (qREML) algorithm for models with penalised splines or simple i.i.d. random effects — qreml_old","text":"","code":"qreml_old(   pnll,   par,   dat,   random,   map = NULL,   psname = \"lambda\",   alpha = 0.25,   smoothing = 1,   maxiter = 100,   tol = 1e-04,   control = list(reltol = 1e-10, maxit = 1000),   silent = 1,   joint_unc = TRUE,   saveall = FALSE )"},{"path":"https://janoleko.github.io/reference/qreml_old.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Quasi restricted maximum likelihood (qREML) algorithm for models with penalised splines or simple i.i.d. random effects — qreml_old","text":"pnll penalised negative log-likelihood function structured dictated RTMB uses penalty function LaMa compute penalty Needs function named list initial parameters par . par named list initial parameters random effects/ spline coefficients can vectors matrices, latter summarising several random effects structure, one row matrix. dat initial data list contains data used likelihood function, hyperparameters, initial penalty strength vector initial penalty strength vector called lambda, name dat needs specified using psname argument . length needs match total number random effects. random vector names random effects/ penalised parameters par Caution: ordering random needs match order random effects passed penalty inside likelihood function. map optional map argument, containing factor vectors indicate parameter sharing fixing. Needs named list subset fixed effect parameters penalty strength parameters. example, model four penalty strength parameters, map[[psname]] factor(c(NA, 1, 1, 2)) fix first penalty strength parameter, estimate second third jointly, estimate fourth separately. psname optional name given penalty strength parameter dat. Defaults \"lambda\". alpha optional hyperparamater exponential smoothing penalty strengths. larger values smoother convergence expected algorithm may need iterations. smoothing optional scaling factor final penalty strength parameters Increasing beyond one lead smoother final model. Can integer vector length equal length penalty strength parameter. maxiter maximum number iterations outer optimisation penalty strength parameters. tol Convergence tolerance penalty strength parameters. control list control parameters optim use inner optimisation. , optim uses BFGS method changed. advise changing default values reltol maxit can decrease accuracy Laplace approximation. silent integer silencing level: 0 corresponds full printing inner outer iterations, 1 printing outer iterations , 2 printing. joint_unc logical, TRUE, joint RTMB object returned allowing joint uncertainty quantification saveall logical, TRUE, model objects iteration saved final model object. # @param epsilon vector two values specifying cycling detection parameters. relative change new penalty strength previous one larger epsilon[1] change one smaller epsilon[2], algorithm average two last values prevent cycling.","code":""},{"path":"https://janoleko.github.io/reference/qreml_old.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Quasi restricted maximum likelihood (qREML) algorithm for models with penalised splines or simple i.i.d. random effects — qreml_old","text":"model object class 'qremlModel'. list containing: ... everything reported inside pnll using RTMB::REPORT(). using forward, tpm_g, etc., may involve automatically reported objects. obj RTMB AD object containing final conditional model fit psname final penalty strength parameter vector all_psname list penalty strength parameter vectors iterations par named estimated parameter list structure initial par. Note name par fixed depends original name par list. relist_par function convert estimated parameter vector estimated parameter list. useful uncertainty quantification based sampling multivariate normal distribution. par_vec estimated parameter vector llk unpenalised log-likelihood optimum n_fixpar number fixed, .e. unpenalised, parameters edf overall effective number parameters all_edf list effective number parameters smooth Hessian_condtional final Hessian conditional penalised fit obj_joint joint_unc = TRUE, joint RTMB object joint uncertainty quantification model penalty parameters.","code":""},{"path":"https://janoleko.github.io/reference/qreml_old.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Quasi restricted maximum likelihood (qREML) algorithm for models with penalised splines or simple i.i.d. random effects — qreml_old","text":"Koslik, J. O. (2024). Efficient smoothness selection nonparametric Markov-switching models via quasi restricted maximum likelihood. arXiv preprint arXiv:2411.11498.","code":""},{"path":[]},{"path":"https://janoleko.github.io/reference/qreml_old.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Quasi restricted maximum likelihood (qREML) algorithm for models with penalised splines or simple i.i.d. random effects — qreml_old","text":"","code":"data = trex[1:1000,] # subset  # initial parameter list par = list(logmu = log(c(0.3, 1)), # step mean            logsigma = log(c(0.2, 0.7)), # step sd            beta0 = c(-2,-2), # state process intercept            betaspline = matrix(rep(0, 18), nrow = 2)) # state process spline coefs            # data object with initial penalty strength lambda dat = list(step = data$step, # step length            tod = data$tod, # time of day covariate            N = 2, # number of states            lambda = rep(100,2)) # initial penalty strength  # building model matrices modmat = make_matrices(~ s(tod, bs = \"cp\"),                         data = data.frame(tod = 1:24),                         knots = list(tod = c(0,24))) # wrapping points dat$Z = modmat$Z # spline design matrix dat$S = modmat$S # penalty matrix  # penalised negative log-likelihood function pnll = function(par) {   getAll(par, dat) # makes everything contained available without $   Gamma = tpm_g(Z, cbind(beta0, betaspline), ad = TRUE) # transition probabilities   delta = stationary_p(Gamma, t = 1, ad = TRUE) # initial distribution   mu = exp(logmu) # step mean   sigma = exp(logsigma) # step sd   # calculating all state-dependent densities   allprobs = matrix(1, nrow = length(step), ncol = N)   ind = which(!is.na(step)) # only for non-NA obs.   for(j in 1:N) allprobs[ind,j] = dgamma2(step[ind],mu[j],sigma[j])   -forward_g(delta, Gamma[,,tod], allprobs) +       penalty(betaspline, S, lambda) # this does all the penalization work }  # model fitting mod = qreml_old(pnll, par, dat, random = \"betaspline\") #> Creating AD function #> Performance tip: Consider running `TapeConfig(matmul = 'plain')` before `MakeADFun()` to speed up the forward algorithm. #> Initialising with lambda: 100 100  #> outer 1 - lambda: 35.133 31.57  #> outer 2 - lambda: 15.325 11.598  #> outer 3 - lambda: 7.633 5.172  #> outer 4 - lambda: 4.151 2.912  #> outer 5 - lambda: 2.443 1.975  #> outer 6 - lambda: 1.555 1.493  #> outer 7 - lambda: 1.074 1.197  #> outer 8 - lambda: 0.806 0.993  #> outer 9 - lambda: 0.655 0.841  #> outer 10 - lambda: 0.569 0.72  #> outer 11 - lambda: 0.52 0.621  #> outer 12 - lambda: 0.492 0.537  #> outer 13 - lambda: 0.477 0.464  #> outer 14 - lambda: 0.47 0.402  #> outer 15 - lambda: 0.467 0.349  #> outer 16 - lambda: 0.466 0.303  #> outer 17 - lambda: 0.467 0.264  #> outer 18 - lambda: 0.468 0.231  #> outer 19 - lambda: 0.47 0.204  #> outer 20 - lambda: 0.473 0.182  #> outer 21 - lambda: 0.475 0.163  #> outer 22 - lambda: 0.477 0.149  #> outer 23 - lambda: 0.479 0.137  #> outer 24 - lambda: 0.481 0.127  #> outer 25 - lambda: 0.483 0.12  #> outer 26 - lambda: 0.484 0.114  #> outer 27 - lambda: 0.485 0.109  #> outer 28 - lambda: 0.486 0.105  #> outer 29 - lambda: 0.487 0.102  #> outer 30 - lambda: 0.488 0.1  #> outer 31 - lambda: 0.488 0.098  #> outer 32 - lambda: 0.489 0.097  #> outer 33 - lambda: 0.489 0.096  #> outer 34 - lambda: 0.49 0.095  #> outer 35 - lambda: 0.49 0.094  #> outer 36 - lambda: 0.49 0.094  #> outer 37 - lambda: 0.49 0.093  #> outer 38 - lambda: 0.49 0.093  #> outer 39 - lambda: 0.49 0.092  #> outer 40 - lambda: 0.49 0.092  #> outer 41 - lambda: 0.49 0.092  #> outer 42 - lambda: 0.49 0.092  #> Converged #> Final model fit with lambda: 0.49 0.092  #> Performance tip: Consider running `TapeConfig(matmul = 'plain')` before `MakeADFun()` to speed up the forward algorithm."},{"path":"https://janoleko.github.io/reference/sdreportMC.html","id":null,"dir":"Reference","previous_headings":"","what":"Monte Carlo version of sdreport — sdreportMC","title":"Monte Carlo version of sdreport — sdreportMC","text":"optimisation AD model, sdreportMC can used calculate samples confidence intervals model parameters REPORT()ed quantities including nonlinear functions random effects parameters.","code":""},{"path":"https://janoleko.github.io/reference/sdreportMC.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Monte Carlo version of sdreport — sdreportMC","text":"","code":"sdreportMC(   obj,   what,   nSamples = 1000,   Hessian = NULL,   CI = FALSE,   probs = c(0.025, 0.975) )"},{"path":"https://janoleko.github.io/reference/sdreportMC.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Monte Carlo version of sdreport — sdreportMC","text":"obj object returned MakeADFun() optimisation model class qremlModel returned qreml. vector strings names parameters /REPORT()ed quantities reported nSamples number samples draw multivariate normal distribution MLE Hessian optional Hessian matrix. provided, computed object CI logical. TRUE, confidence intervals instead samples returned probs vector probabilities confidence intervals (ignored CIs computed)","code":""},{"path":"https://janoleko.github.io/reference/sdreportMC.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Monte Carlo version of sdreport — sdreportMC","text":"named list corresponding elements . element structure corresponding quantity additional dimension added samples. example, quantity vector, list contains matrix. quantity matrix, list contains array. quantity array, list contains array one extra dimension.","code":""},{"path":"https://janoleko.github.io/reference/sdreportMC.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Monte Carlo version of sdreport — sdreportMC","text":"function simply samples approximate multivariate normal distribution maximum likelihood estimate (MLE) parameters $$ \\hat{\\theta} \\sim N(\\theta, H^{-1}), $$ \\(H\\) Hessian matrix negative log-likelihood function MLE. returns either sampled parameters REPORT()ed transformations . CI = TRUE, return samples directly computes confidence intervals. interested several quantities, calling sdreportMC vector generally faster calling several times single elements .","code":""},{"path":"https://janoleko.github.io/reference/sdreportMC.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Monte Carlo version of sdreport — sdreportMC","text":"","code":"# fitting an HMM to the trex data and running sdreportMC ## negative log-likelihood function nll = function(par) {   getAll(par, dat) # makes everything contained available without $   Gamma = tpm(eta) # computes transition probability matrix from unconstrained eta   delta = stationary(Gamma) # computes stationary distribution   # exponentiating because all parameters strictly positive   mu = exp(logmu)   sigma = exp(logsigma)   kappa = exp(logkappa)   # reporting statements for sdreportMC   REPORT(mu)   REPORT(sigma)   REPORT(kappa)   # calculating all state-dependent densities   allprobs = matrix(1, nrow = length(step), ncol = N)   ind = which(!is.na(step) & !is.na(angle)) # only for non-NA obs.   for(j in 1:N){     allprobs[ind,j] = dgamma2(step[ind],mu[j],sigma[j])*dvm(angle[ind],0,kappa[j])   }   -forward(delta, Gamma, allprobs) # simple forward algorithm }  ## initial parameter list par = list(  logmu = log(c(0.3, 1)),       # initial means for step length (log-transformed)   logsigma = log(c(0.2, 0.7)), # initial sds for step length (log-transformed)   logkappa = log(c(0.2, 0.7)), # initial concentration for turning angle (log-transformed)   eta = rep(-2, 2)             # initial t.p.m. parameters (on logit scale) )    ## data and hyperparameters dat = list(   step = trex$step[1:500],   # hourly step lengths   angle = trex$angle[1:500], # hourly turning angles   N = 2 )  ## creating AD function obj = MakeADFun(nll, par, silent = TRUE) # creating the objective function #> Performance tip: Consider running `TapeConfig(matmul = 'plain')` before `MakeADFun()` to speed up the forward algorithm.  ## optimising opt = nlminb(obj$par, obj$fn, obj$gr) # optimization  ## running sdreportMC # `mu` has report statement, `delta` is automatically reported by `forward()` sdrMC = sdreportMC(obj,                     what = c(\"mu\", \"delta\"),                     nSamples = 50) #> Performance tip: Consider running `TapeConfig(matmul = 'plain')` before `MakeADFun()` to speed up the forward algorithm. #> Sampling reported quantities... dim(sdrMC$delta) #> [1] 50  2 # now a matrix with 50 samples (rows)"},{"path":"https://janoleko.github.io/reference/sdreport_outer.html","id":null,"dir":"Reference","previous_headings":"","what":"Report uncertainty of the estimated smoothing parameters or variances — sdreport_outer","title":"Report uncertainty of the estimated smoothing parameters or variances — sdreport_outer","text":"Computes standard deviations smoothing parameters model object returned qreml using delta method.","code":""},{"path":"https://janoleko.github.io/reference/sdreport_outer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Report uncertainty of the estimated smoothing parameters or variances — sdreport_outer","text":"","code":"sdreport_outer(mod, invert = FALSE)"},{"path":"https://janoleko.github.io/reference/sdreport_outer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Report uncertainty of the estimated smoothing parameters or variances — sdreport_outer","text":"mod model objects returned qreml invert optional logical; TRUE, inverse smoothing paramaters (variances) returned along transformed standard deviations obtained via delta method.","code":""},{"path":"https://janoleko.github.io/reference/sdreport_outer.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Report uncertainty of the estimated smoothing parameters or variances — sdreport_outer","text":"list containing report matrix summarising parameters standard deviations well outer Hessian matrix.","code":""},{"path":"https://janoleko.github.io/reference/sdreport_outer.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Report uncertainty of the estimated smoothing parameters or variances — sdreport_outer","text":"computations based approximate gradient restricted log likelihood. outer Hessian computed finite differencing gradient. inverse smoothing parameters requested, standard deviations transformed variances using delta method.","code":""},{"path":"https://janoleko.github.io/reference/sdreport_outer.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Report uncertainty of the estimated smoothing parameters or variances — sdreport_outer","text":"","code":"## no examples"},{"path":"https://janoleko.github.io/reference/skewnorm.html","id":null,"dir":"Reference","previous_headings":"","what":"Skew normal distribution — skewnorm","title":"Skew normal distribution — skewnorm","text":"Density, distribution function, quantile function random generation skew normal distribution.","code":""},{"path":"https://janoleko.github.io/reference/skewnorm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Skew normal distribution — skewnorm","text":"","code":"dskewnorm(x, xi = 0, omega = 1, alpha = 0, log = FALSE)  pskewnorm(q, xi = 0, omega = 1, alpha = 0, ...)  qskewnorm(p, xi = 0, omega = 1, alpha = 0, ...)  rskewnorm(n, xi = 0, omega = 1, alpha = 0)"},{"path":"https://janoleko.github.io/reference/skewnorm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Skew normal distribution — skewnorm","text":"x, q vector quantiles xi location parameter omega scale parameter, must positive. alpha skewness parameter, +/- Inf allowed. log logical; TRUE, probabilities/ densities \\(p\\) returned \\(\\log(p)\\). ... additional parameters passed sn package functions pskewnorm qskewnorm. p vector probabilities n number observations. length(n) > 1, length taken number required.","code":""},{"path":"https://janoleko.github.io/reference/skewnorm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Skew normal distribution — skewnorm","text":"dskewnorm gives density, pskewnorm gives distribution function, qskewnorm gives quantile function, rskewnorm generates random deviates.","code":""},{"path":"https://janoleko.github.io/reference/skewnorm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Skew normal distribution — skewnorm","text":"implementation dskewnorm allows automatic differentiation RTMB functions imported sn package.","code":""},{"path":"https://janoleko.github.io/reference/skewnorm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Skew normal distribution — skewnorm","text":"","code":"x = rskewnorm(1) d = dskewnorm(x) p = pskewnorm(x) q = qskewnorm(p)"},{"path":"https://janoleko.github.io/reference/smooth_dens_construct.html","id":null,"dir":"Reference","previous_headings":"","what":"Build the design and penalty matrices for smooth density estimation — smooth_dens_construct","title":"Build the design and penalty matrices for smooth density estimation — smooth_dens_construct","text":"high-level function can used prepare objects needed estimate mixture models smooth densities using P-Splines.","code":""},{"path":"https://janoleko.github.io/reference/smooth_dens_construct.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build the design and penalty matrices for smooth density estimation — smooth_dens_construct","text":"","code":"smooth_dens_construct(   data,   par,   type = \"real\",   k = 25,   knots = NULL,   degree = 3,   diff_order = 2 )"},{"path":"https://janoleko.github.io/reference/smooth_dens_construct.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build the design and penalty matrices for smooth density estimation — smooth_dens_construct","text":"data named data frame 1 multiple data streams par nested named list initial means sds/concentrations data stream type vector length 1 number data streams containing type data stream, either \"real\" data reals, \"positive\" data positive reals \"circular\" angular data. k vector length 1 number data streams containing number basis functions data stream knots optional list knots vectors (including boundary knots) used basis construction. provided, knots placed equidistantly \"real\" \"circular\" using polynomial spacing \"positive\". \"real\" \"positive\" k - degree + 1 knots needed, \"circular\" k + 1 knots needed. degree degree B-spline basis functions data stream, defaults cubic B-splines diff_order order differencing used P-Spline penalty matrix data stream. Defaults second-order differences.","code":""},{"path":"https://janoleko.github.io/reference/smooth_dens_construct.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build the design and penalty matrices for smooth density estimation — smooth_dens_construct","text":"nested list containing design matrices Z, penalty matrices S, initial coefficients coef prediction design matrices Z_predict, prediction grids xseq, details basis expansion data stream.","code":""},{"path":"https://janoleko.github.io/reference/smooth_dens_construct.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Build the design and penalty matrices for smooth density estimation — smooth_dens_construct","text":"hood, make_matrices_dens used actual construction design penalty matrices. can provide one multiple data streams different types (real, positive, circular) specify initial means standard deviations/ concentrations data stream. information converted suitable spline coefficients. smooth_dens_construct constructs design penalty matrices standardised B-splines basis functions (integrating one) data stream. types \"real\" \"circular\" knots placed equidistant range data, type \"positive\" knots placed using polynomial spacing.","code":""},{"path":"https://janoleko.github.io/reference/smooth_dens_construct.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Build the design and penalty matrices for smooth density estimation — smooth_dens_construct","text":"","code":"## 3 data streams, each with one distribution # normal data with mean 0 and sd 1 x1 = rnorm(100, mean = 0, sd = 1) # gamma data with mean 5 and sd 3 x2 = rgamma2(100, mean = 5, sd = 3) # circular data x3 = rvm(100, mu = 0, kappa = 2)  data = data.frame(x1 = x1, x2 = x2, x3 = x3)  par = list(x1 = list(mean = 0, sd = 1),            x2 = list(mean = 5, sd = 3),            x3 = list(mean = 0, concentration = 2))  SmoothDens = smooth_dens_construct(data,                                     par,                                    type = c(\"real\", \"positive\", \"circular\")) #> x1  #> Leaving out last column of the penalty matrix, fix the last spline coefficient at zero for identifiability! #> Parameter matrix excludes the last column. Add a (fixed) zero column using 'cbind(coef, 0)' in your loss function! #> x2  #> Leaving out last column of the penalty matrix, fix the last spline coefficient at zero for identifiability! #> Parameter matrix excludes the last column. Add a (fixed) zero column using 'cbind(coef, 0)' in your loss function! #> x3  #> Leaving out last column of the penalty matrix, fix the last spline coefficient at zero for identifiability! #> Parameter matrix excludes the last column. Add a (fixed) zero column using 'cbind(coef, 0)' in your loss function!                               # extracting objects for x1 Z1 = SmoothDens$Z$x1 S1 = SmoothDens$S$x1 coefs1 = SmoothDens$coef$x1  ## one data stream, but mixture of two distributions # normal data with mean 0 and sd 1 x = rnorm(100, mean = 0, sd = 1) data = data.frame(x = x)  # now parameters for mixture of two normals par = list(x = list(mean = c(0, 5), sd = c(1,1)))  SmoothDens = smooth_dens_construct(data, par = par) #> x  #> Leaving out last column of the penalty matrix, fix the last spline coefficient at zero for identifiability! #> Parameter matrix excludes the last column. Add a (fixed) zero column using 'cbind(coef, 0)' in your loss function!  # extracting objects  Z = SmoothDens$Z$x S = SmoothDens$S$x coefs = SmoothDens$coef$x"},{"path":"https://janoleko.github.io/reference/stateprobs.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate conditional local state probabilities for homogeneous HMMs — stateprobs","title":"Calculate conditional local state probabilities for homogeneous HMMs — stateprobs","text":"Computes $$\\Pr(S_t = j \\mid X_1, ..., X_T)$$ homogeneous HMMs","code":""},{"path":"https://janoleko.github.io/reference/stateprobs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate conditional local state probabilities for homogeneous HMMs — stateprobs","text":"","code":"stateprobs(delta, Gamma, allprobs, trackID = NULL, mod = NULL)"},{"path":"https://janoleko.github.io/reference/stateprobs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate conditional local state probabilities for homogeneous HMMs — stateprobs","text":"delta initial stationary distribution length N, matrix dimension c(k,N) k independent tracks, trackID provided Gamma transition probability matrix dimension c(N,N), array k transition probability matrices dimension c(N,N,k), trackID provided allprobs matrix state-dependent probabilities/ density values dimension c(n, N) trackID optional vector length n containing IDs provided, total log-likelihood sum track's likelihood contribution. case, Gamma can matrix, leading transition probabilities track, array dimension c(N,N,k), one (homogeneous) transition probability matrix track. Furthermore, instead single vector delta corresponding initial distribution, delta matrix initial distributions, dimension c(k,N), can provided, track starts initial distribution. mod optional model object containing initial distribution delta, transition probability matrix Gamma, matrix state-dependent probabilities allprobs, potentially trackID variable using automatic differentiation either RTMB::MakeADFun qreml include forward likelihood function, objects needed state decoding automatically reported model fitting. Hence, can pass model object obtained running RTMB::report() qreml directly function.","code":""},{"path":"https://janoleko.github.io/reference/stateprobs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate conditional local state probabilities for homogeneous HMMs — stateprobs","text":"matrix conditional state probabilities dimension c(n,N)","code":""},{"path":[]},{"path":"https://janoleko.github.io/reference/stateprobs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate conditional local state probabilities for homogeneous HMMs — stateprobs","text":"","code":"Gamma = tpm(c(-1,-2)) delta = stationary(Gamma) allprobs = matrix(runif(10), nrow = 10, ncol = 2)  probs = stateprobs(delta, Gamma, allprobs)"},{"path":"https://janoleko.github.io/reference/stateprobs_g.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate conditional local state probabilities for inhomogeneous HMMs — stateprobs_g","title":"Calculate conditional local state probabilities for inhomogeneous HMMs — stateprobs_g","text":"Computes $$\\Pr(S_t = j \\mid X_1, ..., X_T)$$ inhomogeneous HMMs","code":""},{"path":"https://janoleko.github.io/reference/stateprobs_g.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate conditional local state probabilities for inhomogeneous HMMs — stateprobs_g","text":"","code":"stateprobs_g(delta, Gamma, allprobs, trackID = NULL, mod = NULL)"},{"path":"https://janoleko.github.io/reference/stateprobs_g.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate conditional local state probabilities for inhomogeneous HMMs — stateprobs_g","text":"delta initial stationary distribution length N, matrix dimension c(k,N) k independent tracks, trackID provided Gamma array transition probability matrices dimension c(N,N,n-1), time series length n, n-1 transitions array dimension c(N,N,n) single track provided, first slice ignored. trackID provided, Gamma needs array dimension c(N,N,n), n number rows allprobs. track first transition matrix ignored. allprobs matrix state-dependent probabilities/ density values dimension c(n, N) trackID optional vector k track IDs, multiple tracks need decoded separately mod optional model object containing initial distribution delta, transition probability matrix Gamma, matrix state-dependent probabilities allprobs, potentially trackID variable using automatic differentiation either RTMB::MakeADFun qreml include forward_g likelihood function, objects needed state decoding automatically reported model fitting. Hence, can pass model object obtained running RTMB::report() qreml directly function.","code":""},{"path":"https://janoleko.github.io/reference/stateprobs_g.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate conditional local state probabilities for inhomogeneous HMMs — stateprobs_g","text":"matrix conditional state probabilities dimension c(n,N)","code":""},{"path":[]},{"path":"https://janoleko.github.io/reference/stateprobs_g.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate conditional local state probabilities for inhomogeneous HMMs — stateprobs_g","text":"","code":"Gamma = tpm_g(runif(10), matrix(c(-1,-1,1,-2), nrow = 2, byrow = TRUE)) delta = c(0.5, 0.5) allprobs = matrix(runif(20), nrow = 10, ncol = 2)  probs = stateprobs_g(delta, Gamma[,,-1], allprobs)"},{"path":"https://janoleko.github.io/reference/stateprobs_p.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate conditional local state probabilities for periodically inhomogeneous HMMs — stateprobs_p","title":"Calculate conditional local state probabilities for periodically inhomogeneous HMMs — stateprobs_p","text":"Computes $$\\Pr(S_t = j \\mid X_1, ..., X_T)$$ periodically inhomogeneous HMMs","code":""},{"path":"https://janoleko.github.io/reference/stateprobs_p.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate conditional local state probabilities for periodically inhomogeneous HMMs — stateprobs_p","text":"","code":"stateprobs_p(delta, Gamma, allprobs, tod, trackID = NULL, mod = NULL)"},{"path":"https://janoleko.github.io/reference/stateprobs_p.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate conditional local state probabilities for periodically inhomogeneous HMMs — stateprobs_p","text":"delta initial stationary distribution length N, matrix dimension c(k,N) k independent tracks, trackID provided e.g. periodically stationary distribution (track) computed stationary_p. Gamma array transition probability matrices time point cycle dimension c(N,N,L), L length cycle. allprobs matrix state-dependent probabilities/ density values dimension c(n, N) tod (Integer valued) variable cycle indexing 1, ..., L, mapping data index generalised time day (length n). half-hourly data L = 48. , however, also day year daily data L = 365. trackID optional vector k track IDs, multiple tracks need decoded separately mod optional model object containing initial distribution delta, transition probability matrix Gamma, matrix state-dependent probabilities allprobs, potentially trackID variable using automatic differentiation either RTMB::MakeADFun qreml include forward_p likelihood function, objects needed state decoding automatically reported model fitting. Hence, can pass model object obtained running RTMB::report() qreml directly function.","code":""},{"path":"https://janoleko.github.io/reference/stateprobs_p.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate conditional local state probabilities for periodically inhomogeneous HMMs — stateprobs_p","text":"matrix conditional state probabilities dimension c(n,N)","code":""},{"path":[]},{"path":"https://janoleko.github.io/reference/stateprobs_p.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate conditional local state probabilities for periodically inhomogeneous HMMs — stateprobs_p","text":"","code":"L = 24 beta = matrix(c(-1, 2, -1, -2, 1, -1), nrow = 2, byrow = TRUE) Gamma = tpm_p(1:L, L, beta, degree = 1) delta = stationary_p(Gamma, 1) allprobs = matrix(runif(200), nrow = 100, ncol = 2) tod = rep(1:24, 5)[1:100]  probs = stateprobs_p(delta, Gamma, allprobs, tod)"},{"path":"https://janoleko.github.io/reference/stationary.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the stationary distribution of a homogeneous Markov chain — stationary","title":"Compute the stationary distribution of a homogeneous Markov chain — stationary","text":"homogeneous, finite state Markov chain irreducible aperiodic converges unique stationary distribution, called \\(\\delta\\). stationary, distribution satisfies $$\\delta \\Gamma = \\delta,$$ subject \\(\\sum_{j=1}^N \\delta_j = 1\\), \\(\\Gamma\\) transition probability matrix. function solves linear system equations .","code":""},{"path":"https://janoleko.github.io/reference/stationary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the stationary distribution of a homogeneous Markov chain — stationary","text":"","code":"stationary(Gamma)"},{"path":"https://janoleko.github.io/reference/stationary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the stationary distribution of a homogeneous Markov chain — stationary","text":"Gamma transition probability matrix dimension c(N,N) array matrices dimension c(N,N,nTracks) stationary distribution computed several matrices ","code":""},{"path":"https://janoleko.github.io/reference/stationary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the stationary distribution of a homogeneous Markov chain — stationary","text":"either single stationary distribution Markov chain (vector length N) matrix stationary distributions dimension c(nTracks,N) one stationary distribution row","code":""},{"path":[]},{"path":"https://janoleko.github.io/reference/stationary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute the stationary distribution of a homogeneous Markov chain — stationary","text":"","code":"# single matrix Gamma = tpm(c(rep(-2,3), rep(-3,3))) delta = stationary(Gamma) # multiple matrices Gamma = array(Gamma, dim = c(3,3,10)) Delta = stationary(Gamma)"},{"path":"https://janoleko.github.io/reference/stationary_cont.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the stationary distribution of a continuous-time Markov chain — stationary_cont","title":"Compute the stationary distribution of a continuous-time Markov chain — stationary_cont","text":"well-behaved continuous-time Markov chain converges unique stationary distribution, called \\(\\pi\\). distribution satisfies $$\\pi Q = 0,$$ subject \\(\\sum_{j=1}^N \\pi_j = 1\\), \\(Q\\) infinitesimal generator Markov chain. function solves linear system equations given generator matrix.","code":""},{"path":"https://janoleko.github.io/reference/stationary_cont.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the stationary distribution of a continuous-time Markov chain — stationary_cont","text":"","code":"stationary_cont(Q)"},{"path":"https://janoleko.github.io/reference/stationary_cont.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the stationary distribution of a continuous-time Markov chain — stationary_cont","text":"Q infinitesimal generator matrix dimension c(N,N) array matrices dimension c(N,N,nTracks) stationary distribution computed several matrices ","code":""},{"path":"https://janoleko.github.io/reference/stationary_cont.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the stationary distribution of a continuous-time Markov chain — stationary_cont","text":"either single stationary distribution continuous-time Markov chain (vector length N) matrix stationary distributions dimension c(nTracks,N) one stationary distribution row","code":""},{"path":[]},{"path":"https://janoleko.github.io/reference/stationary_cont.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute the stationary distribution of a continuous-time Markov chain — stationary_cont","text":"","code":"# single matrix Q = generator(c(-2,-2)) Pi = stationary_cont(Q) # multiple matrices Q = array(Q, dim = c(2,2,10)) Pi = stationary_cont(Q)"},{"path":"https://janoleko.github.io/reference/stationary_p.html","id":null,"dir":"Reference","previous_headings":"","what":"Periodically stationary distribution of a periodically inhomogeneous Markov chain — stationary_p","title":"Periodically stationary distribution of a periodically inhomogeneous Markov chain — stationary_p","text":"Computes periodically stationary distribution periodically inhomogeneous Markov chain.","code":""},{"path":"https://janoleko.github.io/reference/stationary_p.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Periodically stationary distribution of a periodically inhomogeneous Markov chain — stationary_p","text":"","code":"stationary_p(Gamma, t = NULL, ad = NULL)"},{"path":"https://janoleko.github.io/reference/stationary_p.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Periodically stationary distribution of a periodically inhomogeneous Markov chain — stationary_p","text":"Gamma array transition probability matrices dimension c(N,N,L) t integer index time point cycle, calculate stationary distribution t provided, function calculates stationary distributions time point cycle. ad optional logical, indicating whether automatic differentiation RTMB used. default, function determines .","code":""},{"path":"https://janoleko.github.io/reference/stationary_p.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Periodically stationary distribution of a periodically inhomogeneous Markov chain — stationary_p","text":"either periodically stationary distribution time t periodically stationary distributions.","code":""},{"path":"https://janoleko.github.io/reference/stationary_p.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Periodically stationary distribution of a periodically inhomogeneous Markov chain — stationary_p","text":"transition probability matrix inhomogeneous Markov chain varies periodically (period length \\(L\\)), converges -called periodically stationary distribution. happens, thinned Markov chain, full cycle time step, homogeneous transition probability matrix $$\\Gamma_t = \\Gamma^{(t)} \\Gamma^{(t+1)} \\dots \\Gamma^{(t+L-1)}$$ \\(t = 1, \\dots, L.\\) stationary distribution time \\(t\\) satifies \\(\\delta^{(t)} \\Gamma_t = \\delta^{(t)}\\). function calculates said periodically stationary distribution.","code":""},{"path":"https://janoleko.github.io/reference/stationary_p.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Periodically stationary distribution of a periodically inhomogeneous Markov chain — stationary_p","text":"Koslik, J. O., Feldmann, C. C., Mews, S., Michels, R., & Langrock, R. (2023). Inference state process periodically inhomogeneous hidden Markov models animal behavior. arXiv preprint arXiv:2312.14583.","code":""},{"path":[]},{"path":"https://janoleko.github.io/reference/stationary_p.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Periodically stationary distribution of a periodically inhomogeneous Markov chain — stationary_p","text":"","code":"# setting parameters for trigonometric link beta = matrix(c(-1, 2, -1, -2, 1, -1), nrow = 2, byrow = TRUE) Gamma = tpm_p(beta = beta, degree = 1) # periodically stationary distribution for specific time point delta = stationary_p(Gamma, 4)  # all periodically stationary distributions Delta = stationary_p(Gamma)"},{"path":"https://janoleko.github.io/reference/stationary_p_sparse.html","id":null,"dir":"Reference","previous_headings":"","what":"Sparse version of stationary_p — stationary_p_sparse","title":"Sparse version of stationary_p — stationary_p_sparse","text":"function computes periodically stationary distribution Markov chain given list L sparse transition probability matrices. Compatible automatic differentiation RTMB","code":""},{"path":"https://janoleko.github.io/reference/stationary_p_sparse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sparse version of stationary_p — stationary_p_sparse","text":"","code":"stationary_p_sparse(Gamma, t = NULL)"},{"path":"https://janoleko.github.io/reference/stationary_p_sparse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sparse version of stationary_p — stationary_p_sparse","text":"Gamma sist length L containing sparse transition probability matrices one cycle. t integer index time point cycle, calculate stationary distribution t provided, function calculates stationary distributions time point cycle.","code":""},{"path":"https://janoleko.github.io/reference/stationary_p_sparse.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sparse version of stationary_p — stationary_p_sparse","text":"either periodically stationary distribution time t periodically stationary distributions.","code":""},{"path":"https://janoleko.github.io/reference/stationary_p_sparse.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sparse version of stationary_p — stationary_p_sparse","text":"","code":"## periodic HSMM example (here the approximating tpm is sparse) N = 2 # number of states L = 24 # cycle length # time-varying mean dwell times Z = trigBasisExp(1:L) # trigonometric basis functions design matrix beta = matrix(c(2, 2, 0.1, -0.1, -0.2, 0.2), nrow = 2) Lambda = exp(cbind(1, Z) %*% t(beta)) sizes = c(20, 20) # approximating chain with 40 states # state dwell-time distributions dm = lapply(1:N, function(i) sapply(1:sizes[i]-1, dpois, lambda = Lambda[,i])) omega = matrix(c(0,1,1,0), nrow = N, byrow = TRUE) # embedded t.p.m.  # calculating extended-state-space t.p.m.s Gamma = tpm_phsmm(omega, dm) # Periodically stationary distribution for specific time point delta = stationary_p_sparse(Gamma, 4)  # All periodically stationary distributions Delta = stationary_p_sparse(Gamma)"},{"path":"https://janoleko.github.io/reference/stationary_sparse.html","id":null,"dir":"Reference","previous_headings":"","what":"Sparse version of stationary — stationary_sparse","title":"Sparse version of stationary — stationary_sparse","text":"function computes stationary distribution Markov chain given sparse transition probability matrix. Compatible automatic differentiation RTMB","code":""},{"path":"https://janoleko.github.io/reference/stationary_sparse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sparse version of stationary — stationary_sparse","text":"","code":"stationary_sparse(Gamma)"},{"path":"https://janoleko.github.io/reference/stationary_sparse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sparse version of stationary — stationary_sparse","text":"Gamma sparse transition probability matrix dimension c(N,N)","code":""},{"path":"https://janoleko.github.io/reference/stationary_sparse.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sparse version of stationary — stationary_sparse","text":"stationary distribution Markov chain given transition probability matrix","code":""},{"path":"https://janoleko.github.io/reference/stationary_sparse.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sparse version of stationary — stationary_sparse","text":"","code":"## HSMM example (here the approximating tpm is sparse) # building the t.p.m. of the embedded Markov chain omega = matrix(c(0,1,1,0), nrow = 2, byrow = TRUE) # defining state aggregate sizes sizes = c(20, 30) # defining state dwell-time distributions lambda = c(5, 11) dm = list(dpois(1:sizes[1]-1, lambda[1]), dpois(1:sizes[2]-1, lambda[2])) # calculating extended-state-space t.p.m. Gamma = tpm_hsmm(omega, dm) delta = stationary_sparse(Gamma)"},{"path":"https://janoleko.github.io/reference/summary.qremlModel.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary method for qremlModel objects — summary.qremlModel","title":"Summary method for qremlModel objects — summary.qremlModel","text":"Prints summary model object created qreml.","code":""},{"path":"https://janoleko.github.io/reference/summary.qremlModel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary method for qremlModel objects — summary.qremlModel","text":"","code":"# S3 method for class 'qremlModel' summary(object, ...)"},{"path":"https://janoleko.github.io/reference/summary.qremlModel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary method for qremlModel objects — summary.qremlModel","text":"object qremlModel object created qreml ... additional arguments","code":""},{"path":"https://janoleko.github.io/reference/summary.qremlModel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary method for qremlModel objects — summary.qremlModel","text":"prints summary model object","code":""},{"path":"https://janoleko.github.io/reference/summary.qremlModel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary method for qremlModel objects — summary.qremlModel","text":"","code":"# no examples"},{"path":"https://janoleko.github.io/reference/tpm.html","id":null,"dir":"Reference","previous_headings":"","what":"Build the transition probability matrix from unconstrained parameter vector — tpm","title":"Build the transition probability matrix from unconstrained parameter vector — tpm","text":"Markov chains parametrised terms transition probability matrix \\(\\Gamma\\), row contains conditional probability distribution next state given current state. Hence, row entries 0 1 need sum one. numerical optimisation, parameterise terms unconstrained parameters, thus function computes said matrix unconstrained parameter vector via inverse multinomial logistic link (also known softmax) applied row.","code":""},{"path":"https://janoleko.github.io/reference/tpm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build the transition probability matrix from unconstrained parameter vector — tpm","text":"","code":"tpm(param, byrow = FALSE, ref = NULL)"},{"path":"https://janoleko.github.io/reference/tpm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build the transition probability matrix from unconstrained parameter vector — tpm","text":"param unconstrained parameter vector length N*(N-1) N number states Markov chain byrow logical indicating transition probability matrix filled row Defaults FALSE, set TRUE one wants work matrix beta parameters returned popular HMM packages like moveHMM, momentuHMM, hmmTMB. ref Optional integer vector length N giving, row, column index reference state (predictor fixed 0). Defaults diagonal (ref = 1:N).","code":""},{"path":"https://janoleko.github.io/reference/tpm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build the transition probability matrix from unconstrained parameter vector — tpm","text":"Transition probability matrix dimension c(N,N)","code":""},{"path":[]},{"path":"https://janoleko.github.io/reference/tpm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Build the transition probability matrix from unconstrained parameter vector — tpm","text":"","code":"# 2 states: 2 free off-diagonal elements par1 = rep(-1, 2) Gamma1 = tpm(par1)  # 3 states: 6 free off-diagonal elements par2 = rep(-2, 6) Gamma2 = tpm(par2)"},{"path":"https://janoleko.github.io/reference/tpm_cont.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate continuous time transition probabilities — tpm_cont","title":"Calculate continuous time transition probabilities — tpm_cont","text":"continuous-time Markov chain described infinitesimal generator matrix \\(Q\\). observing data time points \\(t_1, \\dots, t_n\\) transition probabilites \\(t_i\\) \\(t_{+1}\\) caluclated $$\\Gamma(\\Delta t_i) = \\exp(Q \\Delta t_i),$$ \\(\\exp()\\) matrix exponential. mapping \\(\\Gamma(\\Delta t)\\) also called Markov semigroup. function calculates transition matrices based given generator time differences.","code":""},{"path":"https://janoleko.github.io/reference/tpm_cont.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate continuous time transition probabilities — tpm_cont","text":"","code":"tpm_cont(Q, timediff, ad = NULL, report = TRUE)"},{"path":"https://janoleko.github.io/reference/tpm_cont.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate continuous time transition probabilities — tpm_cont","text":"Q infinitesimal generator matrix continuous-time Markov chain dimension c(N,N) timediff time differences observations length n-1 based n observations ad optional logical, indicating whether automatic differentiation RTMB used. default, function determines . report logical, indicating whether Q reported fitted model. Defaults TRUE, works ad = TRUE.","code":""},{"path":"https://janoleko.github.io/reference/tpm_cont.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate continuous time transition probabilities — tpm_cont","text":"array continuous-time transition matrices dimension c(N,N,n-1)","code":""},{"path":[]},{"path":"https://janoleko.github.io/reference/tpm_cont.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate continuous time transition probabilities — tpm_cont","text":"","code":"# building a Q matrix for a 3-state cont.-time Markov chain Q = generator(rep(-2, 6))  # draw random time differences timediff = rexp(100, 10)  # compute all transition matrices Gamma = tpm_cont(Q, timediff)"},{"path":"https://janoleko.github.io/reference/tpm_emb.html","id":null,"dir":"Reference","previous_headings":"","what":"Build the embedded transition probability matrix of an HSMM from unconstrained parameter vector — tpm_emb","title":"Build the embedded transition probability matrix of an HSMM from unconstrained parameter vector — tpm_emb","text":"Hidden semi-Markov models defined terms state durations embedded transition probability matrix contains conditional transition probabilities given current state left. matrix necessarily diagonal entries equal zero self-transitions impossible. function builds embedded/ conditional transition probability matrix unconstrained parameter vector. row matrix, inverse multinomial logistic link applied. matrix dimension c(N,N), number free -diagonal elements N*(N-2), hence also length param. means, 2 states, function needs called without arguments, 3-states vector length 3, 4 states vector length 8, etc. Compatible automatic differentiation RTMB","code":""},{"path":"https://janoleko.github.io/reference/tpm_emb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build the embedded transition probability matrix of an HSMM from unconstrained parameter vector — tpm_emb","text":"","code":"tpm_emb(param = NULL)"},{"path":"https://janoleko.github.io/reference/tpm_emb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build the embedded transition probability matrix of an HSMM from unconstrained parameter vector — tpm_emb","text":"param unconstrained parameter vector length N*(N-2) N number states Markov chain function called without param, return conditional transition probability matrix 2-state HSMM, fixed 0 diagonal entries -diagonal entries equal 1.","code":""},{"path":"https://janoleko.github.io/reference/tpm_emb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build the embedded transition probability matrix of an HSMM from unconstrained parameter vector — tpm_emb","text":"embedded/ conditional transition probability matrix dimension c(N,N)","code":""},{"path":[]},{"path":"https://janoleko.github.io/reference/tpm_emb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Build the embedded transition probability matrix of an HSMM from unconstrained parameter vector — tpm_emb","text":"","code":"# 2 states: no free off-diagonal elements omega = tpm_emb()  # 3 states: 3 free off-diagonal elements param = rep(0, 3) omega = tpm_emb(param)  # 4 states: 8 free off-diagonal elements param = rep(0, 8) omega = tpm_emb(param)"},{"path":"https://janoleko.github.io/reference/tpm_emb_g.html","id":null,"dir":"Reference","previous_headings":"","what":"Build all embedded transition probability matrices of an inhomogeneous HSMM — tpm_emb_g","title":"Build all embedded transition probability matrices of an inhomogeneous HSMM — tpm_emb_g","text":"Hidden semi-Markov models defined terms state durations embedded transition probability matrix contains conditional transition probabilities given current state left. matrix necessarily diagonal entries equal zero self-transitions impossible. can allow matrix vary covariates, purpose function. builds embedded/ conditional transition probability matrices based design parameter matrix. row matrix, inverse multinomial logistic link applied. matrix dimension c(N,N), number free -diagonal elements N*(N-2) determines number rows parameter matrix. Compatible automatic differentiation RTMB","code":""},{"path":"https://janoleko.github.io/reference/tpm_emb_g.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build all embedded transition probability matrices of an inhomogeneous HSMM — tpm_emb_g","text":"","code":"tpm_emb_g(Z, beta, report = TRUE)"},{"path":"https://janoleko.github.io/reference/tpm_emb_g.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build all embedded transition probability matrices of an inhomogeneous HSMM — tpm_emb_g","text":"Z covariate design matrix without intercept column, .e. dimension c(n, p) c(n, p+1) Z p columns, intercept column ones added automatically. beta matrix coefficients -diagonal elements embedded transition probability matrix Needs dimension c(N*(N-2), p+1), first column contains intercepts. p can 0, case model homogeneous. report logical, indicating whether coefficient matrix beta reported fitted model. Defaults TRUE.","code":""},{"path":"https://janoleko.github.io/reference/tpm_emb_g.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build all embedded transition probability matrices of an inhomogeneous HSMM — tpm_emb_g","text":"array embedded/ conditional transition probability matrices dimension c(N,N,n)","code":""},{"path":[]},{"path":"https://janoleko.github.io/reference/tpm_emb_g.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Build all embedded transition probability matrices of an inhomogeneous HSMM — tpm_emb_g","text":"","code":"## parameter matrix for 3-state HSMM beta = matrix(c(rep(0, 3), -0.2, 0.2, 0.1), nrow = 3) # no intercept Z = rnorm(100) omega = tpm_emb_g(Z, beta) # intercept Z = cbind(1, Z) omega = tpm_emb_g(Z, beta)"},{"path":"https://janoleko.github.io/reference/tpm_g.html","id":null,"dir":"Reference","previous_headings":"","what":"Build all transition probability matrices of an inhomogeneous HMM — tpm_g","title":"Build all transition probability matrices of an inhomogeneous HMM — tpm_g","text":"HMM, often model influence covariates state process linking transition probabiltiy matrix. commonly, done specifying linear predictor $$ \\eta_{ij}^{(t)} = \\beta^{(ij)}_0 + \\beta^{(ij)}_1 z_{t1} + \\dots + \\beta^{(ij)}_p z_{tp} $$ -diagonal element (\\(\\neq j\\)) transition probability matrix applying inverse multinomial logistic link (also known softmax) row. function efficiently calculates transition probabilty matrices given design matrix Z parameter matrix beta.","code":""},{"path":"https://janoleko.github.io/reference/tpm_g.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build all transition probability matrices of an inhomogeneous HMM — tpm_g","text":"","code":"tpm_g(   Z,   beta,   Eta = NULL,   byrow = FALSE,   ref = NULL,   ad = NULL,   report = TRUE,   sparse = FALSE )"},{"path":"https://janoleko.github.io/reference/tpm_g.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build all transition probability matrices of an inhomogeneous HMM — tpm_g","text":"Z covariate design matrix without intercept column, .e. dimension c(n, p) c(n, p+1) Z p columns, intercept column ones added automatically. beta matrix coefficients -diagonal elements transition probability matrix Needs dimension c(N*(N-1), p+1), first column contains intercepts. Eta optional pre-calculated linear predictor matrix dimension c(n, N*(N-1)). Usually, Eta calculated Z %*% t(beta). provided, Z beta necessary ignored. byrow logical indicating transition probability matrix filled row Defaults FALSE, set TRUE one wants work matrix beta parameters returned popular HMM packages like moveHMM, momentuHMM, hmmTMB. ref Optional integer vector length N giving, row, column index reference state (predictor fixed 0). Defaults diagonal (ref = 1:N). ad optional logical, indicating whether automatic differentiation RTMB used. default, function determines . report logical, indicating whether coefficient matrix beta reported fitted model. Defaults TRUE, works ad = TRUE. sparse logical, indicating whether sparsity rows Z exploited.","code":""},{"path":"https://janoleko.github.io/reference/tpm_g.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build all transition probability matrices of an inhomogeneous HMM — tpm_g","text":"array transition probability matrices dimension c(N,N,n)","code":""},{"path":[]},{"path":"https://janoleko.github.io/reference/tpm_g.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Build all transition probability matrices of an inhomogeneous HMM — tpm_g","text":"","code":"Z = matrix(runif(200), ncol = 2) beta = matrix(c(-1, 1, 2, -2, 1, -2), nrow = 2, byrow = TRUE) Gamma = tpm_g(Z, beta)"},{"path":"https://janoleko.github.io/reference/tpm_g2.html","id":null,"dir":"Reference","previous_headings":"","what":"Build all transition probability matrices of an inhomogeneous HMM — tpm_g2","title":"Build all transition probability matrices of an inhomogeneous HMM — tpm_g2","text":"HMM, often model influence covariates state process linking transition probabiltiy matrix. commonly, done specifying linear predictors $$ \\eta_{ij}^{(t)} = \\beta^{(ij)}_0 + \\beta^{(ij)}_1 z_{t1} + \\dots + \\beta^{(ij)}_p z_{tp} $$ -diagonal element (\\(\\neq j\\)) transition probability matrix applying inverse multinomial logistic link (also known softmax) row. function efficiently calculates transition probabilty matrices given design matrix Z parameter matrix beta.","code":""},{"path":"https://janoleko.github.io/reference/tpm_g2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build all transition probability matrices of an inhomogeneous HMM — tpm_g2","text":"","code":"tpm_g2(Z, beta, byrow = FALSE, ad = NULL, report = TRUE, ref = NULL)"},{"path":"https://janoleko.github.io/reference/tpm_g2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build all transition probability matrices of an inhomogeneous HMM — tpm_g2","text":"Z covariate design matrix without intercept column, .e. dimension c(n, p) c(n, p+1) Z p columns, intercept column ones added automatically. Can also list N*(N-1) design matrices different number columns number rows. case, intercept column added. beta matrix coefficients -diagonal elements transition probability matrix Needs dimension c(N*(N-1), p+1), first column contains intercepts. Z list, beta can also list length N*(N-1) entry vector (long) matrix coefficients, matching dimension corresponding entry Z. byrow logical indicating transition probability matrix filled row Defaults FALSE, set TRUE one wants work matrix beta parameters returned popular HMM packages like moveHMM, momentuHMM, hmmTMB. ad optional logical, indicating whether automatic differentiation RTMB used. default, function determines . report logical, indicating whether coefficient matrix beta reported fitted model. Defaults TRUE, works ad = TRUE. ref optional vector length N reference state indices column transition probability matrix. row transition matrix corresponds multinomial regression, hence one state needs reference category. Defaults -diagonal elements (ref = 1:N).","code":""},{"path":"https://janoleko.github.io/reference/tpm_g2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build all transition probability matrices of an inhomogeneous HMM — tpm_g2","text":"array transition probability matrices dimension c(N,N,n)","code":""},{"path":[]},{"path":"https://janoleko.github.io/reference/tpm_g2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Build all transition probability matrices of an inhomogeneous HMM — tpm_g2","text":"","code":"Z = matrix(runif(200), ncol = 2) beta = matrix(c(-1, 1, 2, -2, 1, -2), nrow = 2, byrow = TRUE) Gamma = tpm_g(Z, beta)"},{"path":"https://janoleko.github.io/reference/tpm_hsmm.html","id":null,"dir":"Reference","previous_headings":"","what":"Builds the transition probability matrix of an HSMM-approximating HMM — tpm_hsmm","title":"Builds the transition probability matrix of an HSMM-approximating HMM — tpm_hsmm","text":"Hidden semi-Markov models (HSMMs) flexible extension HMMs, state duration distribution explicitly modelled. direct numerical maximum likelhood estimation, HSMMs can represented HMMs enlarged state space (size \\(M\\)) structured transition probabilities. function computes transition matrix approximate given HSMM HMM larger state space.","code":""},{"path":"https://janoleko.github.io/reference/tpm_hsmm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Builds the transition probability matrix of an HSMM-approximating HMM — tpm_hsmm","text":"","code":"tpm_hsmm(omega, dm, Fm = NULL, sparse = TRUE, eps = 1e-10)"},{"path":"https://janoleko.github.io/reference/tpm_hsmm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Builds the transition probability matrix of an HSMM-approximating HMM — tpm_hsmm","text":"omega embedded transition probability matrix dimension c(N,N) computed tpm_emb. dm state dwell-time distributions arranged list length(N). list element needs vector length N_i, N_i state aggregate size. Fm optional list length N containing cumulative distribution functions dwell-time distributions. sparse logical, indicating whether output sparse matrix. Defaults TRUE. eps rounding value: entry transition probabily matrix smaller, rounded zero. Usually, changed.","code":""},{"path":"https://janoleko.github.io/reference/tpm_hsmm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Builds the transition probability matrix of an HSMM-approximating HMM — tpm_hsmm","text":"extended-state-space transition probability matrix approximating HMM","code":""},{"path":"https://janoleko.github.io/reference/tpm_hsmm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Builds the transition probability matrix of an HSMM-approximating HMM — tpm_hsmm","text":"","code":"# building the t.p.m. of the embedded Markov chain omega = matrix(c(0,1,1,0), nrow = 2, byrow = TRUE) # defining state aggregate sizes sizes = c(20, 30) # defining state dwell-time distributions lambda = c(5, 11) dm = list(dpois(1:sizes[1]-1, lambda[1]), dpois(1:sizes[2]-1, lambda[2])) # calculating extended-state-space t.p.m. Gamma = tpm_hsmm(omega, dm)"},{"path":"https://janoleko.github.io/reference/tpm_hsmm2.html","id":null,"dir":"Reference","previous_headings":"","what":"Build the transition probability matrix of an HSMM-approximating HMM — tpm_hsmm2","title":"Build the transition probability matrix of an HSMM-approximating HMM — tpm_hsmm2","text":"Hidden semi-Markov models (HSMMs) flexible extension HMMs. direct numerical maximum likelhood estimation, HSMMs can represented HMMs enlarged state space (size \\(M\\)) structured transition probabilities. function computes transition matrix HSMM.","code":""},{"path":"https://janoleko.github.io/reference/tpm_hsmm2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build the transition probability matrix of an HSMM-approximating HMM — tpm_hsmm2","text":"","code":"tpm_hsmm2(omega, dm, eps = 1e-10)"},{"path":"https://janoleko.github.io/reference/tpm_hsmm2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build the transition probability matrix of an HSMM-approximating HMM — tpm_hsmm2","text":"omega embedded transition probability matrix dimension c(N,N) dm state dwell-time distributions arranged list length(N). list element needs vector length N_i, N_i state aggregate size. eps rounding value: entry transition probabily matrix smaller, rounded zero.","code":""},{"path":"https://janoleko.github.io/reference/tpm_hsmm2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build the transition probability matrix of an HSMM-approximating HMM — tpm_hsmm2","text":"extended-state-space transition probability matrix approximating HMM","code":""},{"path":"https://janoleko.github.io/reference/tpm_hsmm2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Build the transition probability matrix of an HSMM-approximating HMM — tpm_hsmm2","text":"","code":"# building the t.p.m. of the embedded Markov chain omega = matrix(c(0,1,1,0), nrow = 2, byrow = TRUE) # defining state aggregate sizes sizes = c(20, 30) # defining state dwell-time distributions lambda = c(5, 11) dm = list(dpois(1:sizes[1]-1, lambda[1]), dpois(1:sizes[2]-1, lambda[2])) # calculating extended-state-space t.p.m. Gamma = tpm_hsmm(omega, dm)"},{"path":"https://janoleko.github.io/reference/tpm_ihsmm.html","id":null,"dir":"Reference","previous_headings":"","what":"Builds all transition probability matrices of an inhomogeneous-HSMM-approximating HMM — tpm_ihsmm","title":"Builds all transition probability matrices of an inhomogeneous-HSMM-approximating HMM — tpm_ihsmm","text":"Hidden semi-Markov models (HSMMs) flexible extension HMMs. direct numerical maximum likelhood estimation, HSMMs can represented HMMs enlarged state space (size \\(M\\)) structured transition probabilities. function computes transition matrices periodically inhomogeneos HSMMs.","code":""},{"path":"https://janoleko.github.io/reference/tpm_ihsmm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Builds all transition probability matrices of an inhomogeneous-HSMM-approximating HMM — tpm_ihsmm","text":"","code":"tpm_ihsmm(omega, dm, eps = 1e-10)"},{"path":"https://janoleko.github.io/reference/tpm_ihsmm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Builds all transition probability matrices of an inhomogeneous-HSMM-approximating HMM — tpm_ihsmm","text":"omega embedded transition probability matrix Either matrix dimension c(N,N) homogeneous conditional transition probabilities (computed tpm_emb), array dimension c(N,N,n) inhomogeneous conditional transition probabilities (computed tpm_emb_g). dm state dwell-time distributions arranged list length N list element needs matrix dimension c(n, N_i), row t (approximate) probability mass function state time t. eps rounding value: entry transition probabily matrix smaller, rounded zero. Usually, changed.","code":""},{"path":"https://janoleko.github.io/reference/tpm_ihsmm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Builds all transition probability matrices of an inhomogeneous-HSMM-approximating HMM — tpm_ihsmm","text":"list dimension length n - max(sapply(dm, ncol)), containing sparse extended-state-space transition probability matrices time point (except first max(sapply(dm, ncol)) - 1).","code":""},{"path":"https://janoleko.github.io/reference/tpm_ihsmm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Builds all transition probability matrices of an inhomogeneous-HSMM-approximating HMM — tpm_ihsmm","text":"","code":"N = 2 # time-varying mean dwell times n = 100 z = runif(n) beta = matrix(c(2, 2, 0.1, -0.1), nrow = 2) Lambda = exp(cbind(1, z) %*% t(beta)) sizes = c(15, 15) # approximating chain with 30 states # state dwell-time distributions dm = lapply(1:N, function(i) sapply(1:sizes[i]-1, dpois, lambda = Lambda[,i]))  ## homogeneous conditional transition probabilites # diagonal elements are zero, rowsums are one omega = matrix(c(0,1,1,0), nrow = N, byrow = TRUE)  # calculating extended-state-space t.p.m.s Gamma = tpm_ihsmm(omega, dm)  ## inhomogeneous conditional transition probabilites # omega can be an array omega = array(omega, dim = c(N,N,n))  # calculating extended-state-space t.p.m.s Gamma = tpm_ihsmm(omega, dm)"},{"path":"https://janoleko.github.io/reference/tpm_p.html","id":null,"dir":"Reference","previous_headings":"","what":"Build all transition probability matrices of a periodically inhomogeneous HMM — tpm_p","title":"Build all transition probability matrices of a periodically inhomogeneous HMM — tpm_p","text":"Given periodically varying variable time day day year associated cycle length, function calculates transition probability matrices applying inverse multinomial logistic link (also known softmax) linear predictors form $$  \\eta^{(t)}_{ij} = \\beta_0^{(ij)} + \\sum_{k=1}^K \\bigl( \\beta_{1k}^{(ij)} \\sin(\\frac{2 \\pi k t}{L}) + \\beta_{2k}^{(ij)} \\cos(\\frac{2 \\pi k t}{L}) \\bigr) $$ -diagonal elements (\\(\\neq j\\)) transition probability matrix. relevant modeling e.g. diurnal variation flexibility can increased adding smaller frequencies (.e. increasing \\(K\\)).","code":""},{"path":"https://janoleko.github.io/reference/tpm_p.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build all transition probability matrices of a periodically inhomogeneous HMM — tpm_p","text":"","code":"tpm_p(   tod = 1:24,   L = 24,   beta,   degree = 1,   Z = NULL,   byrow = FALSE,   ad = NULL,   report = TRUE )"},{"path":"https://janoleko.github.io/reference/tpm_p.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build all transition probability matrices of a periodically inhomogeneous HMM — tpm_p","text":"tod equidistant sequence cyclic variable time day e.g. half-hourly data, 1, ..., L L = 48, 0.5, 1, 1.5, ..., 24 L = 24. L length one full cycle, scale tod beta matrix coefficients -diagonal elements transition probability matrix Needs dimension c(N *(N-1), 2*degree+1), first column contains intercepts. degree degree trigonometric link function additional degree, one sine one cosine frequency added. Z pre-calculated design matrix (excluding intercept column) Defaults NULL trigonometric link calculated. efficiency perspective, Z pre-calculated within likelihood function, basis expansion redundantly calculated. can done using trigBasisExp. byrow logical indicating transition probability matrix filled row Defaults FALSE, set TRUE one wants work matrix beta parameters returned popular HMM packages like moveHMM, momentuHMM, hmmTMB. ad optional logical, indicating whether automatic differentiation RTMB used. default, function determines . report logical, indicating whether coefficient matrix beta reported fitted model. Defaults TRUE, works ad = TRUE.","code":""},{"path":"https://janoleko.github.io/reference/tpm_p.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build all transition probability matrices of a periodically inhomogeneous HMM — tpm_p","text":"array transition probability matrices dimension c(N,N,length(tod))","code":""},{"path":"https://janoleko.github.io/reference/tpm_p.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Build all transition probability matrices of a periodically inhomogeneous HMM — tpm_p","text":"Note using function inside negative log-likelihood function convenient, performs basis expansion sine cosine terms time called. change optimisation, using tpm_g pre-calculated (trigBasisExp) design matrix efficient.","code":""},{"path":[]},{"path":"https://janoleko.github.io/reference/tpm_p.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Build all transition probability matrices of a periodically inhomogeneous HMM — tpm_p","text":"","code":"# hourly data  tod = seq(1, 24, by = 1) L = 24 beta = matrix(c(-1, 2, -1, -2, 1, -1), nrow = 2, byrow = TRUE) Gamma = tpm_p(tod, L, beta, degree = 1)  # half-hourly data ## integer tod sequence tod = seq(1, 48, by = 1) L = 48 beta = matrix(c(-1, 2, -1, -2, 1, -1), nrow = 2, byrow = TRUE) Gamma1 = tpm_p(tod, L, beta, degree = 1)  ## equivalent specification tod = seq(0.5, 24, by = 0.5) L = 24 beta = matrix(c(-1, 2, -1, -2, 1, -1), nrow = 2, byrow = TRUE) Gamma2 = tpm_p(tod, L, beta, degree = 1)  all(Gamma1 == Gamma2) # same result #> [1] TRUE"},{"path":"https://janoleko.github.io/reference/tpm_phsmm.html","id":null,"dir":"Reference","previous_headings":"","what":"Builds all transition probability matrices of an periodic-HSMM-approximating HMM — tpm_phsmm","title":"Builds all transition probability matrices of an periodic-HSMM-approximating HMM — tpm_phsmm","text":"Hidden semi-Markov models (HSMMs) flexible extension HMMs. direct numerical maximum likelhood estimation, HSMMs can represented HMMs enlarged state space (size \\(M\\)) structured transition probabilities. function computes transition matrices periodically inhomogeneos HSMMs.","code":""},{"path":"https://janoleko.github.io/reference/tpm_phsmm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Builds all transition probability matrices of an periodic-HSMM-approximating HMM — tpm_phsmm","text":"","code":"tpm_phsmm(omega, dm, eps = 1e-10)"},{"path":"https://janoleko.github.io/reference/tpm_phsmm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Builds all transition probability matrices of an periodic-HSMM-approximating HMM — tpm_phsmm","text":"omega embedded transition probability matrix Either matrix dimension c(N,N) homogeneous conditional transition probabilities (computed tpm_emb), array dimension c(N,N,L) inhomogeneous conditional transition probabilities (computed tpm_emb_g). dm state dwell-time distributions arranged list length N list element needs matrix dimension c(L, N_i), row t (approximate) probability mass function state time t. eps rounding value: entry transition probabily matrix smaller, rounded zero. Usually, changed.","code":""},{"path":"https://janoleko.github.io/reference/tpm_phsmm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Builds all transition probability matrices of an periodic-HSMM-approximating HMM — tpm_phsmm","text":"list dimension length L, containing sparse extended-state-space transition probability matrices approximating HMM time point cycle.","code":""},{"path":"https://janoleko.github.io/reference/tpm_phsmm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Builds all transition probability matrices of an periodic-HSMM-approximating HMM — tpm_phsmm","text":"","code":"N = 2 # number of states L = 24 # cycle length # time-varying mean dwell times Z = trigBasisExp(1:L) # trigonometric basis functions design matrix beta = matrix(c(2, 2, 0.1, -0.1, -0.2, 0.2), nrow = 2) Lambda = exp(cbind(1, Z) %*% t(beta)) sizes = c(20, 20) # approximating chain with 40 states # state dwell-time distributions dm = lapply(1:N, function(i) sapply(1:sizes[i]-1, dpois, lambda = Lambda[,i]))  ## homogeneous conditional transition probabilites # diagonal elements are zero, rowsums are one omega = matrix(c(0,1,1,0), nrow = N, byrow = TRUE)  # calculating extended-state-space t.p.m.s Gamma = tpm_phsmm(omega, dm)  ## inhomogeneous conditional transition probabilites # omega can be an array omega = array(omega, dim = c(N,N,L))  # calculating extended-state-space t.p.m.s Gamma = tpm_phsmm(omega, dm)"},{"path":"https://janoleko.github.io/reference/tpm_phsmm2.html","id":null,"dir":"Reference","previous_headings":"","what":"Build all transition probability matrices of an periodic-HSMM-approximating HMM — tpm_phsmm2","title":"Build all transition probability matrices of an periodic-HSMM-approximating HMM — tpm_phsmm2","text":"Hidden semi-Markov models (HSMMs) flexible extension HMMs. direct numerical maximum likelhood estimation, HSMMs can represented HMMs enlarged state space (size \\(M\\)) structured transition probabilities. function computes transition matrices periodically inhomogeneos HSMMs.","code":""},{"path":"https://janoleko.github.io/reference/tpm_phsmm2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build all transition probability matrices of an periodic-HSMM-approximating HMM — tpm_phsmm2","text":"","code":"tpm_phsmm2(omega, dm, eps = 1e-10)"},{"path":"https://janoleko.github.io/reference/tpm_phsmm2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build all transition probability matrices of an periodic-HSMM-approximating HMM — tpm_phsmm2","text":"omega embedded transition probability matrix Either matrix dimension c(N,N) homogeneous conditional transition probabilities, array dimension c(N,N,L) inhomogeneous conditional transition probabilities. dm state dwell-time distributions arranged list length(N) list element needs matrix dimension c(L, N_i), row t (approximate) probability mass function state time t. eps rounding value: entry transition probabily matrix smaller, rounded zero.","code":""},{"path":"https://janoleko.github.io/reference/tpm_phsmm2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build all transition probability matrices of an periodic-HSMM-approximating HMM — tpm_phsmm2","text":"array dimension c(N,N,L), containing extended-state-space transition probability matrices approximating HMM time point cycle.","code":""},{"path":"https://janoleko.github.io/reference/tpm_phsmm2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Build all transition probability matrices of an periodic-HSMM-approximating HMM — tpm_phsmm2","text":"","code":"N = 3 L = 24 # time-varying mean dwell times Lambda = exp(matrix(rnorm(L*N, 2, 0.5), nrow = L)) sizes = c(25, 25, 25) # approximating chain with 75 states # state dwell-time distributions dm = list() for(i in 1:3){   dmi = matrix(nrow = L, ncol = sizes[i])   for(t in 1:L){     dmi[t,] = dpois(1:sizes[i]-1, Lambda[t,i])   }   dm[[i]] = dmi }  ## homogeneous conditional transition probabilites # diagonal elements are zero, rowsums are one omega = matrix(c(0,0.5,0.5,0.2,0,0.8,0.7,0.3,0), nrow = N, byrow = TRUE)  # calculating extended-state-space t.p.m.s Gamma = tpm_phsmm(omega, dm)  ## inhomogeneous conditional transition probabilites # omega can be an array omega = array(rep(omega,L), dim = c(N,N,L)) omega[1,,4] = c(0, 0.2, 0.8) # small change for inhomogeneity  # calculating extended-state-space t.p.m.s Gamma = tpm_phsmm(omega, dm)"},{"path":"https://janoleko.github.io/reference/tpm_thinned.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the transition probability matrix of a thinned periodically inhomogeneous Markov chain. — tpm_thinned","title":"Compute the transition probability matrix of a thinned periodically inhomogeneous Markov chain. — tpm_thinned","text":"transition probability matrix inhomogeneous Markov chain varies periodically (period length \\(L\\)), converges -called periodically stationary distribution. happens, thinned Markov chain, full cycle time step, homogeneous transition probability matrix $$\\Gamma_t = \\Gamma^{(t)} \\Gamma^{(t+1)} \\dots \\Gamma^{(t+L-1)}$$ \\(t = 1, \\dots, L.\\) function calculates matrix efficiently preliminery step calculating periodically stationary distribution.","code":""},{"path":"https://janoleko.github.io/reference/tpm_thinned.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the transition probability matrix of a thinned periodically inhomogeneous Markov chain. — tpm_thinned","text":"","code":"tpm_thinned(Gamma, t)"},{"path":"https://janoleko.github.io/reference/tpm_thinned.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the transition probability matrix of a thinned periodically inhomogeneous Markov chain. — tpm_thinned","text":"Gamma array transition probability matrices dimension c(N,N,L). t integer index time point cycle, calculate thinned transition probility matrix","code":""},{"path":"https://janoleko.github.io/reference/tpm_thinned.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the transition probability matrix of a thinned periodically inhomogeneous Markov chain. — tpm_thinned","text":"thinned transition probabilty matrix dimension c(N,N)","code":""},{"path":"https://janoleko.github.io/reference/tpm_thinned.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute the transition probability matrix of a thinned periodically inhomogeneous Markov chain. — tpm_thinned","text":"","code":"# setting parameters for trigonometric link beta = matrix(c(-1, -2, 2, -1, 2, -4), nrow = 2, byrow = TRUE) # calculating periodically varying t.p.m. array (of length 24 here) Gamma = tpm_p(beta = beta) # calculating t.p.m. of thinned Markov chain tpm_thinned(Gamma, 4) #>           [,1]      [,2] #> [1,] 0.8926642 0.1073358 #> [2,] 0.8926642 0.1073358"},{"path":"https://janoleko.github.io/reference/trex.html","id":null,"dir":"Reference","previous_headings":"","what":"T-Rex Movement Data — trex","title":"T-Rex Movement Data — trex","text":"Hourly step lengths turning angles Tyrannosaurus rex, living 66 million years ago.","code":""},{"path":"https://janoleko.github.io/reference/trex.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"T-Rex Movement Data — trex","text":"","code":"trex"},{"path":"https://janoleko.github.io/reference/trex.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"T-Rex Movement Data — trex","text":"data frame 10.000 rows 4 variables: tod time day variable ranging 1 24 step hourly step lengths kilometres angle hourly turning angles radians state hidden state variable","code":""},{"path":"https://janoleko.github.io/reference/trex.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"T-Rex Movement Data — trex","text":"Generated example purposes.","code":""},{"path":"https://janoleko.github.io/reference/trigBasisExp.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the design matrix for a trigonometric basis expansion — trigBasisExp","title":"Compute the design matrix for a trigonometric basis expansion — trigBasisExp","text":"Given periodically varying variable time day day year associated cycle length, function performs basis expansion efficiently calculate linear predictor form $$  \\eta^{(t)} = \\beta_0 + \\sum_{k=1}^K \\bigl( \\beta_{1k} \\sin(\\frac{2 \\pi k t}{L}) + \\beta_{2k} \\cos(\\frac{2 \\pi k t}{L}) \\bigr).  $$  relevant modeling e.g. diurnal variation flexibility can increased adding smaller frequencies (.e. increasing \\(K\\)).","code":""},{"path":"https://janoleko.github.io/reference/trigBasisExp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the design matrix for a trigonometric basis expansion — trigBasisExp","text":"","code":"trigBasisExp(tod, L = 24, degree = 1)"},{"path":"https://janoleko.github.io/reference/trigBasisExp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the design matrix for a trigonometric basis expansion — trigBasisExp","text":"tod equidistant sequence cyclic variable time day e.g. half-hourly data, 1, ..., L L = 48, 0.5, 1, 1.5, ..., 24 L = 24. L length one cycle scale time variable. time day, 24. degree degree K trigonometric link . Increasing K increases flexibility.","code":""},{"path":"https://janoleko.github.io/reference/trigBasisExp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the design matrix for a trigonometric basis expansion — trigBasisExp","text":"design matrix (without intercept column), ordered sin1, cos1, sin2, cos2, ...","code":""},{"path":"https://janoleko.github.io/reference/trigBasisExp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute the design matrix for a trigonometric basis expansion — trigBasisExp","text":"","code":"## hourly data tod = rep(1:24, 10) Z = trigBasisExp(tod, L = 24, degree = 2)  ## half-hourly data tod = rep(1:48/2, 10) # in [0,24] -> L = 24 Z1 = trigBasisExp(tod, L = 24, degree = 3)  tod = rep(1:48, 10) # in [1,48] -> L = 48 Z2 = trigBasisExp(tod, L = 48, degree = 3)  all(Z1 == Z2) #> [1] TRUE # The latter two are equivalent specifications!"},{"path":"https://janoleko.github.io/reference/viterbi.html","id":null,"dir":"Reference","previous_headings":"","what":"Viterbi algorithm for state decoding in homogeneous HMMs — viterbi","title":"Viterbi algorithm for state decoding in homogeneous HMMs — viterbi","text":"Viterbi algorithm allows one decode probable state sequence HMM.","code":""},{"path":"https://janoleko.github.io/reference/viterbi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Viterbi algorithm for state decoding in homogeneous HMMs — viterbi","text":"","code":"viterbi(delta, Gamma, allprobs, trackID = NULL, mod = NULL)"},{"path":"https://janoleko.github.io/reference/viterbi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Viterbi algorithm for state decoding in homogeneous HMMs — viterbi","text":"delta initial distribution length N, matrix dimension c(k,N) k independent tracks, trackID provided Gamma transition probability matrix dimension c(N,N) array transition probability matrices dimension c(N,N,k) trackID provided allprobs matrix state-dependent probabilities/ density values dimension c(n, N) trackID optional vector k track IDs, multiple tracks need decoded separately mod optional model object containing initial distribution delta, transition probability matrix Gamma, matrix state-dependent probabilities allprobs, potentially trackID variable using automatic differentiation either RTMB::MakeADFun qreml include forward likelihood function, objects needed state decoding automatically reported model fitting. Hence, can pass model object obtained running RTMB::report() qreml directly function.","code":""},{"path":"https://janoleko.github.io/reference/viterbi.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Viterbi algorithm for state decoding in homogeneous HMMs — viterbi","text":"vector decoded states length n","code":""},{"path":[]},{"path":"https://janoleko.github.io/reference/viterbi.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Viterbi algorithm for state decoding in homogeneous HMMs — viterbi","text":"","code":"delta = c(0.5, 0.5) Gamma = matrix(c(0.9, 0.1, 0.2, 0.8), nrow = 2, byrow = TRUE) allprobs = matrix(runif(200), nrow = 100, ncol = 2) states = viterbi(delta, Gamma, allprobs)"},{"path":"https://janoleko.github.io/reference/viterbi_g.html","id":null,"dir":"Reference","previous_headings":"","what":"Viterbi algorithm for state decoding in inhomogeneous HMMs — viterbi_g","title":"Viterbi algorithm for state decoding in inhomogeneous HMMs — viterbi_g","text":"Viterbi algorithm allows one decode probable state sequence HMM.","code":""},{"path":"https://janoleko.github.io/reference/viterbi_g.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Viterbi algorithm for state decoding in inhomogeneous HMMs — viterbi_g","text":"","code":"viterbi_g(delta, Gamma, allprobs, trackID = NULL, mod = NULL)"},{"path":"https://janoleko.github.io/reference/viterbi_g.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Viterbi algorithm for state decoding in inhomogeneous HMMs — viterbi_g","text":"delta initial distribution length N, matrix dimension c(k,N) k independent tracks, trackID provided Gamma array transition probability matrices dimension c(N,N,n-1), time series length n, n-1 transitions array dimension c(N,N,n) provided single track, first slice ignored. trackID provided, Gamma needs array dimension c(N,N,n), n number rows allprobs. track first transition matrix ignored. allprobs matrix state-dependent probabilities/ density values dimension c(n, N) trackID optional vector k track IDs, multiple tracks need decoded separately mod optional model object containing initial distribution delta, transition probability matrix Gamma, matrix state-dependent probabilities allprobs, potentially trackID variable using automatic differentiation either RTMB::MakeADFun qreml include forward_g likelihood function, objects needed state decoding automatically reported model fitting. Hence, can pass model object obtained running RTMB::report() qreml directly function.","code":""},{"path":"https://janoleko.github.io/reference/viterbi_g.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Viterbi algorithm for state decoding in inhomogeneous HMMs — viterbi_g","text":"vector decoded states length n","code":""},{"path":[]},{"path":"https://janoleko.github.io/reference/viterbi_g.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Viterbi algorithm for state decoding in inhomogeneous HMMs — viterbi_g","text":"","code":"delta = c(0.5, 0.5) Gamma = tpm_g(runif(10), matrix(c(-2,-2,1,-1), nrow = 2)) allprobs = matrix(runif(20), nrow = 10, ncol = 2) states = viterbi_g(delta, Gamma[,,-1], allprobs)"},{"path":"https://janoleko.github.io/reference/viterbi_p.html","id":null,"dir":"Reference","previous_headings":"","what":"Viterbi algorithm for state decoding in periodically inhomogeneous HMMs — viterbi_p","title":"Viterbi algorithm for state decoding in periodically inhomogeneous HMMs — viterbi_p","text":"Viterbi algorithm allows one decode probable state sequence HMM.","code":""},{"path":"https://janoleko.github.io/reference/viterbi_p.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Viterbi algorithm for state decoding in periodically inhomogeneous HMMs — viterbi_p","text":"","code":"viterbi_p(delta, Gamma, allprobs, tod, trackID = NULL, mod = NULL)"},{"path":"https://janoleko.github.io/reference/viterbi_p.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Viterbi algorithm for state decoding in periodically inhomogeneous HMMs — viterbi_p","text":"delta initial distribution length N, matrix dimension c(k,N) k independent tracks, trackID provided e.g. periodically stationary distribution (track). Gamma array transition probability matrices time point cycle dimension c(N,N,L), L length cycle allprobs matrix state-dependent probabilities/ density values dimension c(n, N) tod (Integer valued) variable cycle indexing 1, ..., L, mapping data index generalised time day (length n) half-hourly data L = 48. , however, also day year daily data L = 365. trackID optional vector k track IDs, multiple tracks need decoded separately mod optional model object containing initial distribution delta, transition probability matrix Gamma, matrix state-dependent probabilities allprobs, potentially trackID variable using automatic differentiation either RTMB::MakeADFun qreml include forward_p likelihood function, objects needed state decoding automatically reported model fitting. Hence, can pass model object obtained running RTMB::report() qreml directly function.","code":""},{"path":"https://janoleko.github.io/reference/viterbi_p.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Viterbi algorithm for state decoding in periodically inhomogeneous HMMs — viterbi_p","text":"vector decoded states length n","code":""},{"path":[]},{"path":"https://janoleko.github.io/reference/viterbi_p.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Viterbi algorithm for state decoding in periodically inhomogeneous HMMs — viterbi_p","text":"","code":"delta = c(0.5, 0.5) beta = matrix(c(-2, 1, -1,                 -2, -1, 1), nrow = 2, byrow = TRUE) Gamma = tpm_p(1:24, 24, beta)  tod = rep(1:24, 5) n = length(tod)  allprobs = matrix(runif(2*n), nrow = n, ncol = 2) states = viterbi_p(delta, Gamma, allprobs, tod)"},{"path":"https://janoleko.github.io/reference/vm.html","id":null,"dir":"Reference","previous_headings":"","what":"von Mises distribution — vm","title":"von Mises distribution — vm","text":"Density, distribution function random generation von Mises distribution.","code":""},{"path":"https://janoleko.github.io/reference/vm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"von Mises distribution — vm","text":"","code":"dvm(x, mu = 0, kappa = 1, log = FALSE)  pvm(q, mu = 0, kappa = 1, from = NULL, tol = 1e-20)  rvm(n, mu = 0, kappa = 1, wrap = TRUE)"},{"path":"https://janoleko.github.io/reference/vm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"von Mises distribution — vm","text":"x, q vector angles measured radians evaluate density function. mu mean direction distribution measured radians. kappa non-negative numeric value concentration parameter distribution. log logical; TRUE, densities returned log scale. value integration CDF starts. NULL, set mu - pi. tol precision evaluating distribution function n number observations. length(n) > 1, length taken number required. wrap logical; TRUE, generated angles wrapped interval [-pi, pi].","code":""},{"path":"https://janoleko.github.io/reference/vm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"von Mises distribution — vm","text":"dvm gives density, pvm gives distribution function, rvm generates random deviates.","code":""},{"path":"https://janoleko.github.io/reference/vm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"von Mises distribution — vm","text":"implementation dvm allows automatic differentiation RTMB. rvm pvm simply wrappers corresponding functions circular.","code":""},{"path":"https://janoleko.github.io/reference/vm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"von Mises distribution — vm","text":"","code":"set.seed(1) x = rvm(10, 0, 1) d = dvm(x, 0, 1) p = pvm(x, 0, 1)"},{"path":"https://janoleko.github.io/reference/wrpcauchy.html","id":null,"dir":"Reference","previous_headings":"","what":"wrapped Cauchy distribution — wrpcauchy","title":"wrapped Cauchy distribution — wrpcauchy","text":"Density random generation wrapped Cauchy distribution.","code":""},{"path":"https://janoleko.github.io/reference/wrpcauchy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"wrapped Cauchy distribution — wrpcauchy","text":"","code":"dwrpcauchy(x, mu = 0, rho, log = FALSE)  rwrpcauchy(n, mu = 0, rho, wrap = TRUE)"},{"path":"https://janoleko.github.io/reference/wrpcauchy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"wrapped Cauchy distribution — wrpcauchy","text":"x vector angles measured radians evaluate density function. mu mean direction distribution measured radians. rho concentration parameter distribution, must interval 0 1. log logical; TRUE, densities returned log scale. n number observations. length(n) > 1, length taken number required. wrap logical; TRUE, generated angles wrapped interval [-pi, pi].","code":""},{"path":"https://janoleko.github.io/reference/wrpcauchy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"wrapped Cauchy distribution — wrpcauchy","text":"dwrpcauchy gives density rwrpcauchy generates random deviates.","code":""},{"path":"https://janoleko.github.io/reference/wrpcauchy.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"wrapped Cauchy distribution — wrpcauchy","text":"implementation dwrpcauchy allows automatic differentiation RTMB. rwrpcauchy simply wrapper rwrappedcauchyimported circular.","code":""},{"path":"https://janoleko.github.io/reference/wrpcauchy.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"wrapped Cauchy distribution — wrpcauchy","text":"","code":"set.seed(1) x = rwrpcauchy(10, 0, 1) d = dwrpcauchy(x, 0, 1)"},{"path":"https://janoleko.github.io/reference/zero_inflate.html","id":null,"dir":"Reference","previous_headings":"","what":"Zero-inflated density constructer — zero_inflate","title":"Zero-inflated density constructer — zero_inflate","text":"Constructs zero-inflated density function given probability density function","code":""},{"path":"https://janoleko.github.io/reference/zero_inflate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Zero-inflated density constructer — zero_inflate","text":"","code":"zero_inflate(dist, discrete = NULL)"},{"path":"https://janoleko.github.io/reference/zero_inflate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Zero-inflated density constructer — zero_inflate","text":"dist either probability density function probability mass function discrete logical; TRUE, density x = 0 zeroprob + (1-zeroprob) * dist(0, ...). Otherwise just zeroprob. standard cases, determined automatically. non-standard cases, set TRUE FALSE depending type dist. See details.","code":""},{"path":"https://janoleko.github.io/reference/zero_inflate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Zero-inflated density constructer — zero_inflate","text":"zero-inflated density function first argument x, second argument zeroprob, additional arguments ... passed dist.","code":""},{"path":"https://janoleko.github.io/reference/zero_inflate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Zero-inflated density constructer — zero_inflate","text":"definition zero-inflation different discrete continuous distributions. discrete distributions p.m.f. \\(f\\) zero-inflation probability \\(p\\), $$\\Pr(X = 0) = p + (1 - p) \\cdot f(0),$$ $$\\Pr(X = x) = (1 - p) \\cdot f(x), \\quad x > 0.$$ continuous distributions p.d.f. \\(f\\), $$f_{\\text{zinfl}}(x) = p \\cdot \\delta_0(x) + (1 - p) \\cdot f(x),$$ \\(\\delta_0\\) Dirac delta function zero.","code":""},{"path":"https://janoleko.github.io/reference/zero_inflate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Zero-inflated density constructer — zero_inflate","text":"","code":"dzinorm <- zero_inflate(dnorm) dzinorm(c(NA, 0, 2), 0.5, mean = 1, sd = 1) #> [1]        NA 0.5000000 0.1209854  zipois <- zero_inflate(dpois) zipois(c(NA, 0, 1), 0.5, 1) #> [1]        NA 0.6839397 0.1839397"}]
