% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/qreml_functions.R
\name{qreml}
\alias{qreml}
\title{Quasi restricted maximum likelihood (qREML) algorithm for models with penalised splines or simple i.i.d. random effects}
\usage{
qreml(
  pnll,
  par,
  dat,
  random,
  psname = "lambda",
  alpha = 0,
  smoothing = 1,
  maxiter = 100,
  tol = 1e-04,
  control = list(reltol = 1e-10, maxit = 1000),
  silent = 1,
  joint_unc = TRUE,
  saveall = FALSE
)
}
\arguments{
\item{pnll}{penalised negative log-likelihood function that is structured as dictated by \code{RTMB} and uses the \code{\link{penalty}} function from \code{LaMa} to compute the penalty

Needs to be a function of the named list of initial parameters \code{par} only.}

\item{par}{named list of initial parameters

The random effects/ spline coefficients can be vectors or matrices, the latter summarising several random effects of the same structure, each one being a row in the matrix.}

\item{dat}{initial data list that contains the data used in the likelihood function, hyperparameters, and the \strong{initial penalty strength} vector

If the initial penalty strength vector is \strong{not} called \code{lambda}, the name it has in \code{dat} needs to be specified using the \code{penalty} argument below.
Its length needs to match the to the total number of random effects.}

\item{random}{vector of names of the random effects/ penalised parameters in \code{par}

\strong{Caution:} The ordering of \code{random} needs to match the order of the random effects passed to \code{\link{penalty}} inside the likelihood function.}

\item{psname}{optional name given to the penalty strength parameter in \code{dat}. Defaults to \code{"lambda"}.}

\item{alpha}{optional hyperparamater for exponential smoothing of the penalty strengths

For larger values smoother convergence is to be expected but the algorithm may need more iterations.}

\item{smoothing}{optional scaling factor for the final penalty strength parameters

Increasing this beyond one will lead to a smoother final model. Can be an integer or a vector of length equal to the length of the penalty strength parameter.}

\item{maxiter}{maximum number of iterations in the outer optimisation over the penalty strength parameters.}

\item{tol}{Convergence tolerance for the penalty strength parameters.}

\item{control}{list of control parameters for \code{\link[stats:optim]{optim}} to use in the inner optimisation. Here, \code{optim} uses the \code{BFGS} method which cannot be changed.

We advise against changing the default values of \code{reltol} and \code{maxit} as this can decrease the accuracy of the Laplace approximation.}

\item{silent}{integer silencing level: 0 corresponds to full printing of inner and outer iterations, 1 to printing of outer iterations only, and 2 to no printing.}

\item{joint_unc}{logical, if \code{TRUE}, joint RTMB object is returned allowing for joint uncertainty quantification}

\item{saveall}{logical, if \code{TRUE}, then all model objects from each iteration are saved in the final model object.}
}
\value{
returns a model list influenced by the users report statements in \code{pnll}
}
\description{
This algorithm can be used very flexibly to fit statistical models that involve \strong{penalised splines} or simple \strong{i.i.d. random effects}, i.e. that have penalties of the form
\deqn{0.5 \sum_{i} \lambda_i b_i^T S_i b_i,}
with smoothing parameters \eqn{\lambda_i}, coefficient vectors \eqn{b_i}, and fixed penalty matrices \eqn{S_i}.

The \strong{qREML} algorithm is typically much faster than REML or marginal ML using the full Laplace approximation method, but may be slightly less accurate regarding the estimation of the penalty strength parameters.

Under the hood, \code{qreml} uses the R package \code{RTMB} for automatic differentiation in the inner optimisation.
The user has to specify the \strong{penalised negative log-likelihood function} \code{pnll} structured as dictated by \code{RTMB} and use the \code{\link{penalty}} function to compute the quadratic-form penalty inside the likelihood.
}
\examples{
data = trex[1:1000,] # subset

# initial parameter list
par = list(logmu = log(c(0.3, 1)), # step mean
           logsigma = log(c(0.2, 0.7)), # step sd
           beta0 = c(-2,2), # state process intercept
           betaspline = matrix(rep(0, 18), nrow = 2)) # state process spline coefs
          
# data object with initial penalty strength lambda
dat = list(step = data$step, # step length
           tod = data$tod, # time of day covariate
           N = 2, # number of states
           lambda = rep(10,2)) # initial penalty strength

# building model matrices
modmat = make_matrices(~ s(tod, bs = "cp"), 
                       data = data.frame(tod = 1:24), 
                       knots = list(tod = c(0,24))) # wrapping points
dat$Z = modmat$Z # spline design matrix
dat$S = modmat$S # penalty matrix

# penalised negative log-likelihood function
pnll = function(par) {
  getAll(par, dat) # makes everything contained available without $
  Gamma = tpm_g(Z, cbind(beta0, betaspline), ad = TRUE) # transition probabilities
  delta = stationary_p(Gamma, t = 1, ad = TRUE) # initial distribution
  mu = exp(logmu) # step mean
  sigma = exp(logsigma) # step sd
  # calculating all state-dependent densities
  allprobs = matrix(1, nrow = length(step), ncol = N)
  ind = which(!is.na(step)) # only for non-NA obs.
  for(j in 1:N) allprobs[ind,j] = dgamma2(step[ind],mu[j],sigma[j])
  -forward_g(delta, Gamma[,,tod], allprobs, ad = TRUE) +
      penalty(betaspline, S, lambda) # this does all the penalization work
}

# model fitting
mod = qreml(pnll, par, dat, random = "betaspline")
}
\seealso{
\code{\link{penalty}} to compute the penalty inside the likelihood function
}
